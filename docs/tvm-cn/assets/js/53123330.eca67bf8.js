"use strict";(self.webpackChunktvm_cn=self.webpackChunktvm_cn||[]).push([["61284"],{1588:function(n,e,t){t.r(e),t.d(e,{default:()=>p,frontMatter:()=>s,metadata:()=>i,assets:()=>o,toc:()=>d,contentTitle:()=>c});var i=JSON.parse('{"id":"how_to/optimize/gpu_conv","title":"\u5982\u4F55\u5728 GPU \u4E0A\u4F18\u5316\u5377\u79EF","description":"\u5355\u51FB \u6B64\u5904 \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801","source":"@site/versioned_docs/version-0.12.0/how_to/optimize/02-gpu_conv.md","sourceDirName":"how_to/optimize","slug":"/how_to/optimize/gpu_conv","permalink":"/docs/tvm-cn/docs/0.12.0/how_to/optimize/gpu_conv","draft":false,"unlisted":false,"editUrl":"https://github.com/hyperai/tvm-cn/edit/master/versioned_docs/version-0.12.0/how_to/optimize/02-gpu_conv.md","tags":[],"version":"0.12.0","lastUpdatedBy":"sparanoid","lastUpdatedAt":1744717810000,"sidebarPosition":2,"frontMatter":{"title":"\u5982\u4F55\u5728 GPU \u4E0A\u4F18\u5316\u5377\u79EF"},"sidebar":"tutorialSidebar","previous":{"title":"\u5982\u4F55\u5728 CPU \u4E0A\u4F18\u5316 GEMM","permalink":"/docs/tvm-cn/docs/0.12.0/how_to/optimize/cpu_conv"},"next":{"title":"\u5982\u4F55\u4F7F\u7528 TensorCores \u4F18\u5316\u5377\u79EF","permalink":"/docs/tvm-cn/docs/0.12.0/how_to/optimize/tensorcore_conv"}}'),a=t("74132"),r=t("21494");let s={title:"\u5982\u4F55\u5728 GPU \u4E0A\u4F18\u5316\u5377\u79EF"},c="\u5982\u4F55\u5728 GPU \u4E0A\u4F18\u5316\u5377\u79EF",o={},d=[{value:"\u51C6\u5907\u548C\u7B97\u6CD5",id:"\u51C6\u5907\u548C\u7B97\u6CD5",level:2},{value:"\u5185\u5B58\u5C42\u6B21\u7ED3\u6784",id:"\u5185\u5B58\u5C42\u6B21\u7ED3\u6784",level:2},{value:"\u5206\u5757",id:"\u5206\u5757",level:2},{value:"\u865A\u62DF\u7EBF\u7A0B\u5206\u5272",id:"\u865A\u62DF\u7EBF\u7A0B\u5206\u5272",level:2},{value:"\u534F\u540C\u83B7\u53D6\uFF08Cooperative Fetching\uFF09",id:"\u534F\u540C\u83B7\u53D6cooperative-fetching",level:2},{value:"\u751F\u6210 CUDA \u5185\u6838",id:"\u751F\u6210-cuda-\u5185\u6838",level:2}];function l(n){let e={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",p:"p",pre:"pre",strong:"strong",...(0,r.a)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"\u5982\u4F55\u5728-gpu-\u4E0A\u4F18\u5316\u5377\u79EF",children:"\u5982\u4F55\u5728 GPU \u4E0A\u4F18\u5316\u5377\u79EF"})}),"\n",(0,a.jsx)(e.admonition,{type:"note",children:(0,a.jsxs)(e.p,{children:["\u5355\u51FB ",(0,a.jsx)(e.a,{href:"https://tvm.apache.org/docs/how_to/optimize_operators/opt_conv_cuda.html#sphx-glr-download-how-to-optimize-operators-opt-conv-cuda-py",children:"\u6B64\u5904"})," \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801"]})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"\u4F5C\u8005"}),"\uFF1A",(0,a.jsx)(e.a,{href:"https://homes.cs.washington.edu/~haichen/",children:"Haichen Shen"})]}),"\n",(0,a.jsx)(e.p,{children:"\u672C\u6559\u7A0B\u6F14\u793A\u4E86\u5982\u4F55\u5728 TVM \u4E2D\u7F16\u5199\u9AD8\u6027\u80FD\u5377\u79EF\u5B9E\u73B0\u3002\u4EE5\u6B63\u65B9\u5F62\u5927\u5C0F\u7684\u8F93\u5165\u5F20\u91CF\u548C\u6EE4\u6CE2\u5668\u4E3A\u4F8B\uFF0C\u5047\u8BBE\u5377\u79EF\u8F93\u5165\u7684 batch \u8F83\u5927\u3002\u5728\u6B64\u793A\u4F8B\u4E2D\uFF0C\u4F7F\u7528\u4E0D\u540C\u7684\u5E03\u5C40\u6765\u5B58\u50A8\u6570\u636E\uFF0C\u4EE5\u5B9E\u73B0\u66F4\u597D\u7684\u6570\u636E\u5C40\u90E8\u6027\u3002\u7F13\u51B2\u533A\u5E03\u5C40\u662F HWCN\uFF0C\u5206\u522B\u4EE3\u8868\u9AD8\u5EA6\u3001\u5BBD\u5EA6\u3001\u901A\u9053\u3001batch\u3002"}),"\n",(0,a.jsx)(e.h2,{id:"\u51C6\u5907\u548C\u7B97\u6CD5",children:"\u51C6\u5907\u548C\u7B97\u6CD5"}),"\n",(0,a.jsx)(e.p,{children:"\u5BF9\u5177\u6709 256 \u4E2A\u901A\u9053\u548C 14 x 14 \u7EF4\u5EA6\u7684\u8F93\u5165\u5F20\u91CF\u4F7F\u7528\u56FA\u5B9A\u5927\u5C0F\u3002batch size \u4E3A 256\uFF0C\u5377\u79EF\u8FC7\u6EE4\u5668\u5305\u542B 512 \u4E2A\u5927\u5C0F\u4E3A 3 x 3 \u7684\u8FC7\u6EE4\u5668\uFF0C\u7528\u6B65\u957F\u4E3A 1 \u548C padding size \u4E3A 1 \u8FDB\u884C\u5377\u79EF\u3002\u4EE5\u4E0B\u4EE3\u7801\u5B9A\u4E49\u4E86 TVM \u4E2D\u7684\u5377\u79EF\u7B97\u6CD5\u3002"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import numpy as np\nimport tvm\nfrom tvm import te\n\n# \u8F93\u5165\u548C\u8FC7\u6EE4\u5668\u7684\u5927\u5C0F\nbatch = 256\nin_channel = 256\nout_channel = 512\nin_size = 14\nkernel = 3\npad = 1\nstride = 1\n\n# \u7B97\u6CD5\nA = te.placeholder((in_size, in_size, in_channel, batch), name="A")\nW = te.placeholder((kernel, kernel, in_channel, out_channel), name="W")\nout_size = (in_size - kernel + 2 * pad) // stride + 1\n# Pad \u8F93\u5165\nApad = te.compute(\n    (in_size + 2 * pad, in_size + 2 * pad, in_channel, batch),\n    lambda yy, xx, cc, nn: tvm.tir.if_then_else(\n        tvm.tir.all(yy >= pad, yy - pad < in_size, xx >= pad, xx - pad < in_size),\n        A[yy - pad, xx - pad, cc, nn],\n        tvm.tir.const(0.0, "float32"),\n    ),\n    name="Apad",\n)\n# \u521B\u5EFA\u5F52\u7EA6\u53D8\u91CF\nrc = te.reduce_axis((0, in_channel), name="rc")\nry = te.reduce_axis((0, kernel), name="ry")\nrx = te.reduce_axis((0, kernel), name="rx")\n# \u8BA1\u7B97\u5377\u79EF\nB = te.compute(\n    (out_size, out_size, out_channel, batch),\n    lambda yy, xx, ff, nn: te.sum(\n        Apad[yy * stride + ry, xx * stride + rx, rc, nn] * W[ry, rx, rc, ff], axis=[ry, rx, rc]\n    ),\n    name="B",\n)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"\u5185\u5B58\u5C42\u6B21\u7ED3\u6784",children:"\u5185\u5B58\u5C42\u6B21\u7ED3\u6784"}),"\n",(0,a.jsx)(e.p,{children:"\u9996\u5148\u6307\u5B9A\u7F13\u51B2\u533A\u7684\u5185\u5B58\u5C42\u6B21\u7ED3\u6784\u3002\u4E0B\u56FE\u663E\u793A\u4E86 GPU \u5185\u5B58\u5C42\u6B21\u7ED3\u6784\uFF0C\u4E0E CPU \u5185\u5B58\u5C42\u6B21\u7ED3\u6784\u7684\u91CD\u8981\u533A\u522B\u662F GPU \u63D0\u4F9B\u4E86\u4E00\u4E2A\u79F0\u4E3A\u5171\u4EAB\u5185\u5B58\u7684\u7F13\u5B58\u7F13\u51B2\u533A\uFF0C\u7531\u7A0B\u5E8F\u5458\u7BA1\u7406\u3002\u56E0\u6B64\uFF0C\u5982\u4F55\u6700\u5927\u5316\u5171\u4EAB\u5185\u5B58\u4E2D\u7684\u6570\u636E\u91CD\u7528\u5BF9\u4E8E\u5728 GPU \u5185\u6838\u4E2D\u5B9E\u73B0\u9AD8\u6027\u80FD\u81F3\u5173\u91CD\u8981\u3002"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{src:"https://github.com/dmlc/web-data/raw/main/tvm/tutorial/gpu_memory_hierarchy.png",alt:"\u56FE\u7247"})}),"\n",(0,a.jsx)(e.p,{children:"\u5728\u672C\u4F8B\u4E2D\uFF0C\u5C06 Apad \u548C W \u52A0\u8F7D\u5230\u7F13\u51B2\u533A AA \u548C WW \u4E2D\uFF08\u5B58\u50A8\u5728\u5171\u4EAB\u5185\u5B58\u4E2D\uFF09\u3002\u8FD9\u4E9B\u7F13\u51B2\u533A\u7A0D\u540E\u5C06\u7531\u540C\u4E00\u7EBF\u7A0B\u5757\u4E2D\u7684\u6240\u6709\u7EBF\u7A0B\u5171\u4EAB\u4EE5\u8BA1\u7B97\u5377\u79EF\uFF0C\u7136\u540E\u6BCF\u4E2A\u7EBF\u7A0B\u5C06\u81EA\u5DF1\u7684\u90E8\u5206\u4ECE\u5171\u4EAB\u7F13\u51B2\u533A\u52A0\u8F7D\u5230\u5B83\u4EEC\u7684\u672C\u5730\u5BC4\u5B58\u5668 AL \u548C WL \u4E2D\u3002BL \u662F\u8F93\u51FA B \u7684\u672C\u5730\u7F13\u5B58\uFF0C\u4E5F\u5B58\u50A8\u5728\u7EBF\u7A0B\u672C\u5730\u5BC4\u5B58\u5668\u4E2D\u3002"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# \u6307\u5B9A\u5185\u5B58\u5C42\u6B21\u7ED3\u6784\ns = te.create_schedule(B.op)\ns[Apad].compute_inline()  # compute Apad inline\nAA = s.cache_read(Apad, "shared", [B])\nWW = s.cache_read(W, "shared", [B])\nAL = s.cache_read(AA, "local", [B])\nWL = s.cache_read(WW, "local", [B])\nBL = s.cache_write(B, "local")\n'})}),"\n",(0,a.jsx)(e.h2,{id:"\u5206\u5757",children:"\u5206\u5757"}),"\n",(0,a.jsx)(e.p,{children:"\u4EE5\u4E0B\u4EE3\u7801\u5C06\u5DE5\u4F5C\u8D1F\u8F7D\u62C6\u5206\u4E3A\u7EBF\u7A0B\u5757\u548C\u5355\u72EC\u7684\u7EBF\u7A0B\uFF0C\u9075\u5FAA\u77E9\u9635\u4E58\u6CD5\u4E2D\u7684\u5206\u5757\u65B9\u6848\u3002\u5982\u4E0B\u56FE\u6240\u793A\uFF0C\u7ED9\u5B9A\u4E00\u4E2A\u50CF\u7D20\u5750\u6807\uFF08y\u3001x\uFF09\uFF0C\u4E00\u4E2A\u7EBF\u7A0B\u5757\u8D1F\u8D23\u8BA1\u7B97\u4E00\u4E2A block_factor x block_factor (64 x 64) \u7684\u533A\u57DF\uFF0C\u7528\u4E8E\u8F93\u51FA\u901A\u9053\u548C batch\u3002\u7531\u4E8E\u5171\u4EAB\u5185\u5B58\u7A7A\u95F4\u7684\u9650\u5236\uFF0C\u6BCF\u6B21\u53EA\u4ECE Apad \u548C B \u52A0\u8F7D step x block_factor (8 x 64) \u6570\u636E\u5230\u5171\u4EAB\u5185\u5B58\u4E2D\u7684\u7F13\u51B2\u533A\u3002"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{src:"https://github.com/dmlc/web-data/raw/main/tvm/tutorial/conv_gpu_blocking.png",alt:"\u56FE\u7247"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# \u5E73\u94FA\u5E38\u91CF\ntile = 8\nnum_thread = 8\nblock_factor = tile * num_thread\nstep = 8\nvthread = 2\n\n# \u83B7\u53D6 GPU \u7EBF\u7A0B\u7D22\u5F15\nblock_x = te.thread_axis("blockIdx.x")\nblock_y = te.thread_axis("blockIdx.y")\nblock_z = te.thread_axis("blockIdx.z")\nthread_x = te.thread_axis((0, num_thread), "threadIdx.x")\nthread_y = te.thread_axis((0, num_thread), "threadIdx.y")\nthread_xz = te.thread_axis((0, vthread), "vthread", name="vx")\nthread_yz = te.thread_axis((0, vthread), "vthread", name="vy")\n\n# split \u5DE5\u4F5C\u8D1F\u8F7D\nhi, wi, fi, ni = s[B].op.axis\nbz = s[B].fuse(hi, wi)\nby, fi = s[B].split(fi, factor=block_factor)\nbx, ni = s[B].split(ni, factor=block_factor)\n\n# \u5C06\u8FED\u4EE3\u53D8\u91CF\u7ED1\u5B9A\u5230 GPU \u7EBF\u7A0B\u7D22\u5F15\ns[B].bind(bz, block_z)\ns[B].bind(by, block_y)\ns[B].bind(bx, block_x)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"\u865A\u62DF\u7EBF\u7A0B\u5206\u5272",children:"\u865A\u62DF\u7EBF\u7A0B\u5206\u5272"}),"\n",(0,a.jsxs)(e.p,{children:["\u8FDB\u4E00\u6B65\u5C06\u5DE5\u4F5C\u8D1F\u8F7D\u4ECE\u7EBF\u7A0B\u5757\u62C6\u5206\u4E3A\u5355\u4E2A\u7EBF\u7A0B\u3002\u4E3A\u4E86\u907F\u514D ",(0,a.jsx)(e.em,{children:"memory bank conflict"}),"\uFF0C\u4F7F\u7528\u865A\u62DF\u7EBF\u7A0B\u5C06\u533A\u57DF\u5206\u6210 4 \u4E2A\u90E8\u5206\uFF0C\u7136\u540E\u5E73\u94FA\u6210 8x8 \u7684\u7F51\u683C\u3002\u56E0\u6B64\uFF0C\u5982\u4E0B\u56FE\u6240\u793A\uFF0C\u6BCF\u4E2A\u7EBF\u7A0B\u8BA1\u7B97 4 \u4E2A\u8DE8\u6B65\u7F51\u683C\uFF0C\u6BCF\u4E2A\u7F51\u683C\u7684\u5927\u5C0F\u4E3A 4 x 4\u3002"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.img,{src:"https://github.com/dmlc/web-data/raw/main/tvm/tutorial/conv_gpu_vthread.png",alt:"\u56FE\u7247"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"tyz, fi = s[B].split(fi, nparts=vthread)  # \u865A\u62DF\u7EBF\u7A0B split\ntxz, ni = s[B].split(ni, nparts=vthread)  # \u865A\u62DF\u7EBF\u7A0B split\nty, fi = s[B].split(fi, nparts=num_thread)\ntx, ni = s[B].split(ni, nparts=num_thread)\ns[B].reorder(bz, by, bx, tyz, txz, ty, tx, fi, ni)\n\ns[B].bind(tyz, thread_yz)\ns[B].bind(txz, thread_xz)\ns[B].bind(ty, thread_y)\ns[B].bind(tx, thread_x)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"\u534F\u540C\u83B7\u53D6cooperative-fetching",children:"\u534F\u540C\u83B7\u53D6\uFF08Cooperative Fetching\uFF09"}),"\n",(0,a.jsx)(e.p,{children:"\u5982\u524D\u6240\u8FF0\uFF0C\u6BCF\u4E2A\u65F6\u95F4\u6B65\u957F\u90FD\u8981\u5C06 step x block_factor \u6570\u636E\u4ECE GPU \u5168\u5C40\u5185\u5B58\u4F20\u8F93\u5230\u5171\u4EAB\u5185\u5B58\u3002\u4E3A\u4E86\u51CF\u5C11\u6BCF\u4E2A\u7EBF\u7A0B\u7684\u5185\u5B58\u4F20\u8F93\uFF0C\u4EE5\u4E0B\u4EE3\u7801\u8BA9\u540C\u4E00\u7EBF\u7A0B\u5757\u4E2D\u7684\u7EBF\u7A0B\u534F\u540C\u4ECE\u5168\u5C40\u5185\u5B58\u4E2D\u83B7\u53D6\u76F8\u5173\u6570\u636E\u3002"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# Schedule BL \u672C\u5730\u5199\u5165\ns[BL].compute_at(s[B], tx)\nyi, xi, fi, ni = s[BL].op.axis\nry, rx, rc = s[BL].op.reduce_axis\nrco, rci = s[BL].split(rc, factor=step)\ns[BL].reorder(rco, ry, rx, rci, fi, ni)\n\n# \u5C06\u8BA1\u7B97\u9644\u52A0\u5230\u8FED\u4EE3\u53D8\u91CF\ns[AA].compute_at(s[BL], rx)\ns[WW].compute_at(s[BL], rx)\ns[AL].compute_at(s[BL], rci)\ns[WL].compute_at(s[BL], rci)\n\n# A \u7684\u5171\u4EAB\u5185\u5B58\u8D1F\u8F7D\u8C03\u5EA6\nyi, xi, ci, ni = s[AA].op.axis\nty, ci = s[AA].split(ci, nparts=num_thread)\ntx, ni = s[AA].split(ni, nparts=num_thread)\n_, ni = s[AA].split(ni, factor=4)\ns[AA].reorder(ty, tx, yi, xi, ci, ni)\ns[AA].bind(ty, thread_y)\ns[AA].bind(tx, thread_x)\ns[AA].vectorize(ni)  # \u5411\u91CF\u5316\u5185\u5B58\u52A0\u8F7D\n\n# W \u7684\u5171\u4EAB\u5185\u5B58\u8D1F\u8F7D\u8C03\u5EA6\nyi, xi, ci, fi = s[WW].op.axis\nty, ci = s[WW].split(ci, nparts=num_thread)\ntx, fi = s[WW].split(fi, nparts=num_thread)\n_, fi = s[WW].split(fi, factor=4)\ns[WW].reorder(ty, tx, yi, xi, ci, fi)\ns[WW].bind(ty, thread_y)\ns[WW].bind(tx, thread_x)\ns[WW].vectorize(fi)  # \u5411\u91CF\u5316\u5185\u5B58\u52A0\u8F7D\n"})}),"\n",(0,a.jsx)(e.h2,{id:"\u751F\u6210-cuda-\u5185\u6838",children:"\u751F\u6210 CUDA \u5185\u6838"}),"\n",(0,a.jsx)(e.p,{children:"\u6700\u540E\u7528 TVM \u751F\u6210\u548C\u7F16\u8BD1 CUDA \u5185\u6838\uFF0C\u5E76\u8BC4\u4F30\u5377\u79EF\u7684\u5EF6\u8FDF\u3002"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'func = tvm.build(s, [A, W, B], "cuda")\ndev = tvm.cuda(0)\na_np = np.random.uniform(size=(in_size, in_size, in_channel, batch)).astype(A.dtype)\nw_np = np.random.uniform(size=(kernel, kernel, in_channel, out_channel)).astype(W.dtype)\na = tvm.nd.array(a_np, dev)\nw = tvm.nd.array(w_np, dev)\nb = tvm.nd.array(np.zeros((out_size, out_size, out_channel, batch), dtype=B.dtype), dev)\nfunc(a, w, b)\nevaluator = func.time_evaluator(func.entry_name, dev, number=1)\nprint("Convolution: %f ms" % (evaluator(a, w, b).mean * 1e3))\n'})}),"\n",(0,a.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"Convolution: 54.146944 ms\n"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:"https://tvm.apache.org/docs/_downloads/3c5c85c3954f3110f16ca084e286f03a/opt_conv_cuda.py",children:"\u4E0B\u8F7D Python \u6E90\u4EE3\u7801\uFF1Aopt_conv_cuda.py"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.a,{href:"https://tvm.apache.org/docs/_downloads/854257a66df713b1f3f82eb3577f95e3/opt_conv_cuda.ipynb",children:"\u4E0B\u8F7D Jupyter notebook\uFF1Aopt_conv_cuda.ipynb"})})]})}function p(n={}){let{wrapper:e}={...(0,r.a)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(l,{...n})}):l(n)}},21494:function(n,e,t){t.d(e,{Z:function(){return c},a:function(){return s}});var i=t(39546);let a={},r=i.createContext(a);function s(n){let e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function c(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);