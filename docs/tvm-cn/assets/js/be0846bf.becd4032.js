"use strict";(self.webpackChunktvm_cn=self.webpackChunktvm_cn||[]).push([["89073"],{40117:function(e,n,t){t.r(n),t.d(n,{default:()=>d,frontMatter:()=>s,metadata:()=>a,assets:()=>l,toc:()=>u,contentTitle:()=>i});var a=JSON.parse('{"id":"how_to/autotune/autotuning_x86","title":"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC","description":"\u5355\u51FB \u6B64\u5904 \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801","source":"@site/versioned_docs/version-0.10.0/how_to/autotune/03-autotuning_x86.md","sourceDirName":"how_to/autotune","slug":"/how_to/autotune/autotuning_x86","permalink":"/docs/tvm-cn/docs/0.10.0/how_to/autotune/autotuning_x86","draft":false,"unlisted":false,"editUrl":"https://github.com/hyperai/tvm-cn/edit/master/versioned_docs/version-0.10.0/how_to/autotune/03-autotuning_x86.md","tags":[],"version":"0.10.0","lastUpdatedBy":"sparanoid","lastUpdatedAt":1744717810000,"sidebarPosition":3,"frontMatter":{"title":"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC"},"sidebar":"tutorialSidebar","previous":{"title":"\u4E3A NVIDIA GPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC","permalink":"/docs/tvm-cn/docs/0.10.0/how_to/autotune/autotuning_nvidia"},"next":{"title":"\u4E3A ARM CPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC","permalink":"/docs/tvm-cn/docs/0.10.0/how_to/autotune/autotuning_arm"}}'),r=t("74132"),o=t("21494");let s={title:"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC"},i="\u4E3A x86 CPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC",l={},u=[{value:"\u5B9A\u4E49\u7F51\u7EDC",id:"\u5B9A\u4E49\u7F51\u7EDC",level:2},{value:"\u914D\u7F6E\u5F20\u91CF\u8C03\u4F18\u8BBE\u7F6E\u5E76\u521B\u5EFA\u4EFB\u52A1",id:"\u914D\u7F6E\u5F20\u91CF\u8C03\u4F18\u8BBE\u7F6E\u5E76\u521B\u5EFA\u4EFB\u52A1",level:2},{value:"\u6837\u672C\u8F93\u51FA",id:"\u6837\u672C\u8F93\u51FA",level:2}];function p(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",strong:"strong",...(0,o.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"\u4E3A-x86-cpu-\u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC",children:"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC"})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["\u5355\u51FB ",(0,r.jsx)(n.a,{href:"https://tvm.apache.org/docs/how_to/tune_with_autotvm/tune_relay_x86.html#sphx-glr-download-how-to-tune-with-autotvm-tune-relay-x86-py",children:"\u6B64\u5904"})," \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801"]})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"\u4F5C\u8005"}),"\uFF1A",(0,r.jsx)(n.a,{href:"https://github.com/kevinthesun",children:"Yao Wang"}),", ",(0,r.jsx)(n.a,{href:"https://github.com/eqy",children:"Eddie Yan"})]}),"\n",(0,r.jsx)(n.p,{children:"\u672C\u6587\u4ECB\u7ECD\u5982\u4F55\u4E3A x86 CPU \u8C03\u4F18\u5377\u79EF\u795E\u7ECF\u7F51\u7EDC\u3002"}),"\n",(0,r.jsxs)(n.p,{children:["\u6CE8\u610F\uFF0C\u672C\u6559\u7A0B\u4E0D\u4F1A\u5728 Windows \u6216\u6700\u65B0\u7248\u672C\u7684 macOS \u4E0A\u8FD0\u884C\u3002\u5982\u9700\u8FD0\u884C\uFF0C\u8BF7\u5C06\u672C\u6559\u7A0B\u7684\u4E3B\u4F53\u653E\u5728 ",(0,r.jsx)(n.code,{children:'if __name__ == "__main__":'})," \u4EE3\u7801\u5757\u4E2D\u3002"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import os\nimport numpy as np\n\nimport tvm\nfrom tvm import relay, autotvm\nfrom tvm.relay import testing\nfrom tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\nfrom tvm.autotvm.graph_tuner import DPTuner, PBQPTuner\nimport tvm.contrib.graph_executor as runtime\n"})}),"\n",(0,r.jsx)(n.h2,{id:"\u5B9A\u4E49\u7F51\u7EDC",children:"\u5B9A\u4E49\u7F51\u7EDC"}),"\n",(0,r.jsxs)(n.p,{children:["\u9996\u5148\u5728 Relay \u524D\u7AEF API \u4E2D\u5B9A\u4E49\u7F51\u7EDC\uFF0C\u53EF\u4EE5\u4ECE ",(0,r.jsx)(n.code,{children:"relay.testing"})," \u52A0\u8F7D\u4E00\u4E9B\u9884\u5B9A\u4E49\u7684\u7F51\u7EDC\uFF0C\u4E5F\u53EF\u4EE5\u4F7F\u7528 Relay \u6784\u5EFA ",(0,r.jsx)(n.code,{children:"relay.testing.resnet"}),"\u3002\u8FD8\u53EF\u4EE5\u4ECE MXNet\u3001ONNX \u548C TensorFlow \u52A0\u8F7D\u6A21\u578B\u3002"]}),"\n",(0,r.jsx)(n.p,{children:"\u672C\u6559\u7A0B\u7528 resnet-18 \u4F5C\u4E3A\u8C03\u4F18\u793A\u4F8B\u3002"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def get_network(name, batch_size):\n    """\u83B7\u53D6\u7F51\u7EDC\u7684\u7B26\u53F7\u5B9A\u4E49\u548C\u968F\u673A\u6743\u91CD"""\n    input_shape = (batch_size, 3, 224, 224)\n    output_shape = (batch_size, 1000)\n\n    if "resnet" in name:\n        n_layer = int(name.split("-")[1])\n        mod, params = relay.testing.resnet.get_workload(\n            num_layers=n_layer, batch_size=batch_size, dtype=dtype\n        )\n    elif "vgg" in name:\n        n_layer = int(name.split("-")[1])\n        mod, params = relay.testing.vgg.get_workload(\n            num_layers=n_layer, batch_size=batch_size, dtype=dtype\n        )\n    elif name == "mobilenet":\n        mod, params = relay.testing.mobilenet.get_workload(batch_size=batch_size, dtype=dtype)\n    elif name == "squeezenet_v1.1":\n        mod, params = relay.testing.squeezenet.get_workload(\n            batch_size=batch_size, version="1.1", dtype=dtype\n        )\n    elif name == "inception_v3":\n        input_shape = (batch_size, 3, 299, 299)\n        mod, params = relay.testing.inception_v3.get_workload(batch_size=batch_size, dtype=dtype)\n    elif name == "mxnet":\n        # MXNet \u6A21\u578B\u7684\u793A\u4F8B\n        from mxnet.gluon.model_zoo.vision import get_model\n\n        block = get_model("resnet18_v1", pretrained=True)\n        mod, params = relay.frontend.from_mxnet(block, shape={input_name: input_shape}, dtype=dtype)\n        net = mod["main"]\n        net = relay.Function(\n            net.params, relay.nn.softmax(net.body), None, net.type_params, net.attrs\n        )\n        mod = tvm.IRModule.from_expr(net)\n    else:\n        raise ValueError("Unsupported network: " + name)\n\n    return mod, params, input_shape, output_shape\n\n# \u5C06\u300Cllvm\u300D\u66FF\u6362\u4E3A\u4F60\u7684 CPU \u7684 target\u3002\n# \u4F8B\u5982\uFF0C\u5BF9\u4E8E\u652F\u6301 Intel Xeon Platinum 8000 \u7CFB\u5217\u7684 AWS EC2 c5 \u5B9E\u4F8B\uFF0C\n# target \u662F\u300Cllvm -mcpu=skylake-avx512\u300D\u3002\n# \u5BF9\u4E8E\u652F\u6301 Intel Xeon E5-2666 v3 \u7684 AWS EC2 c4 \u5B9E\u4F8B\uFF0Ctarget \u662F\u300Cllvm -mcpu=core-avx2\u300D\u3002\ntarget = "llvm"\nbatch_size = 1\ndtype = "float32"\nmodel_name = "resnet-18"\nlog_file = "%s.log" % model_name\ngraph_opt_sch_file = "%s_graph_opt.log" % model_name\n\n# \u8BBE\u7F6E\u56FE\u8BA1\u7B97\u56FE\u7684\u8F93\u5165\u540D\u79F0\n# \u5BF9\u4E8E ONNX \u6A21\u578B\uFF0C\u5B83\u901A\u5E38\u4E3A\u201C0\u201D\u3002\ninput_name = "data"\n\n# \u6839\u636E CPU \u5185\u6838\u8BBE\u7F6E\u8C03\u4F18\u7684\u7EBF\u7A0B\u6570\nnum_threads = 1\nos.environ["TVM_NUM_THREADS"] = str(num_threads)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u914D\u7F6E\u5F20\u91CF\u8C03\u4F18\u8BBE\u7F6E\u5E76\u521B\u5EFA\u4EFB\u52A1",children:"\u914D\u7F6E\u5F20\u91CF\u8C03\u4F18\u8BBE\u7F6E\u5E76\u521B\u5EFA\u4EFB\u52A1"}),"\n",(0,r.jsx)(n.p,{children:"\u4E3A\u4E86\u5728 x86 CPU \u4E0A\u83B7\u5F97\u66F4\u597D\u7684\u5185\u6838\u6267\u884C\u6027\u80FD\uFF0C\u5C06\u5377\u79EF\u5185\u6838\u7684\u6570\u636E\u5E03\u5C40\u4ECE\u300CNCHW\u300D\u66F4\u6539\u4E3A\u300CNCHWc\u300D\u3002\u4E3A\u4E86\u5904\u7406\u8FD9\u79CD\u60C5\u51B5\uFF0C\u5728 topi \u4E2D\u5B9A\u4E49\u4E86 conv2d_NCHWc \u7B97\u5B50\uFF0C\u8C03\u4F18\u6B64\u7B97\u5B50\u800C\u975E\u666E\u901A\u7684 conv2d\u3002"}),"\n",(0,r.jsxs)(n.p,{children:["\u4F7F\u7528\u672C\u5730\u6A21\u5F0F\u6765\u8C03\u4F18\u914D\u7F6E\uFF0CRPC tracker \u6A21\u5F0F\u7684\u8BBE\u7F6E\u7C7B\u4F3C\u4E8E ",(0,r.jsx)(n.a,{href:"autotuning_arm",children:"\u81EA\u52A8\u8C03\u4F18 ARM CPU \u7684\u5377\u79EF\u7F51\u7EDC"})," \u6559\u7A0B\u4E2D\u7684\u65B9\u6CD5\u3002"]}),"\n",(0,r.jsx)(n.p,{children:"\u4E3A\u4E86\u7CBE\u51C6\u6D4B\u8BD5\uFF0C\u5E94\u8BE5\u591A\u6B21\u91CD\u590D\u6D4B\u8BD5\uFF0C\u5E76\u53D6\u7ED3\u679C\u7684\u5E73\u5747\u503C\u3002\u6B64\u5916\uFF0C\u9700\u8981\u5728\u91CD\u590D\u6D4B\u8BD5\u65F6\u5237\u65B0\u6743\u91CD\u5F20\u91CF\u7684\u7F13\u5B58\uFF0C\u4F7F\u5F97\u7B97\u5B50\u7684\u6D4B\u8BD5\u5EF6\u8FDF\u66F4\u63A5\u8FD1\u5176\u5728\u7AEF\u5230\u7AEF\u63A8\u7406\u671F\u95F4\u7684\u5B9E\u9645\u5EF6\u8FDF\u3002"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'tuning_option = {\n    "log_filename": log_file,\n    "tuner": "random",\n    "early_stopping": None,\n    "measure_option": autotvm.measure_option(\n        builder=autotvm.LocalBuilder(),\n        runner=autotvm.LocalRunner(\n            number=1, repeat=10, min_repeat_ms=0, enable_cpu_cache_flush=True\n        ),\n    ),\n}\n\n# \u53EF\u8DF3\u8FC7\u6B64\u51FD\u6570\u7684\u5B9E\u73B0\u3002\ndef tune_kernels(\n    tasks, measure_option, tuner="gridsearch", early_stopping=None, log_filename="tuning.log"\n):\n    for i, task in enumerate(tasks):\n        prefix = "[Task %2d/%2d] " % (i + 1, len(tasks))\n\n        # \u521B\u5EFA\u8C03\u4F18\u5668\n        if tuner == "xgb" or tuner == "xgb-rank":\n            tuner_obj = XGBTuner(task, loss_type="rank")\n        elif tuner == "ga":\n            tuner_obj = GATuner(task, pop_size=50)\n        elif tuner == "random":\n            tuner_obj = RandomTuner(task)\n        elif tuner == "gridsearch":\n            tuner_obj = GridSearchTuner(task)\n        else:\n            raise ValueError("Invalid tuner: " + tuner)\n\n        # \u5F00\u59CB\u8C03\u4F18\n        n_trial = len(task.config_space)\n        tuner_obj.tune(\n            n_trial=n_trial,\n            early_stopping=early_stopping,\n            measure_option=measure_option,\n            callbacks=[\n                autotvm.callback.progress_bar(n_trial, prefix=prefix),\n                autotvm.callback.log_to_file(log_filename),\n            ],\n        )\n\n# \u4F7F\u7528 graph Tuner \u5B9E\u73B0\u8BA1\u7B97\u56FE\u7EA7\u522B\u6700\u4F18\u8C03\u5EA6\n# \u5982\u679C\u5B8C\u6210\u65F6\u95F4\u8FC7\u957F\uFF0C\u5219\u8BBE\u7F6E use_DP=False\u3002\ndef tune_graph(graph, dshape, records, opt_sch_file, use_DP=True):\n    target_op = [\n        relay.op.get("nn.conv2d"),\n    ]\n    Tuner = DPTuner if use_DP else PBQPTuner\n    executor = Tuner(graph, {input_name: dshape}, records, target_op, target)\n    executor.benchmark_layout_transform(min_exec_num=2000)\n    executor.run()\n    executor.write_opt_sch2record_file(opt_sch_file)\n'})}),"\n",(0,r.jsx)(n.p,{children:"\u6700\u540E\u542F\u52A8\u8C03\u4F18\u4F5C\u4E1A\uFF0C\u5E76\u8BC4\u4F30\u7AEF\u5230\u7AEF\u6027\u80FD\u3002"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def evaluate_performance(lib, data_shape):\n    # \u4E0A\u4F20\u53C2\u6570\u5230\u8BBE\u5907\n    dev = tvm.cpu()\n    data_tvm = tvm.nd.array((np.random.uniform(size=data_shape)).astype(dtype))\n    module = runtime.GraphModule(lib["default"](dev))\n    module.set_input(input_name, data_tvm)\n\n    # \u8BC4\u4F30\n    print("Evaluate inference time cost...")\n    print(module.benchmark(dev, number=100, repeat=3))\n\ndef tune_and_evaluate(tuning_opt):\n    # \u4ECE Relay \u7A0B\u5E8F\u4E2D\u63D0\u53D6\u5DE5\u4F5C\u8D1F\u8F7D\n    print("Extract tasks...")\n    mod, params, data_shape, out_shape = get_network(model_name, batch_size)\n    tasks = autotvm.task.extract_from_program(\n        mod["main"], target=target, params=params, ops=(relay.op.get("nn.conv2d"),)\n    )\n\n    # \u8FD0\u884C\u8C03\u4F18\u4EFB\u52A1\n    tune_kernels(tasks, **tuning_opt)\n    tune_graph(mod["main"], data_shape, log_file, graph_opt_sch_file)\n\n    # \u5728\u9ED8\u8BA4\u6A21\u5F0F\u4E0B\u7F16\u8BD1\u5185\u6838\n    print("Evaluation of the network compiled in \'default\' mode without auto tune:")\n    with tvm.transform.PassContext(opt_level=3):\n        print("Compile...")\n        lib = relay.build(mod, target=target, params=params)\n        evaluate_performance(lib, data_shape)\n\n    # \u5728\u4EC5\u5185\u6838\u8C03\u4F18\u6A21\u5F0F\u4E0B\u7F16\u8BD1\u5185\u6838\n    print("\\nEvaluation of the network been tuned on kernel level:")\n    with autotvm.apply_history_best(log_file):\n        print("Compile...")\n        with tvm.transform.PassContext(opt_level=3):\n            lib = relay.build(mod, target=target, params=params)\n        evaluate_performance(lib, data_shape)\n\n    # \u7F16\u8BD1\u5177\u6709\u8BA1\u7B97\u56FE\u7EA7\u6700\u4F73\u8BB0\u5F55\u7684\u5185\u6838\n    print("\\nEvaluation of the network been tuned on graph level:")\n    with autotvm.apply_graph_best(graph_opt_sch_file):\n        print("Compile...")\n        with tvm.transform.PassContext(opt_level=3):\n            lib = relay.build_module.build(mod, target=target, params=params)\n        evaluate_performance(lib, data_shape)\n\n# \u4E0D\u5728\u7F51\u9875\u670D\u52A1\u5668\u4E2D\u8FD0\u884C\u8C03\u4F18\uFF0C\u56E0\u4E3A\u5B83\u9700\u8981\u7684\u65F6\u95F4\u592A\u957F\u3002\n# \u53D6\u6D88\u6CE8\u91CA\u8FD0\u884C\u4E0B\u4E00\u884C\n# tune_and_evaluate(tuning_option)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u6837\u672C\u8F93\u51FA",children:"\u6837\u672C\u8F93\u51FA"}),"\n",(0,r.jsx)(n.p,{children:"\u8C03\u4F18\u9700\u8981\u7F16\u8BD1\u8BB8\u591A\u7A0B\u5E8F\uFF0C\u5E76\u4ECE\u4E2D\u63D0\u53D6\u7279\u5F81\uFF0C\u63A8\u8350\u4F7F\u7528\u9AD8\u6027\u80FD\u7684 CPU\u3002\u4E0B\u9762\u5217\u51FA\u4E86\u4E00\u4E2A\u8F93\u51FA\u793A\u4F8B\u3002"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Extract tasks...\nTuning...\n[Task  1/12]  Current/Best:  598.05/2497.63 GFLOPS | Progress: (252/252) | 1357.95 s Done.\n[Task  2/12]  Current/Best:  522.63/2279.24 GFLOPS | Progress: (784/784) | 3989.60 s Done.\n[Task  3/12]  Current/Best:  447.33/1927.69 GFLOPS | Progress: (784/784) | 3869.14 s Done.\n[Task  4/12]  Current/Best:  481.11/1912.34 GFLOPS | Progress: (672/672) | 3274.25 s Done.\n[Task  5/12]  Current/Best:  414.09/1598.45 GFLOPS | Progress: (672/672) | 2720.78 s Done.\n[Task  6/12]  Current/Best:  508.96/2273.20 GFLOPS | Progress: (768/768) | 3718.75 s Done.\n[Task  7/12]  Current/Best:  469.14/1955.79 GFLOPS | Progress: (576/576) | 2665.67 s Done.\n[Task  8/12]  Current/Best:  230.91/1658.97 GFLOPS | Progress: (576/576) | 2435.01 s Done.\n[Task  9/12]  Current/Best:  487.75/2295.19 GFLOPS | Progress: (648/648) | 3009.95 s Done.\n[Task 10/12]  Current/Best:  182.33/1734.45 GFLOPS | Progress: (360/360) | 1755.06 s Done.\n[Task 11/12]  Current/Best:  372.18/1745.15 GFLOPS | Progress: (360/360) | 1684.50 s Done.\n[Task 12/12]  Current/Best:  215.34/2271.11 GFLOPS | Progress: (400/400) | 2128.74 s Done.\nINFO Start to benchmark layout transformation...\nINFO Benchmarking layout transformation successful.\nINFO Start to run dynamic programming algorithm...\nINFO Start forward pass...\nINFO Finished forward pass.\nINFO Start backward pass...\nINFO Finished backward pass...\nINFO Finished DPExecutor run.\nINFO Writing optimal schedules to resnet-18_graph_opt.log successfully.\n\nEvaluation of the network compiled in 'default' mode without auto tune:\nCompile...\nEvaluate inference time cost...\nMean inference time (std dev): 4.5 ms (0.03 ms)\n\nEvaluation of the network been tuned on kernel level:\nCompile...\nEvaluate inference time cost...\nMean inference time (std dev): 3.2 ms (0.03 ms)\n\nEvaluation of the network been tuned on graph level:\nCompile...\nConfig for target=llvm -keys=cpu -link-params=0, workload=('dense_nopack.x86', ('TENSOR', (1, 512), 'float32'), ('TENSOR', (1000, 512), 'float32'), None, 'float32') is missing in ApplyGraphBest context. A fallback configuration is used, which may bring great performance regression.\nConfig for target=llvm -keys=cpu -link-params=0, workload=('dense_pack.x86', ('TENSOR', (1, 512), 'float32'), ('TENSOR', (1000, 512), 'float32'), None, 'float32') is missing in ApplyGraphBest context. A fallback configuration is used, which may bring great performance regression.\nEvaluate inference time cost...\nMean inference time (std dev): 3.16 ms (0.03 ms)\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://tvm.apache.org/docs/_downloads/6836ce26807b8d33b8f499287c1f3d04/tune_relay_x86.py",children:"\u4E0B\u8F7D Python \u6E90\u4EE3\u7801\uFF1Atune_relay_x86.py"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://tvm.apache.org/docs/_downloads/910e6ecee4ecac8d8ca0baeb6d00689d/tune_relay_x86.ipynb",children:"\u4E0B\u8F7D Jupyter notebook\uFF1Atune_relay_x86.ipynb"})})]})}function d(e={}){let{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},21494:function(e,n,t){t.d(n,{Z:function(){return i},a:function(){return s}});var a=t(39546);let r={},o=a.createContext(r);function s(e){let n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);