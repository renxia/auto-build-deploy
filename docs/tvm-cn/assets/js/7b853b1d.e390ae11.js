"use strict";(self.webpackChunktvm_cn=self.webpackChunktvm_cn||[]).push([["49614"],{93979:function(n,t,e){e.r(t),e.d(t,{default:()=>c,frontMatter:()=>s,metadata:()=>r,assets:()=>l,toc:()=>p,contentTitle:()=>i});var r=JSON.parse('{"id":"topic/vta/tutorials/autotuning_alu","title":"\u5728 VTA \u4E0A\u81EA\u52A8\u8C03\u4F18 ALU \u878D\u5408\u7B97\u5B50","description":"\u5355\u51FB \u6B64\u5904 \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801","source":"@site/docs/topic/vta/tutorials/07-autotuning_alu.md","sourceDirName":"topic/vta/tutorials","slug":"/topic/vta/tutorials/autotuning_alu","permalink":"/docs/tvm-cn/docs/topic/vta/tutorials/autotuning_alu","draft":false,"unlisted":false,"editUrl":"https://github.com/hyperai/tvm-cn/edit/master/docs/topic/vta/tutorials/07-autotuning_alu.md","tags":[],"version":"current","lastUpdatedBy":"sparanoid","lastUpdatedAt":1744717810000,"sidebarPosition":7,"frontMatter":{"title":"\u5728 VTA \u4E0A\u81EA\u52A8\u8C03\u4F18 ALU \u878D\u5408\u7B97\u5B50"},"sidebar":"tutorialSidebar","previous":{"title":"\u77E9\u9635\u4E58\u6CD5\u5206\u5757","permalink":"/docs/tvm-cn/docs/topic/vta/tutorials/mat_mul_blocking"},"next":{"title":"\u5728 VTA \u4E0A\u81EA\u52A8\u8C03\u4F18\u5377\u79EF\u7F51\u7EDC","permalink":"/docs/tvm-cn/docs/topic/vta/tutorials/autotuning_conv"}}'),a=e("74132"),o=e("21494");let s={title:"\u5728 VTA \u4E0A\u81EA\u52A8\u8C03\u4F18 ALU \u878D\u5408\u7B97\u5B50"},i="\u5728 VTA \u4E0A\u81EA\u52A8\u8C03\u4F18 ALU \u878D\u5408\u7B97\u5B50",l={},p=[];function u(n){let t={a:"a",admonition:"admonition",code:"code",h1:"h1",header:"header",p:"p",pre:"pre",...(0,o.a)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"\u5728-vta-\u4E0A\u81EA\u52A8\u8C03\u4F18-alu-\u878D\u5408\u7B97\u5B50",children:"\u5728 VTA \u4E0A\u81EA\u52A8\u8C03\u4F18 ALU \u878D\u5408\u7B97\u5B50"})}),"\n",(0,a.jsx)(t.admonition,{type:"note",children:(0,a.jsxs)(t.p,{children:["\u5355\u51FB ",(0,a.jsx)(t.a,{href:"https://tvm.apache.org/docs/topic/vta/tutorials/autotvm/tune_alu_vta.html#sphx-glr-download-topic-vta-tutorials-autotvm-tune-alu-vta-py",children:"\u6B64\u5904"})," \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801"]})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"import os\nfrom mxnet.gluon.model_zoo import vision\nimport numpy as np\nfrom PIL import Image\n\nfrom tvm import topi\nimport tvm\nfrom tvm import te\nfrom tvm import rpc, autotvm, relay\nfrom tvm.contrib import download\nfrom tvm.autotvm.measure.measure_methods import request_remote\nfrom tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\nfrom tvm.autotvm import record\n\nimport vta\nfrom vta.testing import simulator\nfrom vta.top import graph_pack\nimport copy\n"})}),"\n",(0,a.jsx)(t.h1,{id:"\u7F16\u8BD1\u7F51\u7EDC",children:"\u7F16\u8BD1\u7F51\u7EDC"}),"\n",(0,a.jsx)(t.p,{children:"\u4F7F\u7528\u6765\u81EA Gluon \u6A21\u578B\u7684 Relay \u6267\u884C\u7279\u5B9A\u4E8E VTA \u7684\u7F16\u8BD1\uFF1A"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'def compile_network(env, target, model, start_pack, stop_pack):\n    # \u586B\u5145 shape \u548C\u6570\u636E\u7C7B\u578B\u5B57\u5178\n    dtype_dict = {"data": "float32"}\n    shape_dict = {"data": (env.BATCH, 3, 224, 224)}\n\n    # \u4E0B\u67B6 gluon \u6A21\u578B\uFF0C\u5E76\u8F6C\u6362\u4E3A Relay\n    gluon_model = vision.get_model(model, pretrained=True)\n    mod, params = relay.frontend.from_mxnet(gluon_model, shape_dict)\n\n    # \u66F4\u65B0 shape \u548C\u7C7B\u578B\u5B57\u5178\n    shape_dict.update({k: v.shape for k, v in params.items()})\n    dtype_dict.update({k: str(v.dtype) for k, v in params.items()})\n\n    # \u5728 Relay \u4E2D\u6267\u884C\u91CF\u5316\n    # \u6CE8\u610F\uFF1A\u6211\u4EEC\u5C06 opt_level \u8BBE\u7F6E\u4E3A 3 \u4EE5\u6298\u53E0\u6279\u91CF\u89C4\u8303\n    with relay.build_config(opt_level=3):\n        with relay.quantize.qconfig(global_scale=8.0, skip_conv_layers=[0]):\n            mod = relay.quantize.quantize(mod, params=params)\n\n    # \u5BF9 VTA \u76EE\u6807\u8FDB\u884C\u56FE\u6253\u5305\u548C\u5E38\u91CF\u6298\u53E0\n    if target.device_name == "vta":\n        assert env.BLOCK_IN == env.BLOCK_OUT\n        relay_prog = graph_pack(\n            mod["main"],\n            env.BATCH,\n            env.BLOCK_OUT,\n            env.WGT_WIDTH,\n            start_name=start_pack,\n            stop_name=stop_pack,\n        )\n\n    return relay_prog, params\n'})}),"\n",(0,a.jsx)(t.h1,{id:"\u8BBE\u7F6E\u8C03\u4F18\u9009\u9879",children:"\u8BBE\u7F6E\u8C03\u4F18\u9009\u9879"}),"\n",(0,a.jsx)(t.p,{children:"\u8C03\u4F18\u524D\uFF0C\u9700\u8981\u5E94\u7528\u4E00\u4E9B\u914D\u7F6E\u3002\u8FD9\u91CC\u4EE5 Pynq-Z1 \u677F\u4E3A\u4F8B\uFF1A"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'# Tracker \u4E3B\u673A\u548C\u7AEF\u53E3\u53EF\u4EE5\u7531\u4F60\u7684\u73AF\u5883\u8BBE\u7F6E\ntracker_host = os.environ.get("TVM_TRACKER_HOST", "0.0.0.0")\ntracker_port = int(os.environ.get("TVM_TRACKER_PORT", 9190))\n\n# \u4ECE vta/config/vta_config.json \u6587\u4EF6\u4E2D\u52A0\u8F7D VTA \u53C2\u6570\nenv = vta.get_env()\n\n# \u6B64 target \u7528\u4E8E\u4EA4\u53C9\u7F16\u8BD1\u3002\u53EF\u4EE5\u5728\u4F60\u7684\u8BBE\u5907\u4E0A\u901A\u8FC7\uFF1Acode:`gcc -v` \u6765\u67E5\u8BE2\u3002\n# \u8BBE\u7F6E ``device=arm_cpu`` \u5728 CPU \u4E0A\u8FD0\u884C\u63A8\u7406\n# \u6216\u8005\u8BBE\u7F6E ``device=vta`` \u5728 FPGA \u4E0A\u8FD0\u884C\u63A8\u7406\ndevice = "vta"\ntarget = env.target if device == "vta" else env.target_vta_cpu\n\n# \u8981\u7F16\u8BD1\u7684 Gluon \u6A21\u578B\u7684\u540D\u79F0\n# ``start_pack`` \u548C ``stop_pack`` \u6807\u7B7E\u6307\u793A\u5728\u54EA\u91CC\u5F00\u59CB\u548C\u7ED3\u675F\u56FE\u5F62\u6253\u5305 Relay pass\uFF1A\u6362\u8A00\u4E4B\uFF0C\u4ECE\u54EA\u91CC\u5F00\u59CB\u548C\u7ED3\u675F\u8F6C\u79FB\u5230 VTA\u3002\nnetwork = "resnet50_v2"\nstart_pack = "nn.max_pool2d"\nstop_pack = "nn.global_avg_pool2d"\n\n# \u8C03\u4F18\u9009\u9879\nlog_file = "%s.alu.%s.log" % (device, network)\ntuning_option = {\n    "log_filename": log_file,\n    "tuner": "random",\n    "n_trial": 1000,\n    "early_stopping": None,\n    "measure_option": autotvm.measure_option(\n        builder=autotvm.LocalBuilder(n_parallel=1),\n        runner=autotvm.RPCRunner(\n            env.TARGET,\n            host=tracker_host,\n            port=tracker_port,\n            number=5,\n            timeout=60,\n            # check_correctness=True, # TODO: \u5F53 check_correctness \u518D\u6B21\u8D77\u4F5C\u7528\u65F6\u91CD\u65B0\u542F\u7528\u3002\n        ),\n    ),\n}\n\ndef log_to_file(file_out, protocol="json"):\n    """Log the tuning records into file.\n    The rows of the log are stored in the format of autotvm.record.encode.\n    for lhs == rhs, we add an extra rhs = [] record\n    \u5C06\u8C03\u4F18\u65E5\u5FD7\u8BB0\u5F55\u5230\u6587\u4EF6\u4E2D\u3002\n	\u65E5\u5FD7\u7684\u884C\u4EE5 autotvm.record.encode \u7684\u683C\u5F0F\u5B58\u50A8\u3002\n	\u5BF9\u4E8E lhs == rhs\uFF0C\u6DFB\u52A0\u4E00\u4E2A\u989D\u5916\u7684 rhs = [] \u6765\u8BB0\u5F55\n\n    Parameters\n    \u53C2\u6570\n    ----------\n    file_out : str\n        The file to log to.\n        \u8BB0\u5F55\u7684\u6587\u4EF6\u3002\n    protocol: str, optional\n        The log protocol. Can be \'json\' or \'pickle\'\n        \u65E5\u5FD7\u534F\u8BAE\u3002\u4E3A \'json\' \u6216 \u2019pickle\u2018\u3002\n\n    Returns\n    \u8FD4\u56DE\u503C\n    -------\n    callback : callable\n        Callback function to do the logging.\n        \u5B9E\u73B0\u65E5\u5FD7\u8BB0\u5F55\u7684\u56DE\u8C03\u51FD\u6570\u3002\n    """\n\n    def _callback(_, inputs, results):\n        with open(file_out, "a") as f:\n            for inp, result in zip(inputs, results):\n                f.write(record.encode(inp, result, protocol) + "\\n")\n\n                # \u53EA\u8003\u8651\u5177\u6709\u76F8\u540C lhs \u548C rhs \u7684\u4EFB\u52A1\n                if inp.task.args[0] == inp.task.args[1]:\n                    args = list(inp.task.args)\n                    args[1] = (args[0][0], (), args[0][2])\n                    inp_copy = copy.deepcopy(inp)\n                    inp_copy.task.args = tuple(args)\n                    f.write(record.encode(inp_copy, result, protocol) + "\\n")\n\n    return _callback\n\ndef tune_tasks(\n    tasks,\n    measure_option,\n    tuner="xgb",\n    n_trial=10,\n    early_stopping=None,\n    log_filename="tuning.log",\n    use_transfer_learning=True,\n):\n\n    # \u521B\u5EFA tmp \u65E5\u5FD7\u6587\u4EF6\n    tmp_log_file = log_filename + ".tmp"\n    if os.path.exists(tmp_log_file):\n        os.remove(tmp_log_file)\n\n    for i, tsk in enumerate(reversed(tasks)):\n        prefix = "[Task %2d/%2d] " % (i + 1, len(tasks))\n\n        # \u521B\u5EFA\u8C03\u4F18\u5668\n       if tuner == "xgb":\n            tuner_obj = XGBTuner(tsk, loss_type="reg")\n        elif tuner == "xgb_knob":\n            tuner_obj = XGBTuner(tsk, loss_type="reg", feature_type="knob")\n        elif tuner == "xgb_itervar":\n            tuner_obj = XGBTuner(tsk, loss_type="reg", feature_type="itervar")\n        elif tuner == "xgb_curve":\n            tuner_obj = XGBTuner(tsk, loss_type="reg", feature_type="curve")\n        elif tuner == "xgb_rank":\n            tuner_obj = XGBTuner(tsk, loss_type="rank")\n        elif tuner == "xgb_rank_knob":\n            tuner_obj = XGBTuner(tsk, loss_type="rank", feature_type="knob")\n        elif tuner == "xgb_rank_itervar":\n            tuner_obj = XGBTuner(tsk, loss_type="rank", feature_type="itervar")\n        elif tuner == "xgb_rank_curve":\n            tuner_obj = XGBTuner(tsk, loss_type="rank", feature_type="curve")\n        elif tuner == "xgb_rank_binary":\n            tuner_obj = XGBTuner(tsk, loss_type="rank-binary")\n        elif tuner == "xgb_rank_binary_knob":\n            tuner_obj = XGBTuner(tsk, loss_type="rank-binary", feature_type="knob")\n        elif tuner == "xgb_rank_binary_itervar":\n            tuner_obj = XGBTuner(tsk, loss_type="rank-binary", feature_type="itervar")\n        elif tuner == "xgb_rank_binary_curve":\n            tuner_obj = XGBTuner(tsk, loss_type="rank-binary", feature_type="curve")\n        elif tuner == "ga":\n            tuner_obj = GATuner(tsk, pop_size=50)\n        elif tuner == "random":\n            tuner_obj = RandomTuner(tsk)\n        elif tuner == "gridsearch":\n            tuner_obj = GridSearchTuner(tsk)\n        else:\n            raise ValueError("Invalid tuner: " + tuner)\n\n        if use_transfer_learning:\n            if os.path.isfile(tmp_log_file):\n                tuner_obj.load_history(autotvm.record.load_from_file(tmp_log_file))\n\n        # \u5F00\u59CB\u8C03\u4F18\n        tsk_trial = min(n_trial, len(tsk.config_space))\n        tuner_obj.tune(\n            n_trial=tsk_trial,\n            early_stopping=early_stopping,\n            measure_option=measure_option,\n            callbacks=[\n                autotvm.callback.progress_bar(tsk_trial, prefix=prefix),\n                log_to_file(tmp_log_file),\n            ],\n        )\n\n    # \u9009\u62E9\u6700\u4F73\u8BB0\u5F55\u5230\u7F13\u5B58\u6587\u4EF6\n    autotvm.record.pick_best(tmp_log_file, log_filename)\n    os.remove(tmp_log_file)\n'})}),"\n",(0,a.jsx)(t.p,{children:"\u6CE8\u518C\u7279\u5B9A\u4E8E VTA \u7684\u8C03\u4F18\u4EFB\u52A1"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'def register_vta_tuning_tasks():\n    from tvm.autotvm.task import TaskExtractEnv\n\n    @tvm.te.tag_scope(tag=topi.tag.ELEMWISE)\n    def my_clip(x, a_min, a_max):\n        """Unlike topi\'s current clip, put min and max into two stages."""\n        const_min = tvm.tir.const(a_min, x.dtype)\n        const_max = tvm.tir.const(a_max, x.dtype)\n        x = te.compute(x.shape, lambda *i: tvm.te.min(x(*i), const_max), name="clipA")\n        x = te.compute(x.shape, lambda *i: tvm.te.max(x(*i), const_min), name="clipB")\n        return x\n\n    # \u521D\u59CB\u5316 autotvm \u73AF\u5883\u4EE5\u6CE8\u518C VTA \u7B97\u5B50\n    TaskExtractEnv()\n\n    @autotvm.template("add.vta")\n    def _topi_add(*args, **kwargs):\n        assert not kwargs, "Do not support kwargs in template function call"\n        A, B = args[:2]\n\n        with tvm.target.vta():\n            res = vta.top.op.add_packed(*args, **kwargs)\n            res = my_clip(res, 0, 127)\n            res = topi.cast(res, "int8")\n\n        if tvm.target.Target.current().device_name == "vta":\n            s = vta.top.op.schedule_add_packed([res])\n        else:\n            s = te.create_schedule([res.op])\n        return s, [A, B, res]\n\n    @autotvm.template("multiply.vta")\n    def _topi_multiply(*args, **kwargs):\n        assert not kwargs, "Do not support kwargs in template function call"\n        A, B = args[:2]\n\n        with tvm.target.vta():\n            res = vta.top.op.multiply_packed(*args, **kwargs)\n            res = my_clip(res, 0, 127)\n            res = topi.cast(res, "int8")\n\n        if tvm.target.Target.current().device_name == "vta":\n            s = vta.top.op.schedule_multiply_packed([res])\n        else:\n            s = te.create_schedule([res.op])\n        return s, [A, B, res]\n'})}),"\n",(0,a.jsx)(t.p,{children:"\u6700\u540E\uFF0C\u542F\u52A8\u8C03\u4F18\u4F5C\u4E1A\uFF0C\u5E76\u8BC4\u4F30\u7AEF\u5230\u7AEF\u6027\u80FD\u3002"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'def tune_and_evaluate(tuning_opt):\n\n    if env.TARGET != "intelfocl":\n        print("ALU only op only available for intelfocl target")\n        return\n\n    # \u6CE8\u518C VTA \u8C03\u4F18\u4EFB\u52A1\n    register_vta_tuning_tasks()\n\n    # \u5BF9 Relay \u7A0B\u5E8F\u8FDB\u884C\u4EFB\u52A1\u63D0\u53D6\n    print("Extract tasks...")\n    relay_prog, params = compile_network(env, target, network, start_pack, stop_pack)\n    mod = tvm.IRModule.from_expr(relay_prog)\n    tasks = autotvm.task.extract_from_program(\n        mod,\n        params=params,\n        ops=(\n            relay.op.get("add"),\n            relay.op.get("multiply"),\n        ),\n        target=tvm.target.Target(target, host=env.target_host),\n    )\n\n    # \u8FC7\u6EE4\u6389\u975E\u6253\u5305\u7684 alu \u4EFB\u52A1\n    tasks = list(filter(lambda t: len(t.args[0][1]) > 4, tasks))\n    # \u8FC7\u6EE4\u6389 float alu \u4EFB\u52A1\n    tasks = list(filter(lambda t: t.args[0][2] != "float32", tasks))\n\n    # \u6211\u4EEC\u5E94\u8BE5\u5DF2\u7ECF\u63D0\u53D6\u4E86 10 \u4E2A\u5377\u79EF\u4EFB\u52A1\n    tasks_set = {}\n    print("Extracted {} alu tasks:".format(len(tasks)))\n    for tsk in tasks:\n        print("tsk = ", tsk)\n\n        if len(tsk.args[1][1]) == 0:\n            args = list(tsk.args)\n            args[1] = args[0]\n            tsk.args = tuple(args)\n\n        if (tsk.name, tsk.args) in tasks_set:\n            print("task {} already exists".format(tsk))\n        tasks_set[(tsk.name, tsk.args)] = tsk\n\n    tasks = list(tasks_set.values())\n    print("After merged, final #tasks={}, tasks = {}".format(len(tasks), tasks))\n\n    # \u8FD0\u884C\u8C03\u4F18\u4EFB\u52A1\n    print("Tuning...")\n    tune_tasks(tasks, **tuning_opt)\n\n# \u8FD0\u884C\u8C03\u4F18\u5E76\u8BC4\u4F30\u7ED3\u679C\ntune_and_evaluate(tuning_option)\n'})}),"\n",(0,a.jsx)(t.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"ALU only op only available for intelfocl target\n"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://tvm.apache.org/docs/_downloads/6bbcf342fb9192416b8e1a86a1d4e981/tune_alu_vta.py",children:"\u4E0B\u8F7D Python \u6E90\u4EE3\u7801\uFF1Atune_alu_vta.py"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.a,{href:"https://tvm.apache.org/docs/_downloads/178b6f23dffc01ac92f2cf95f41a5679/tune_alu_vta.ipynb",children:"\u4E0B\u8F7D Jupyter Notebook\uFF1Atune_alu_vta.ipynb"})})]})}function c(n={}){let{wrapper:t}={...(0,o.a)(),...n.components};return t?(0,a.jsx)(t,{...n,children:(0,a.jsx)(u,{...n})}):u(n)}},21494:function(n,t,e){e.d(t,{Z:function(){return i},a:function(){return s}});var r=e(39546);let a={},o=r.createContext(a);function s(n){let t=r.useContext(o);return r.useMemo(function(){return"function"==typeof n?n(t):{...t,...n}},[t,n])}function i(n){let t;return t=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),r.createElement(o.Provider,{value:t},n.children)}}}]);