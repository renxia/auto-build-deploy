"use strict";(self.webpackChunktvm_cn=self.webpackChunktvm_cn||[]).push([["29930"],{65334:function(e,n,a){a.r(n),a.d(n,{default:()=>p,frontMatter:()=>o,metadata:()=>r,assets:()=>d,toc:()=>l,contentTitle:()=>i});var r=JSON.parse('{"id":"how_to/deploy/deploy_models/hugging_face","title":"\u5728 CPU \u4E0A\u90E8\u7F72 Hugging Face \u526A\u679D\u6A21\u578B","description":"\u5355\u51FB \u6B64\u5904 \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801","source":"@site/versioned_docs/version-0.12.0/how_to/deploy/deploy_models/08-hugging_face.md","sourceDirName":"how_to/deploy/deploy_models","slug":"/how_to/deploy/deploy_models/hugging_face","permalink":"/docs/tvm-cn/docs/0.12.0/how_to/deploy/deploy_models/hugging_face","draft":false,"unlisted":false,"editUrl":"https://github.com/hyperai/tvm-cn/edit/master/versioned_docs/version-0.12.0/how_to/deploy/deploy_models/08-hugging_face.md","tags":[],"version":"0.12.0","lastUpdatedBy":"sparanoid","lastUpdatedAt":1744717810000,"sidebarPosition":8,"frontMatter":{"title":"\u5728 CPU \u4E0A\u90E8\u7F72 Hugging Face \u526A\u679D\u6A21\u578B"},"sidebar":"tutorialSidebar","previous":{"title":"\u5728 CUDA \u4E0A\u90E8\u7F72\u91CF\u5316\u6A21\u578B","permalink":"/docs/tvm-cn/docs/0.12.0/how_to/deploy/deploy_models/deploy_quan"},"next":{"title":"\u90E8\u7F72 Single Shot Multibox Detector\uFF08SSD\uFF09\u6A21\u578B","permalink":"/docs/tvm-cn/docs/0.12.0/how_to/deploy/deploy_models/deploy_ssd"}}'),s=a("74132"),t=a("21494");let o={title:"\u5728 CPU \u4E0A\u90E8\u7F72 Hugging Face \u526A\u679D\u6A21\u578B"},i="\u5728 CPU \u4E0A\u90E8\u7F72 Hugging Face \u526A\u679D\u6A21\u578B",d={},l=[{value:"\u52A0\u8F7D\u6240\u9700\u6A21\u5757",id:"\u52A0\u8F7D\u6240\u9700\u6A21\u5757",level:2},{value:"\u914D\u7F6E\u8BBE\u7F6E",id:"\u914D\u7F6E\u8BBE\u7F6E",level:2},{value:"\u4E0B\u8F7D\u548C\u8F6C\u6362 Transformers \u6A21\u578B",id:"\u4E0B\u8F7D\u548C\u8F6C\u6362-transformers-\u6A21\u578B",level:2},{value:"\u8F6C\u6362\u4E3A Relay \u8BA1\u7B97\u56FE",id:"\u8F6C\u6362\u4E3A-relay-\u8BA1\u7B97\u56FE",level:2},{value:"\u8FD0\u884C\u5BC6\u96C6\u8BA1\u7B97\u56FE",id:"\u8FD0\u884C\u5BC6\u96C6\u8BA1\u7B97\u56FE",level:2},{value:"\u8FD0\u884C\u7A00\u758F\u8BA1\u7B97\u56FE",id:"\u8FD0\u884C\u7A00\u758F\u8BA1\u7B97\u56FE",level:2},{value:"\u8FD0\u884C\u6240\u6709\u4EE3\u7801",id:"\u8FD0\u884C\u6240\u6709\u4EE3\u7801",level:2},{value:"\u6837\u672C\u8F93\u51FA",id:"\u6837\u672C\u8F93\u51FA",level:2}];function c(e){let n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",strong:"strong",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"\u5728-cpu-\u4E0A\u90E8\u7F72-hugging-face-\u526A\u679D\u6A21\u578B",children:"\u5728 CPU \u4E0A\u90E8\u7F72 Hugging Face \u526A\u679D\u6A21\u578B"})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["\u5355\u51FB ",(0,s.jsx)(n.a,{href:"https://tvm.apache.org/docs/how_to/deploy_models/deploy_sparse.html#sphx-glr-download-how-to-deploy-models-deploy-sparse-py",children:"\u6B64\u5904"})," \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801"]})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"\u4F5C\u8005"}),"\uFF1A",(0,s.jsx)(n.a,{href:"https://github.com/jwfromm",children:"Josh Fromm"})]}),"\n",(0,s.jsxs)(n.p,{children:["\u672C\u6559\u7A0B\u6F14\u793A\u5982\u4F55\u91C7\u7528\u526A\u679D\u540E\u7684\u6A21\u578B\uFF08\u672C\u4F8B\u4E2D\u6A21\u578B\u662F ",(0,s.jsx)(n.a,{href:"https://huggingface.co/huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad",children:"\u6765\u81EA Hugging Face \u7684 PruneBert"}),"\uFF09\uFF0C\u5E76\u4F7F\u7528 TVM \u6765\u5229\u7528\u6A21\u578B\u7A00\u758F\u652F\u6301\u6765\u52A0\u901F\u3002"]}),"\n",(0,s.jsx)(n.p,{children:"\u5C3D\u7BA1\u672C\u6559\u7A0B\u7684\u4E3B\u8981\u76EE\u7684\u662F\u5728\u5DF2\u7ECF\u4FEE\u526A\u8FC7\u7684\u6A21\u578B\u4E0A\u5B9E\u73B0\u52A0\u901F\uFF0C\u4F46\u8BC4\u4F30\u4FEE\u526A\u540E\u6A21\u578B\u7684\u901F\u5EA6\u4E5F\u5341\u5206\u5FC5\u8981\u3002\u4E3A\u6B64\uFF0C\u6211\u4EEC\u63D0\u4F9B\u4E86\u4E00\u4E2A\u51FD\u6570\u91C7\u7528\u672A\u4FEE\u526A\u7684\u6A21\u578B\uFF0C\u5E76\u5C06\u5176\u6743\u91CD\u66FF\u6362\u4E3A\u6307\u5B9A\u7A00\u758F\u7684\u968F\u673A\u548C\u4FEE\u526A\u6743\u91CD\u3002\u786E\u5B9A\u6A21\u578B\u662F\u5426\u503C\u5F97\u4FEE\u526A\u65F6\uFF0C\u8FD9\u53EF\u80FD\u662F\u4E00\u4E2A\u6709\u7528\u7684\u7279\u6027\u3002"}),"\n",(0,s.jsxs)(n.p,{children:["\u8FDB\u5165\u4EE3\u7801\u524D\u8BA8\u8BBA\u4E00\u4E0B\u7A00\u758F\u548C\u526A\u679D\uFF0C\u5E76\u6DF1\u5165\u7814\u7A76\u4E24\u79CD\u4E0D\u540C\u7C7B\u578B\u7684\u7A00\u758F\uFF1A",(0,s.jsx)(n.strong,{children:"\u7ED3\u6784\u5316"}),"\u548C",(0,s.jsx)(n.strong,{children:"\u975E\u7ED3\u6784\u5316"}),"\u3002"]}),"\n",(0,s.jsx)(n.p,{children:"\u526A\u679D\u662F\u4E00\u79CD\u4E3B\u8981\u901A\u8FC7\u5C06\u6743\u91CD\u503C\u66FF\u6362\u4E3A 0 \u6765\u51CF\u5C0F\u6A21\u578B\u53C2\u6570\u5927\u5C0F\u7684\u6280\u672F\uFF0C\u5C3D\u7BA1\u9009\u62E9\u54EA\u4E9B\u6743\u91CD\u8BBE\u7F6E\u4E3A 0 \u7684\u65B9\u6CD5\u4F17\u591A\uFF0C\u4F46\u6700\u76F4\u63A5\u7684\u65B9\u6CD5\u662F\u9009\u62E9\u5177\u6709\u6700\u5C0F\u503C\u7684\u6743\u91CD\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u901A\u5E38\uFF0C\u6743\u91CD\u4F1A\u88AB\u4FEE\u526A\u4E3A\u6240\u9700\u7684\u7A00\u758F\u767E\u5206\u6BD4\u3002\u4F8B\u5982\uFF0C\u4E00\u4E2A 95% \u7684\u7A00\u758F\u6A21\u578B\u5C06\u53EA\u6709 5% \u7684\u6743\u91CD\u975E\u96F6\u3002\u4FEE\u526A\u6210\u975E\u5E38\u9AD8\u7684\u7A00\u758F\u901A\u5E38\u9700\u8981\u5FAE\u8C03\uFF0C\u6216\u5B8C\u5168\u91CD\u65B0\u8BAD\u7EC3\uFF0C\u56E0\u4E3A\u5B83\u662F\u6709\u635F\u8FD1\u4F3C\u3002\u5C3D\u7BA1\u901A\u8FC7\u7B80\u5355\u7684\u538B\u7F29\u4ECE\u4FEE\u526A\u540E\u7684\u6A21\u578B\u4E2D\u5F88\u5BB9\u6613\u83B7\u5F97\u53C2\u6570\u5927\u5C0F\u7684\u597D\u5904\uFF0C\u4F46\u5229\u7528\u6A21\u578B\u7A00\u758F\u6765\u4EA7\u751F runtime \u52A0\u901F\u66F4\u52A0\u590D\u6742\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u4FEE\u526A\u7ED3\u6784\u5316\u7A00\u758F\u6743\u91CD\u7684\u76EE\u7684\uFF0C\u662F\u628A\u4FEE\u526A\u8FC7\u7684\u6743\u91CD\u805A\u96C6\u5728\u4E00\u8D77\u3002\u6362\u8A00\u4E4B\uFF0C\u7528\u5B83\u4EEC\u7684\u503C\u548C\u4F4D\u7F6E\u8FDB\u884C\u4FEE\u526A\u3002\u5C06\u4FEE\u526A\u540E\u7684\u6743\u91CD\u6346\u7ED1\u5728\u4E00\u8D77\u7684\u597D\u5904\u662F\u5B83\u5141\u8BB8\u8BF8\u5982\u77E9\u9635\u4E58\u6CD5\u4E4B\u7C7B\u7684\u7B97\u6CD5\u8DF3\u8FC7\u6574\u4E2A\u5757\u3002"}),"\n",(0,s.jsxs)(n.p,{children:["\u4E8B\u5B9E\u8BC1\u660E\uFF0C\u5728\u5F53\u4ECA\u53EF\u7528\u7684\u5927\u591A\u6570\u786C\u4EF6\u4E0A\uFF0C\u67D0\u79CD\u7A0B\u5EA6\u7684",(0,s.jsx)(n.em,{children:"\u5757\u7A00\u758F"}),"\u5BF9\u4E8E\u5B9E\u73B0\u663E\u8457\u52A0\u901F\u975E\u5E38\u91CD\u8981\u3002\u8FD9\u662F\u56E0\u4E3A\u5728\u5927\u591A\u6570 CPU \u6216 GPU \u52A0\u8F7D\u5185\u5B58\u65F6\uFF0C\u4E00\u6B21\u8DF3\u8FC7\u8BFB\u53D6\u5355\u4E2A\u503C\u5E76\u4E0D\u4F1A\u8282\u7701\u4EFB\u4F55\u5DE5\u4F5C\uFF0C\u800C\u662F\u4F7F\u7528\u5411\u91CF\u5316\u6307\u4EE4\u4E4B\u7C7B\u7684\u4E1C\u897F\u8BFB\u5165\u5E76\u6267\u884C\u6574\u4E2A\u5757\u3002"]}),"\n",(0,s.jsx)(n.p,{children:"\u975E\u7ED3\u6784\u5316\u7A00\u758F\u6743\u91CD\u662F\u4EC5\u6839\u636E\u539F\u59CB\u6743\u91CD\u503C\u8FDB\u884C\u4FEE\u526A\u7684\u6743\u91CD\uFF0C\u5B83\u4EEC\u770B\u8D77\u6765\u968F\u673A\u5206\u6563\u5728\u6574\u4E2A\u5F20\u91CF\u4E2D\uFF0C\u800C\u975E\u50CF\u5757\u7A00\u758F\u6743\u91CD\u4E2D\u770B\u5230\u7684\u90A3\u6837\u6210\u5757\u3002\u5728\u4F4E\u7A00\u758F\u4E0B\uFF0C\u975E\u7ED3\u6784\u5316\u526A\u679D\u6280\u672F\u5F88\u96BE\u52A0\u901F\u3002\u7136\u800C\uFF0C\u5728\u9AD8\u7A00\u758F\u4E0B\uFF0C\u4F1A\u51FA\u73B0\u8BB8\u591A\u5168 0 \u503C\u7684\u5757\uFF0C\u8FD9\u4F7F\u5F97\u52A0\u901F\u6210\u4E3A\u53EF\u80FD\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u672C\u6559\u7A0B\u5305\u542B\u7ED3\u6784\u5316\u548C\u975E\u7ED3\u6784\u5316\u7A00\u758F\u3002Hugging Face \u7684 PruneBert \u6A21\u578B\u662F\u975E\u7ED3\u6784\u5316\u7684\uFF0C\u4F46 95% \u662F\u7A00\u758F\u7684\uFF0C\u5373\u4F7F\u4E0D\u662F\u6700\u4F18\u7684\uFF0C\u4E5F\u53EF\u4EE5\u5BF9\u5176\u5E94\u7528 TVM \u7684\u5757\u7A00\u758F\u4F18\u5316\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u53EF\u4EE5\u7528\u7ED3\u6784\u5316\u7A00\u758F\u4E3A\u672A\u4FEE\u526A\u6A21\u578B\u751F\u6210\u968F\u673A\u7A00\u758F\u6743\u91CD\u3002\u5C06 PruneBert \u7684\u771F\u5B9E\u901F\u5EA6\u4E0E\u4F7F\u7528\u5047\u6743\u91CD\u7684\u5757\u7A00\u758F\u901F\u5EA6\u6BD4\u8F83\uFF0C\u53EF\u4EE5\u53D1\u73B0\u7ED3\u6784\u5316\u7A00\u758F\u7684\u4F18\u52BF\u3002"}),"\n",(0,s.jsx)(n.h2,{id:"\u52A0\u8F7D\u6240\u9700\u6A21\u5757",children:"\u52A0\u8F7D\u6240\u9700\u6A21\u5757"}),"\n",(0,s.jsx)(n.p,{children:"\u9664\u4E86 TVM\uFF0C\u8FD8\u9700\u8981 scipy\uFF08\u6700\u65B0\u7684 transformers\uFF09\u548C TensorFlow\uFF08\u7248\u672C\u5728 2.2 \u4EE5\u4E0A\uFF09\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\nimport tvm\nimport time\nimport itertools\nimport numpy as np\nimport tensorflow as tf\nfrom tvm import relay, runtime\nfrom tvm.contrib import graph_executor\nfrom tvm.relay import data_dep_optimization as ddo\nfrom tensorflow.python.framework.convert_to_constants import (\n    convert_variables_to_constants_v2,\n)\nimport scipy.sparse as sp\n\n# \u8981\u6C42 TensorFlow \u5C06\u5176 GPU \u5185\u5B58\u9650\u5236\u4E3A\u5B9E\u9645\u9700\u8981\u7684\u5185\u5B58\n# \u800C\u4E0D\u662F\u4EFB\u5176\u6D88\u8017\u5176\u4ED6\u5185\u5B58\u3002\n# https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n# \u8FD9\u6837\u5BF9 sphinx-gallery \u66F4\u53CB\u597D\u4E00\u70B9\u3002\ngpus = tf.config.list_physical_devices("GPU")\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print("tensorflow will use experimental.set_memory_growth(True)")\n    except RuntimeError as e:\n        print("experimental.set_memory_growth option is not available: {}".format(e))\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u914D\u7F6E\u8BBE\u7F6E",children:"\u914D\u7F6E\u8BBE\u7F6E"}),"\n",(0,s.jsx)(n.p,{children:"\u4ECE\u53C2\u6570\u5F00\u59CB\uFF0C\u5B9A\u4E49\u8981\u8FD0\u884C\u7684\u6A21\u578B\u7C7B\u578B\u548C\u7A00\u758F\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# \u8981\u4E0B\u8F7D\u548C\u8FD0\u884C\u7684 transformer \u6A21\u578B\u7684\u540D\u79F0\nname = "huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad"\n# \u8F93\u5165\u7684 batches \u6570\u76EE\nbatch_size = 1\n# \u6BCF\u4E2A\u8F93\u5165\u5E8F\u5217\u7684\u957F\u5EA6\u3002\nseq_len = 128\n# TVM \u5E73\u53F0\u6807\u8BC6\u7B26\u3002\u6CE8\u610F\uFF0C\u53EF\u4EE5\u901A\u8FC7\u8BBE\u7F6E -mcpu \u6765\u5B9E\u73B0\u6700\u4F73 CPU \u6027\u80FD\n# \u9002\u5408\u7279\u5B9A\u673A\u5668\uFF0C\u8FD8\u652F\u6301 CUDA \u548C ROCm\u3002\ntarget = "llvm"\n# \u5728\u54EA\u4E2A\u8BBE\u5907\u4E0A\u8FD0\u884C\uFF0Ctvm.cpu() \u6216 tvm.cuda() \u3002\n# \u5982\u679C\u4E3A True\uFF0C\u5219\u5C06\u8FD0\u884C\u7F51\u7EDC\u7684\u7A00\u758F\u53D8\u4F53\uFF0C\u5E76\u8FDB\u884C benchmark \u6D4B\u8BD5\u3002\nmeasure_sparse = True\n# \u7ED3\u6784\u5316\u7A00\u758F\u5757\u5927\u5C0F\u8F6C\u6362\u6743\u91CD\u5F20\u91CF\n\uFF03 \u8FDB\u5165\u3002\u66F4\u6539\u6B64\u53C2\u6570\u53EF\u80FD\u4F1A\u63D0\u9AD8\u67D0\u4E9B\u5E73\u53F0\u7684\u901F\u5EA6\u3002\nbs_r = 1\n# \u5BF9\u4E8E\u9664 PruneBert\uFF0895% \u7A00\u758F\uFF09\u4EE5\u5916\u7684\u6A21\u578B\uFF0C\u6B64\u53C2\u6570\n# \u786E\u5B9A\u751F\u6210\u7684\u6743\u91CD\u7A00\u758F\uFF0C\u503C\u8D8A\u5927\uFF0C\u7A00\u758F\u8D8A\u9AD8\uFF0C\u7ED3\u679C\u8D8A\u5FEB\u3002\nsparsity = 0.85\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u4E0B\u8F7D\u548C\u8F6C\u6362-transformers-\u6A21\u578B",children:"\u4E0B\u8F7D\u548C\u8F6C\u6362 Transformers \u6A21\u578B"}),"\n",(0,s.jsx)(n.p,{children:"\u4E0B\u9762\u4ECE transformers \u6A21\u5757\u83B7\u53D6\u4E00\u4E2A\u6A21\u578B\uFF0C\u4E0B\u8F7D\u5E76\u8F6C\u6362\u4E3A TensorFlow graphdef\uFF0C\u5C06\u8BE5 graphdef \u8F6C\u6362\u4E3A\u53EF\u4EE5\u4F18\u5316\u548C\u90E8\u7F72\u7684 Relay \u8BA1\u7B97\u56FE\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def load_keras_model(module, name, seq_len, batch_size, report_runtime=True):\n    model = module.from_pretrained(name)\n    dummy_input = tf.keras.Input(shape=[seq_len], batch_size=batch_size, dtype="int32")\n    dummy_out = model(dummy_input)  # \u901A\u8FC7 Keras \u6A21\u578B\u4F20\u64AD shape\u3002\n    if report_runtime:\n        np_input = np.random.uniform(size=[batch_size, seq_len], low=0, high=seq_len).astype(\n            "int32"\n        )\n        start = time.time()\n        repeats = 50\n        for i in range(repeats):\n            np_out = model(np_input)\n        end = time.time()\n        print("Keras Runtime: %f ms." % (1000 * ((end - start) / repeats)))\n    return model\n\ndef convert_to_graphdef(model, batch_size, seq_len):\n    model_func = tf.function(lambda x: model(x))\n    input_dict = model._saved_model_inputs_spec\n    input_spec = input_dict[list(input_dict.keys())[0]]\n    model_func = model_func.get_concrete_function(\n        tf.TensorSpec([batch_size, seq_len], input_spec.dtype)\n    )\n    frozen_func = convert_variables_to_constants_v2(model_func)\n    return frozen_func.graph.as_graph_def()\n\ndef download_model(name, batch_size, seq_len):\n    import transformers\n\n    module = getattr(transformers, "TFBertForSequenceClassification")\n    model = load_keras_model(module, name=name, batch_size=batch_size, seq_len=seq_len)\n    return convert_to_graphdef(model, batch_size, seq_len)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u8F6C\u6362\u4E3A-relay-\u8BA1\u7B97\u56FE",children:"\u8F6C\u6362\u4E3A Relay \u8BA1\u7B97\u56FE"}),"\n",(0,s.jsx)(n.p,{children:"\u76EE\u524D\u6709\u5F88\u591A\u5DE5\u5177\u53EF\u4EE5\u83B7\u5F97\u6B63\u786E\u683C\u5F0F\u7684 transformers \u6A21\u578B\uFF0C\u4ECE\u800C\u8FDB\u884C Relay \u8F6C\u6362\u3002\u4E0B\u9762\u7684\u51FD\u6570\u5C06\u5BFC\u5165\u7684\u8BA1\u7B97\u56FE\u4FDD\u5B58\u4E3A Relay \u7684 json \u683C\u5F0F\uFF0C\u8FD9\u6837\u5C31\u4E0D\u5FC5\u5728\u6BCF\u6B21\u8FD0\u884C\u6B64\u811A\u672C\u65F6\u4ECE TensorFlow \u91CD\u65B0\u5BFC\u5165\u4E86\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def import_graphdef(\n    name,\n    batch_size,\n    seq_len,\n    save_relay=True,\n    relay_file="model.json",\n    relay_params="model.params",\n):\n    abs_path = os.path.dirname(os.path.abspath(__file__))\n    shape_dict = {"input_1": (batch_size, seq_len)}\n    relay_file = ("%s_%d_%d_%s" % (name, batch_size, seq_len, relay_file)).replace("/", "_")\n    relay_params = ("%s_%d_%d_%s" % (name, batch_size, seq_len, relay_params)).replace("/", "_")\n    if os.path.exists(os.path.join(abs_path, relay_file)) and os.path.exists(\n        os.path.join(abs_path, relay_params)\n    ):\n        with open(os.path.join(abs_path, relay_file), "r") as fi:\n            mod = tvm.ir.load_json(fi.read())\n        with open(os.path.join(abs_path, relay_params), "rb") as fi:\n            params = relay.load_param_dict(fi.read())\n    else:\n        graph_def = download_model(name, batch_size, seq_len)\n\n        mod, params = relay.frontend.from_tensorflow(graph_def, shape=shape_dict)\n\n        if save_relay:\n            with open(os.path.join(abs_path, relay_file), "w") as fo:\n                fo.write(tvm.ir.save_json(mod))\n            with open(os.path.join(abs_path, relay_params), "wb") as fo:\n                fo.write(runtime.save_param_dict(params))\n\n    return mod, dict(params.items()), shape_dict\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u8FD0\u884C\u5BC6\u96C6\u8BA1\u7B97\u56FE",children:"\u8FD0\u884C\u5BC6\u96C6\u8BA1\u7B97\u56FE"}),"\n",(0,s.jsx)(n.p,{children:"\u8FD0\u884C\u5BFC\u5165\u6A21\u578B\u7684\u9ED8\u8BA4\u7248\u672C\u3002\u6CE8\u610F\uFF0C\u5373\u4F7F\u6743\u91CD\u662F\u7A00\u758F\u7684\uFF0C\u4E5F\u4E0D\u4F1A\u770B\u5230\u4EFB\u4F55\u52A0\u901F\uFF0C\u56E0\u4E3A\u5728\u8FD9\u4E9B\u5BC6\u96C6\uFF08\u4F46\u5927\u90E8\u5206\u4E3A\u96F6\uFF09\u5F20\u91CF\u4E0A\u4F7F\u7528\u7684\u662F\u5E38\u89C4\u5BC6\u96C6\u77E9\u9635\u4E58\u6CD5\uFF0C\u800C\u975E\u7A00\u758F\u611F\u77E5\u5185\u6838\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def run_relay_graph(mod, params, shape_dict, target, dev):\n    with relay.build_config(opt_level=3):\n        lib = relay.build(mod, target=target, params=params)\n    input_shape = shape_dict["input_1"]\n    dummy_data = np.random.uniform(size=input_shape, low=0, high=input_shape[1]).astype("int32")\n\n    m = graph_executor.GraphModule(lib["default"](dev))\n    m.set_input(0, dummy_data)\n    m.run()\n    tvm_output = m.get_output(0)\n\n    print(m.benchmark(dev, repeat=5, number=5))\n    return tvm_output\n\ndef run_dense(mod, params, shape_dict, target, dev):\n    print("Dense Model Benchmark:")\n    return run_relay_graph(mod, params, shape_dict, target, dev)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u8FD0\u884C\u7A00\u758F\u8BA1\u7B97\u56FE",children:"\u8FD0\u884C\u7A00\u758F\u8BA1\u7B97\u56FE"}),"\n",(0,s.jsx)(n.p,{children:"\u63A5\u4E0B\u6765\u628A\u8BA1\u7B97\u56FE\u8F6C\u6362\u4E3A\u7A00\u758F\u8868\u793A\uFF0C\u5E76\u5728\u9700\u8981\u65F6\u751F\u6210\u5047\u7684\u7A00\u758F\u6743\u91CD\u3002\u7136\u540E\u7528\u4E0E dense \u76F8\u540C\u7684 benchmark \u6D4B\u8BD5\u811A\u672C\u6765\u6D4B\u8BD5\u901F\u5EA6\uFF01\u5BF9\u8BA1\u7B97\u56FE\u5E94\u7528\u4E00\u4E9B Relay pass\uFF0C\u4ECE\u800C\u5229\u7528\u7A00\u758F\u3002"}),"\n",(0,s.jsx)(n.p,{children:"\u9996\u5148\u7528 simple_fc_transpose \u5C06\u5BC6\u96C6\u5C42\u7684\u6743\u91CD\u8F6C\u7F6E\u5230\u53C2\u6570\u4E2D\uFF0C\u4FBF\u4E8E\u77E9\u9635\u4E58\u6CD5\u8F6C\u6362\u4E3A\u7A00\u758F\u7248\u672C\u3002\u63A5\u4E0B\u6765\u5E94\u7528 bsr_dense.convert \u6765\u8BC6\u522B\u6240\u6709\u53EF\u4EE5\u7A00\u758F\u7684\u6743\u91CD\u77E9\u9635\uFF0C\u5E76\u81EA\u52A8\u66FF\u6362\u5B83\u4EEC\u3002"}),"\n",(0,s.jsxs)(n.p,{children:["\u4E0B\u9762\u7684 bsr_dense.convert \u51FD\u6570\u901A\u8FC7\u68C0\u67E5 sparse_threshold \u767E\u5206\u6BD4\u7A00\u758F\uFF0C\u8BC6\u522B\u6A21\u578B\u4E2D\u7684\u54EA\u4E9B\u6743\u91CD\u53EF\u4EE5\u53D8\u5F97\u7A00\u758F\uFF0C\u5E76\u5C06\u8FD9\u4E9B\u6743\u91CD\u8F6C\u6362\u4E3A ",(0,s.jsx)(n.em,{children:"Block Compressed Row Format (BSR)"}),"\u3002"]}),"\n",(0,s.jsx)(n.p,{children:"BSR \u672C\u8D28\u4E0A\u662F\u4E00\u79CD\u5BF9\u5F20\u91CF\u7684 nonzero chunks \u8FDB\u884C\u7D22\u5F15\u7684\u8868\u793A\uFF0C\u4F7F\u7B97\u6CD5\u53EF\u4EE5\u8F7B\u677E\u52A0\u8F7D\u90A3\u4E9B nonzero chunks\uFF0C\u5E76\u5FFD\u7565\u5F20\u91CF\u7684\u5176\u4F59\u90E8\u5206\u3002\u4E00\u65E6\u7A00\u758F\u6743\u91CD\u91C7\u7528 BSR \u683C\u5F0F\uFF0C\u5C31\u4F1A\u5E94\u7528 relay.transform.DenseToSparse\uFF0C\u5B9E\u9645\u4E0A\u662F\u7528 relay.sparse_dense \u51FD\u6570\u6765\u66FF\u6362 relay.dense \u64CD\u4F5C\uFF0C\u4ECE\u800C\u8FD0\u884C\u66F4\u5FEB\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def random_bsr_matrix(M, N, BS_R, BS_C, density, dtype="float32"):\n    Y = np.zeros((M, N), dtype=dtype)\n    assert M % BS_R == 0\n    assert N % BS_C == 0\n    nnz = int(density * M * N)\n    num_blocks = int(nnz / (BS_R * BS_C)) + 1\n    candidate_blocks = np.asarray(list(itertools.product(range(0, M, BS_R), range(0, N, BS_C))))\n    assert candidate_blocks.shape[0] == M // BS_R * N // BS_C\n    chosen_blocks = candidate_blocks[\n        np.random.choice(candidate_blocks.shape[0], size=num_blocks, replace=False)\n    ]\n    for i in range(len(chosen_blocks)):\n        r, c = chosen_blocks[i]\n        Y[r : r + BS_R, c : c + BS_C] = np.random.uniform(-0.1, 0.1, (BS_R, BS_C))\n    s = sp.bsr_matrix(Y, blocksize=(BS_R, BS_C))\n    assert s.data.shape == (num_blocks, BS_R, BS_C)\n    assert s.data.size >= nnz\n    assert s.indices.shape == (num_blocks,)\n    assert s.indptr.shape == (M // BS_R + 1,)\n    return s.todense()\n\ndef random_sparse_bert_params(func, params, density, BS_R, BS_C):\n    def deepcopy(param_dic):\n        ret = {}\n        for k, v in param_dic.items():\n            ret[k] = tvm.nd.array(v.numpy())\n        return ret\n\n    new_params = deepcopy(params)\n    dense_weight_names = relay.analysis.sparse_dense._search_dense_op_weight(func)\n    for item in dense_weight_names:\n        name = str(item)\n        shape = new_params[name].shape\n        if shape[0] % BS_R == 0 and shape[1] % BS_C == 0:\n            new_w = random_bsr_matrix(shape[0], shape[1], BS_R, BS_C, density)\n            new_params[name] = tvm.nd.array(new_w)\n    return new_params\n\ndef run_sparse(mod, params, shape_dict, target, dev, bs_r, sparsity, gen_weights):\n    mod, params = ddo.simplify_fc_transpose.convert(mod["main"], params)\n    if gen_weights:\n        params = random_sparse_bert_params(mod, params, BS_R=bs_r, BS_C=1, density=1 - sparsity)\n    mod, params = ddo.bsr_dense.convert(mod, params, (bs_r, 1), sparsity_threshold=0.8)\n    print("Block Sparse Model with {blocksize}x1 blocks:".format(blocksize=bs_r))\n    return run_relay_graph(mod, params, shape_dict, target, dev)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u8FD0\u884C\u6240\u6709\u4EE3\u7801",children:"\u8FD0\u884C\u6240\u6709\u4EE3\u7801"}),"\n",(0,s.jsx)(n.p,{children:"\u8C03\u7528\u6240\u6709\u9700\u8981\u7684\u51FD\u6570\uFF0C\u6839\u636E\u8BBE\u7F6E\u7684\u53C2\u6570\u5BF9\u6A21\u578B\u8FDB\u884C benchmark \u6D4B\u8BD5\u3002\u6CE8\u610F\uFF0C\u8FD0\u884C\u8FD9\u4E2A\u4EE3\u7801\uFF0C\u9996\u5148\u9700\u8981\u53D6\u6D88\u6700\u540E\u4E00\u884C\u7684\u6CE8\u91CA\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def benchmark():\n    mod, params, shape_dict = import_graphdef(name, batch_size, seq_len)\n    run_dense(mod, params, shape_dict, target, dev)\n    if measure_sparse:\n        gen_weights = "prune" not in name\n        run_sparse(mod, params, shape_dict, target, dev, bs_r, sparsity, gen_weights)\n\n# benchmark()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"\u6837\u672C\u8F93\u51FA",children:"\u6837\u672C\u8F93\u51FA"}),"\n",(0,s.jsx)(n.p,{children:"\u53EF\u53C2\u8003\u4E0B\u9762\u5728 AMD CPU \u4E0A\u8FD0\u884C\u7684\u811A\u672C\u8F93\u51FA\uFF0C\u663E\u793A\u7528\u7A00\u758F\u6A21\u578B\u53EF\u63D0\u9AD8\u7EA6 2.5 \u500D\u7684\u901F\u5EA6\u3002"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Dense Model Benchmark:\n# Cannot find config for target=llvm, workload=('dense_nopack.x86', ('TENSOR', (1, 768), 'float32'), ('TENSOR', (2, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=llvm, workload=('dense_nopack.x86', ('TENSOR', (1, 768), 'float32'), ('TENSOR', (768, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=llvm, workload=('dense_nopack.x86', ('TENSOR', (128, 3072), 'float32'), ('TENSOR', (768, 3072), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=llvm, workload=('dense_nopack.x86', ('TENSOR', (128, 768), 'float32'), ('TENSOR', (3072, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=llvm, workload=('dense_nopack.x86', ('TENSOR', (128, 768), 'float32'), ('TENSOR', (768, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=llvm, workload=('batch_matmul.x86', ('TENSOR', (12, 128, 128), 'float32'), ('TENSOR', (12, 64, 128), 'float32')). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=llvm, workload=('batch_matmul.x86', ('TENSOR', (12, 128, 64), 'float32'), ('TENSOR', (12, 128, 64), 'float32')). A fallback configuration is used, which may bring great performance regression.\n# Runtime:             165.26 ms           (12.83 ms)\n# Block Sparse Model with 1x1 blocks:\n# Runtime:             67.75 ms            (8.83 ms)\n\n# Here is the output of this script on a GPU (GTX 1070) with the target \"cuda -libs=cublas\".\n#\n# Dense Model Benchmark:\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('dense_cublas.cuda', ('TENSOR', (1, 768), 'float32'), ('TENSOR', (2, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('dense_cublas.cuda', ('TENSOR', (1, 768), 'float32'), ('TENSOR', (768, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('dense_cublas.cuda', ('TENSOR', (128, 3072), 'float32'), ('TENSOR', (768, 3072), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('dense_cublas.cuda', ('TENSOR', (128, 768), 'float32'), ('TENSOR', (3072, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('dense_cublas.cuda', ('TENSOR', (128, 768), 'float32'), ('TENSOR', (768, 768), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('batch_matmul_cublas.cuda', ('TENSOR', (12, 128, 128), 'float32'), ('TENSOR', (12, 64, 128), 'float32'), (12, 128, 64)). A fallback configuration is used, which may bring great performance regression.\n# Cannot find config for target=cuda -keys=cuda,gpu -libs=cublas -max_num_threads=1024 -thread_warp_size=32, workload=('batch_matmul_cublas.cuda', ('TENSOR', (12, 128, 64), 'float32'), ('TENSOR', (12, 128, 64), 'float32'), (12, 128, 128)). A fallback configuration is used, which may bring great performance regression.\n# Runtime:             10.64 ms            (0.29 ms)\n# Block Sparse Model with 1x1 blocks:\n# Runtime:             6.46 ms             (0.05 ms)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://tvm.apache.org/docs/_downloads/9c3764c88ab3eb57dc223b4eda1e8a2f/deploy_sparse.py",children:"\u4E0B\u8F7D Python \u6E90\u4EE3\u7801\uFF1Adeploy_sparse.py"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://tvm.apache.org/docs/_downloads/0b60295044fd20226a0d5adc52b50b2f/deploy_sparse.ipynb",children:"\u4E0B\u8F7D Jupyter Notebook\uFF1Adeploy_sparse.ipynb"})})]})}function p(e={}){let{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},21494:function(e,n,a){a.d(n,{Z:function(){return i},a:function(){return o}});var r=a(39546);let s={},t=r.createContext(s);function o(e){let n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);