"use strict";(self.webpackChunktvm_cn=self.webpackChunktvm_cn||[]).push([["63869"],{73751:function(a,e,n){n.r(e),n.d(e,{default:()=>s,frontMatter:()=>l,metadata:()=>r,assets:()=>t,toc:()=>c,contentTitle:()=>x});var r=JSON.parse('{"id":"how_to/autoscheduler/autoschedule_x86","title":"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC","description":"\u5355\u51FB \u6B64\u5904 \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801","source":"@site/docs/how_to/autoscheduler/02-autoschedule_x86.md","sourceDirName":"how_to/autoscheduler","slug":"/how_to/autoscheduler/autoschedule_x86","permalink":"/docs/tvm-cn/docs/how_to/autoscheduler/autoschedule_x86","draft":false,"unlisted":false,"editUrl":"https://github.com/hyperai/tvm-cn/edit/master/docs/how_to/autoscheduler/02-autoschedule_x86.md","tags":[],"version":"current","lastUpdatedBy":"sparanoid","lastUpdatedAt":1744717810000,"sidebarPosition":2,"frontMatter":{"title":"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC"},"sidebar":"tutorialSidebar","previous":{"title":"\u4E3A GPU \u81EA\u52A8\u8C03\u5EA6\u5377\u79EF\u5C42","permalink":"/docs/tvm-cn/docs/how_to/autoscheduler/autoschedule_gpu"},"next":{"title":"\u4E3A NVIDIA GPU \u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC","permalink":"/docs/tvm-cn/docs/how_to/autoscheduler/autoschedule_nvidia"}}'),d=n("74132"),o=n("21494");let l={title:"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC"},x="\u4E3A x86 CPU \u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC",t={},c=[{value:"\u5B9A\u4E49\u7F51\u7EDC",id:"\u5B9A\u4E49\u7F51\u7EDC",level:2},{value:"\u63D0\u53D6\u641C\u7D22\u4EFB\u52A1",id:"\u63D0\u53D6\u641C\u7D22\u4EFB\u52A1",level:2},{value:"\u5F00\u59CB\u8C03\u4F18",id:"\u5F00\u59CB\u8C03\u4F18",level:2},{value:"\u7F16\u8BD1\u53CA\u8BC4\u4F30",id:"\u7F16\u8BD1\u53CA\u8BC4\u4F30",level:2},{value:"\u5176\u4ED6\u6280\u5DE7",id:"\u5176\u4ED6\u6280\u5DE7",level:2}];function i(a){let e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...a.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(e.header,{children:(0,d.jsx)(e.h1,{id:"\u4E3A-x86-cpu-\u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC",children:"\u4E3A x86 CPU \u81EA\u52A8\u8C03\u5EA6\u795E\u7ECF\u7F51\u7EDC"})}),"\n",(0,d.jsx)(e.admonition,{type:"note",children:(0,d.jsxs)(e.p,{children:["\u5355\u51FB ",(0,d.jsx)(e.a,{href:"https://tvm.apache.org/docs/how_to/tune_with_autoscheduler/tune_network_x86.html#sphx-glr-download-how-to-tune-with-autoscheduler-tune-network-x86-py",children:"\u6B64\u5904"})," \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801"]})}),"\n",(0,d.jsxs)(e.p,{children:[(0,d.jsx)(e.strong,{children:"\u4F5C\u8005"}),"\uFF1A",(0,d.jsx)(e.a,{href:"https://github.com/merrymercy",children:"Lianmin Zheng"}),"\uFF0C",(0,d.jsx)(e.a,{href:"https://github.com/jcf94/",children:"Chengfan Jia"})]}),"\n",(0,d.jsx)(e.p,{children:"\u9488\u5BF9\u7279\u5B9A\u8BBE\u5907\u548C\u5DE5\u4F5C\u8D1F\u8F7D\u81EA\u52A8\u8C03\u4F18\uFF0C\u5BF9\u4E8E\u83B7\u53D6\u6700\u4F73\u6027\u80FD\u81F3\u5173\u91CD\u8981\u3002\u672C\u6587\u4ECB\u7ECD\u5982\u4F55\u4F7F\u7528 auto-scheduler \u4E3A x86 CPU \u8C03\u4F18\u6574\u4E2A\u795E\u7ECF\u7F51\u7EDC\u3002"}),"\n",(0,d.jsx)(e.p,{children:"\u4E3A\u81EA\u52A8\u8C03\u4F18\u795E\u7ECF\u7F51\u7EDC\uFF0C\u5C06\u7F51\u7EDC\u5212\u5206\u4E3A\u5C0F\u7684\u5B50\u56FE\u5E76\u72EC\u7ACB\u8C03\u4F18\u3002\u6BCF\u4E2A\u5B50\u56FE\u88AB\u89C6\u4E3A\u4E00\u4E2A\u641C\u7D22\u4EFB\u52A1\uFF0C\u4EFB\u52A1\u8C03\u5EA6\u5668\u5BF9\u65F6\u95F4\u8FDB\u884C\u5207\u7247\u5E76\u52A8\u6001\u5730\u4E3A\u8FD9\u4E9B\u4EFB\u52A1\u5206\u914D\u65F6\u95F4\u8D44\u6E90\uFF0C\u5E76\u9884\u6D4B\u6BCF\u4E2A\u4EFB\u52A1\u5BF9\u7AEF\u5230\u7AEF\u6267\u884C\u65F6\u95F4\u7684\u5F71\u54CD\uFF0C\u4F18\u5148\u8003\u8651\u6700\u80FD\u51CF\u5C11\u6267\u884C\u65F6\u95F4\u7684\u4EFB\u52A1\u3002"}),"\n",(0,d.jsxs)(e.p,{children:["\u5BF9\u4E8E\u6BCF\u4E2A\u5B50\u56FE\uFF0C\u4F7F\u7528 ",(0,d.jsx)(e.code,{children:"tvm/python/topi"})," \u4E2D\u7684\u8BA1\u7B97\u58F0\u660E\u6765\u83B7\u53D6\u5F20\u91CF\u8868\u8FBE\u5F0F\u5F62\u5F0F\u7684\u8BA1\u7B97 DAG\u3002\u7136\u540E\u4F7F\u7528 auto-scheduler \u6765\u6784\u5EFA\u8FD9\u4E2A DAG \u7684\u641C\u7D22\u7A7A\u95F4\u5E76\u641C\u7D22\u5408\u9002\u7684\u8C03\u5EA6\uFF08\u5E95\u5C42\u4F18\u5316\uFF09\u3002"]}),"\n",(0,d.jsxs)(e.p,{children:["\u4E0E\u57FA\u4E8E\u6A21\u677F\u7684 ",(0,d.jsx)(e.a,{href:"/docs/how_to/autotune",children:"AutoTVM"}),"\uFF08\u4F9D\u8D56\u624B\u52A8\u6A21\u677F\u6765\u5B9A\u4E49\u641C\u7D22\u7A7A\u95F4\u7684\uFF09 \u4E0D\u540C\uFF0Cauto-scheduler \u4E0D\u9700\u8981\u4EFB\u4F55\u8C03\u5EA6\u6A21\u677F\u3002\u6362\u8A00\u4E4B\uFF0Cauto-scheduler \u53EA\u4F7F\u7528 ",(0,d.jsx)(e.code,{children:"tvm/python/topi"})," \u4E2D\u7684\u8BA1\u7B97\u58F0\u660E\uFF0C\u4E0D\u4F7F\u7528\u73B0\u6709\u7684\u8C03\u5EA6\u6A21\u677F\u3002"]}),"\n",(0,d.jsxs)(e.p,{children:["\u6CE8\u610F\uFF0C\u672C\u6559\u7A0B\u65E0\u6CD5\u5728 Windows \u6216\u6700\u65B0\u7248\u672C\u7684 macOS \u4E0A\u8FD0\u884C\u3002\u5982\u9700\u8FD0\u884C\uFF0C\u8BF7\u5C06\u672C\u6559\u7A0B\u7684\u4E3B\u4F53\u653E\u5728 ",(0,d.jsx)(e.code,{children:'if __name__ == "__main__":'})," \u4EE3\u7801\u5757\u4E2D\u3002"]}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-python",children:"import numpy as np\n\nimport tvm\nfrom tvm import relay, auto_scheduler\nfrom tvm.relay import data_dep_optimization as ddo\nimport tvm.relay.testing\nfrom tvm.contrib import graph_executor\n"})}),"\n",(0,d.jsx)(e.h2,{id:"\u5B9A\u4E49\u7F51\u7EDC",children:"\u5B9A\u4E49\u7F51\u7EDC"}),"\n",(0,d.jsxs)(e.p,{children:["\u9996\u5148\uFF0C\u8981\u4F7F\u7528 Relay \u524D\u7AEF API \u5B9A\u4E49\u7F51\u7EDC\u3002\u53EF\u4EE5\u4ECE ",(0,d.jsx)(e.code,{children:"tvm.relay.testing"})," \u52A0\u8F7D\u4E00\u4E9B\u9884\u5B9A\u4E49\u7684\u7F51\u7EDC\u3002\u4E5F\u53EF\u4EE5\u4ECE MXNet\u3001ONNX\u3001PyTorch \u548C TensorFlow \u52A0\u8F7D\u6A21\u578B\uFF08\u53C2\u89C1 ",(0,d.jsx)(e.a,{href:"/docs/how_to/compile",children:"\u524D\u7AEF\u6559\u7A0B"})," \uFF09\u3002"]}),"\n",(0,d.jsxs)(e.p,{children:["\u5BF9\u4E8E\u5377\u79EF\u795E\u7ECF\u7F51\u7EDC\uFF0C\u5C3D\u7BA1 auto-scheduler \u53EF\u4EE5\u5728\u4EFB\u4F55\u5E03\u5C40\u4E0B\u6B63\u5E38\u8FD0\u884C\uFF0C\u4F46\u901A\u8FC7 NHWC \u5E03\u5C40\u5B9E\u73B0\u7684\u6027\u80FD\u6700\u4F73\u3002auto-scheduler \u5BF9 NHWC \u5E03\u5C40\u8FDB\u884C\u4E86\u5F88\u591A\u4F18\u5316\uFF0C\u56E0\u6B64\u63A8\u8350\u5C06\u6A21\u578B\u8F6C\u6362\u4E3A NHWC \u5E03\u5C40\uFF0C\u4ECE\u800C\u5F97\u4EE5\u4F7F\u7528 auto-scheduler\u3002\u53EF\u7528 ",(0,d.jsx)(e.a,{href:"https://tvm.apache.org/docs/arch/convert_layout.html#convert-layout-usage",children:"ConvertLayout"})," pass \u5728 TVM \u4E2D\u8FDB\u884C\u5E03\u5C40\u8F6C\u6362\u3002"]}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-python",children:'def get_network(name, batch_size, layout="NHWC", dtype="float32", use_sparse=False):\n    """Get the symbol definition and random weight of a network"""\n\n    # auto-scheduler \u66F4\u9002\u5408 NHWC \u5E03\u5C40\n    if layout == "NHWC":\n        image_shape = (224, 224, 3)\n    elif layout == "NCHW":\n        image_shape = (3, 224, 224)\n    else:\n        raise ValueError("Invalid layout: " + layout)\n\n    input_shape = (batch_size,) + image_shape\n    output_shape = (batch_size, 1000)\n\n    if name.startswith("resnet-"):\n        n_layer = int(name.split("-")[1])\n        mod, params = relay.testing.resnet.get_workload(\n            num_layers=n_layer,\n            batch_size=batch_size,\n            layout=layout,\n            dtype=dtype,\n            image_shape=image_shape,\n        )\n    elif name.startswith("resnet3d-"):\n        n_layer = int(name.split("-")[1])\n        mod, params = relay.testing.resnet.get_workload(\n            num_layers=n_layer,\n            batch_size=batch_size,\n            layout=layout,\n            dtype=dtype,\n            image_shape=image_shape,\n        )\n    elif name == "mobilenet":\n        mod, params = relay.testing.mobilenet.get_workload(\n            batch_size=batch_size, layout=layout, dtype=dtype, image_shape=image_shape\n        )\n    elif name == "squeezenet_v1.1":\n        assert layout == "NCHW", "squeezenet_v1.1 only supports NCHW layout"\n        mod, params = relay.testing.squeezenet.get_workload(\n            version="1.1",\n            batch_size=batch_size,\n            dtype=dtype,\n            image_shape=image_shape,\n        )\n    elif name == "inception_v3":\n        input_shape = (batch_size, 3, 299, 299) if layout == "NCHW" else (batch_size, 299, 299, 3)\n        mod, params = relay.testing.inception_v3.get_workload(batch_size=batch_size, dtype=dtype)\n    elif name == "mxnet":\n        # MXNet \u6A21\u578B\u7684\u793A\u4F8B\n        from mxnet.gluon.model_zoo.vision import get_model\n        assert layout == "NCHW"\n\n        block = get_model("resnet50_v1", pretrained=True)\n        mod, params = relay.frontend.from_mxnet(block, shape={"data": input_shape}, dtype=dtype)\n        net = mod["main"]\n        net = relay.Function(\n            net.params, relay.nn.softmax(net.body), None, net.type_params, net.attrs\n        )\n        mod = tvm.IRModule.from_expr(net)\n    elif name == "mlp":\n        mod, params = relay.testing.mlp.get_workload(\n            batch_size=batch_size, dtype=dtype, image_shape=image_shape, num_classes=1000\n        )\n    else:\n        raise ValueError("Network not found.")\n\n    if use_sparse:\n        from tvm.topi.sparse.utils import convert_model_dense_to_sparse\n\n        mod, params = convert_model_dense_to_sparse(mod, params, bs_r=4, random_params=True)\n\n    return mod, params, input_shape, output_shape\n\n# \u5B9A\u4E49\u795E\u7ECF\u7F51\u7EDC\u548C\u7F16\u8BD1 target\u3002\n# \u82E5 target \u673A\u5668\u652F\u6301 avx512 \u6307\u4EE4\uFF0C\n# \u4F7F\u7528 "llvm -mcpu=skylake-avx512" \u66FF\u6362 "llvm -mcpu=core-avx2"\nnetwork = "resnet-50"\nuse_sparse = False\nbatch_size = 1\nlayout = "NHWC"\ntarget = tvm.target.Target("llvm -mcpu=core-avx2")\ndtype = "float32"\nlog_file = "%s-%s-B%d-%s.json" % (network, layout, batch_size, target.kind.name)\n'})}),"\n",(0,d.jsx)(e.h2,{id:"\u63D0\u53D6\u641C\u7D22\u4EFB\u52A1",children:"\u63D0\u53D6\u641C\u7D22\u4EFB\u52A1"}),"\n",(0,d.jsxs)(e.p,{children:["\u63A5\u4E0B\u6765\uFF0C\u4ECE\u7F51\u7EDC\u4E2D\u63D0\u53D6\u641C\u7D22\u4EFB\u52A1\u53CA\u5176\u6743\u91CD\u3002\u4EFB\u52A1\u7684\u6743\u91CD\u662F\u4EFB\u52A1\u7684\u5B50\u56FE\u5728\u6574\u4E2A\u7F51\u7EDC\u4E2D\u51FA\u73B0\u7684\u6B21\u6570\u3002\u901A\u8FC7\u4F7F\u7528\u6743\u91CD\uFF0C\u53EF\u4EE5\u5C06\u7F51\u7EDC\u7684\u7AEF\u5230\u7AEF\u5EF6\u8FDF\u8FD1\u4F3C\u4E3A ",(0,d.jsx)(e.code,{children:"sum(latency[t] * weight[t])"}),"\uFF0C\u5176\u4E2D ",(0,d.jsx)(e.code,{children:"latency[t]"})," \u662F\u4EFB\u52A1\u7684\u5EF6\u8FDF\uFF0C\u800C ",(0,d.jsx)(e.code,{children:"weight[t]"})," \u662F\u4EFB\u52A1\u7684\u6743\u91CD\uFF0C\u4EFB\u52A1\u8C03\u5EA6\u5668\u4EC5\u9488\u5BF9\u8BE5\u76EE\u6807\u8FDB\u884C\u4F18\u5316\u3002"]}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-python",children:'# \u4ECE\u7F51\u7EDC\u4E2D\u63D0\u53D6\u4EFB\u52A1\nprint("Get model...")\nmod, params, input_shape, output_shape = get_network(\n    network,\n    batch_size,\n    layout,\n    dtype=dtype,\n    use_sparse=use_sparse,\n)\nprint("Extract tasks...")\ntasks, task_weights = auto_scheduler.extract_tasks(mod["main"], params, target)\n\nfor idx, task in enumerate(tasks):\n    print("========== Task %d  (workload key: %s) ==========" % (idx, task.workload_key))\n    print(task.compute_dag)\n'})}),"\n",(0,d.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-bash",children:'Get model...\nExtract tasks...\n/workspace/python/tvm/driver/build_module.py:268: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n  "target_host parameter is going to be deprecated. "\n========== Task 0  (workload key: ["8654f16aeddf785bad9f028164b3a48d", [1, 56, 56, 64], [1, 1, 64, 256], [1, 56, 56, 256]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 64]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 64, 256]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\n\n========== Task 1  (workload key: ["b9a4f9bd1416ba25810cb3de27628ace", [1, 14, 14, 256], [1, 1, 256, 1024], [1, 14, 14, 1024], [1, 1, 1, 1024], [1, 14, 14, 1024]]) ==========\nplaceholder = PLACEHOLDER [1, 14, 14, 256]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 256, 1024]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 14, 14, 1024]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\nplaceholder = PLACEHOLDER [1, 1, 1, 1024]\nT_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 2  (workload key: ["12cb81d4ad0a81be02dedf09d1ac8391", [1, 14, 14, 256], [1, 1, 256, 1024], [1, 14, 14, 1024], [1, 14, 14, 1024]]) ==========\nplaceholder = PLACEHOLDER [1, 14, 14, 256]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 256, 1024]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 14, 14, 1024]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\n\n========== Task 3  (workload key: ["56af7508fbcdf6d851892b1e8434667b", [1, 14, 14, 1024], [1, 1, 1024, 512], [1, 1, 1, 512], [1, 7, 7, 512]]) ==========\nplaceholder = PLACEHOLDER [1, 14, 14, 1024]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 1024, 512]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 512]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 4  (workload key: ["06f578e6519a86e85028eecf4de64b25", [1, 56, 56, 256], [1, 1, 256, 512], [1, 28, 28, 512]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 256]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 256, 512]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\n\n========== Task 5  (workload key: ["c68f92478eb18145106184c587d212b6", [1, 14, 14, 256], [6, 6, 256, 256], [1, 1, 1, 256], [1, 14, 14, 256]]) ==========\nplaceholder = PLACEHOLDER [1, 14, 14, 256]\ndata_pad(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 15)) && (i2 >= 1)) && (i2 < 15)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)\ninput_tile(eps, nu, p, ci) = data_pad[floordiv(p, 16), ((floormod(floordiv(p, 4), 4)*4) + eps), ((floormod(p, 4)*4) + nu), ci]\nB(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 6) == 5)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 6) == 4)),  ..(OMITTED)..  (floormod(j, 6) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 6) == 0)), 1f, 0f))))))))))))))))))))))))))))))))))))\ndata_pack(eps, nu, p, ci) += ((input_tile[r_a, r_b, p, ci]*B[r_a, eps])*B[r_b, nu])\nplaceholder = PLACEHOLDER [6, 6, 256, 256]\nbgemm(eps, nu, p, co) += (data_pack[eps, nu, p, ci]*placeholder[eps, nu, co, ci])\nA(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 4) == 3)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 4) == 2)),  ..(OMITTED)..  6) == 0) && (floormod(j, 4) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 4) == 0)), 1f, 0f))))))))))))))))))))))))\ninverse(vh, vw, p, co) += ((bgemm[r_a, r_b, p, co]*A[r_a, vh])*A[r_b, vw])\nconv2d_winograd(n, h, w, co) = inverse[floormod(h, 4), floormod(w, 4), ((((n*4)*4) + (floordiv(h, 4)*4)) + floordiv(w, 4)), co]\nplaceholder = PLACEHOLDER [1, 1, 1, 256]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_winograd[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 6  (workload key: ["1037be767e8e18197e87653d81c34558", [1, 14, 14, 1024], [1, 1, 1024, 256], [1, 1, 1, 256], [1, 14, 14, 256]]) ==========\nplaceholder = PLACEHOLDER [1, 14, 14, 1024]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 1024, 256]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 256]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 7  (workload key: ["12cb81d4ad0a81be02dedf09d1ac8391", [1, 28, 28, 128], [1, 1, 128, 512], [1, 28, 28, 512], [1, 28, 28, 512]]) ==========\nplaceholder = PLACEHOLDER [1, 28, 28, 128]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 128, 512]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 28, 28, 512]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\n\n========== Task 8  (workload key: ["12cb81d4ad0a81be02dedf09d1ac8391", [1, 56, 56, 64], [1, 1, 64, 256], [1, 56, 56, 256], [1, 56, 56, 256]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 64]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 64, 256]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 56, 56, 256]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\n\n========== Task 9  (workload key: ["ecec634b4882c5731f86cce3109db636", [1, 28, 28, 128], [6, 6, 128, 128], [1, 1, 1, 128], [1, 28, 28, 128]]) ==========\nplaceholder = PLACEHOLDER [1, 28, 28, 128]\ndata_pad(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 29)) && (i2 >= 1)) && (i2 < 29)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)\ninput_tile(eps, nu, p, ci) = data_pad[floordiv(p, 49), ((floormod(floordiv(p, 7), 7)*4) + eps), ((floormod(p, 7)*4) + nu), ci]\nB(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 6) == 5)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 6) == 4)),  ..(OMITTED)..  (floormod(j, 6) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 6) == 0)), 1f, 0f))))))))))))))))))))))))))))))))))))\ndata_pack(eps, nu, p, ci) += ((input_tile[r_a, r_b, p, ci]*B[r_a, eps])*B[r_b, nu])\nplaceholder = PLACEHOLDER [6, 6, 128, 128]\nbgemm(eps, nu, p, co) += (data_pack[eps, nu, p, ci]*placeholder[eps, nu, co, ci])\nA(i, j) = select(((floormod(i, 6) == 5) && (floormod(j, 4) == 3)), 1f, select(((floormod(i, 6) == 5) && (floormod(j, 4) == 2)),  ..(OMITTED)..  6) == 0) && (floormod(j, 4) == 1)), 0f, select(((floormod(i, 6) == 0) && (floormod(j, 4) == 0)), 1f, 0f))))))))))))))))))))))))\ninverse(vh, vw, p, co) += ((bgemm[r_a, r_b, p, co]*A[r_a, vh])*A[r_b, vw])\nconv2d_winograd(n, h, w, co) = inverse[floormod(h, 4), floormod(w, 4), ((((n*7)*7) + (floordiv(h, 4)*7)) + floordiv(w, 4)), co]\nplaceholder = PLACEHOLDER [1, 1, 1, 128]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_winograd[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 10  (workload key: ["d7b65649a4dd54becea0a52aabbc5af5", [1, 1000], [1, 1000]]) ==========\nplaceholder = PLACEHOLDER [1, 1000]\nT_softmax_maxelem(i0) max= placeholder[i0, k]\nT_softmax_exp(i0, i1) = tir.exp((placeholder[i0, i1] - T_softmax_maxelem[i0]))\nT_softmax_expsum(i0) += T_softmax_exp[i0, k]\nT_softmax_norm(i0, i1) = (T_softmax_exp[i0, i1]/T_softmax_expsum[i0])\n\n========== Task 11  (workload key: ["69115f188984ae34ede37c3b8ca40b43", [1, 7, 7, 2048], [1, 1, 1, 2048]]) ==========\nplaceholder = PLACEHOLDER [1, 7, 7, 2048]\ntensor(ax0, ax1, ax2, ax3) += placeholder[ax0, ((ax1*7) + rv0), ((ax2*7) + rv1), ax3]\ntensor(ax0, ax1, ax2, ax3) = (tensor[ax0, ax1, ax2, ax3]/(float32((select((bool)1, ((ax1 + 1)*7), (((ax1 + 1)*7) + 1)) - (ax1*7)))*float32((select((bool)1, ((ax2 + 1)*7), (((ax2 + 1)*7) + 1)) - (ax2*7)))))\n\n========== Task 12  (workload key: ["12cb81d4ad0a81be02dedf09d1ac8391", [1, 7, 7, 512], [1, 1, 512, 2048], [1, 7, 7, 2048], [1, 7, 7, 2048]]) ==========\nplaceholder = PLACEHOLDER [1, 7, 7, 512]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 512, 2048]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 7, 7, 2048]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\n\n========== Task 13  (workload key: ["1037be767e8e18197e87653d81c34558", [1, 28, 28, 512], [1, 1, 512, 128], [1, 1, 1, 128], [1, 28, 28, 128]]) ==========\nplaceholder = PLACEHOLDER [1, 28, 28, 512]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 512, 128]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 128]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 14  (workload key: ["56af7508fbcdf6d851892b1e8434667b", [1, 28, 28, 512], [1, 1, 512, 256], [1, 1, 1, 256], [1, 14, 14, 256]]) ==========\nplaceholder = PLACEHOLDER [1, 28, 28, 512]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 512, 256]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 256]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 15  (workload key: ["06f578e6519a86e85028eecf4de64b25", [1, 28, 28, 512], [1, 1, 512, 1024], [1, 14, 14, 1024]]) ==========\nplaceholder = PLACEHOLDER [1, 28, 28, 512]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 512, 1024]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\n\n========== Task 16  (workload key: ["1037be767e8e18197e87653d81c34558", [1, 7, 7, 2048], [1, 1, 2048, 512], [1, 1, 1, 512], [1, 7, 7, 512]]) ==========\nplaceholder = PLACEHOLDER [1, 7, 7, 2048]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 2048, 512]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 512]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 17  (workload key: ["1037be767e8e18197e87653d81c34558", [1, 56, 56, 256], [1, 1, 256, 64], [1, 1, 1, 64], [1, 56, 56, 64]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 256]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 256, 64]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 64]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 18  (workload key: ["b9a4f9bd1416ba25810cb3de27628ace", [1, 56, 56, 64], [1, 1, 64, 256], [1, 56, 56, 256], [1, 1, 1, 256], [1, 56, 56, 256]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 64]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 64, 256]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 56, 56, 256]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\nplaceholder = PLACEHOLDER [1, 1, 1, 256]\nT_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 19  (workload key: ["b9a4f9bd1416ba25810cb3de27628ace", [1, 28, 28, 128], [1, 1, 128, 512], [1, 28, 28, 512], [1, 1, 1, 512], [1, 28, 28, 512]]) ==========\nplaceholder = PLACEHOLDER [1, 28, 28, 128]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 128, 512]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 28, 28, 512]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\nplaceholder = PLACEHOLDER [1, 1, 1, 512]\nT_add(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 20  (workload key: ["86551f1a74663d3ceafd5884659d3478", [1, 7, 7, 512], [3, 3, 512, 512], [1, 1, 1, 512], [1, 7, 7, 512]]) ==========\nplaceholder = PLACEHOLDER [1, 7, 7, 512]\npad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 8)) && (i2 >= 1)) && (i2 < 8)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)\nplaceholder = PLACEHOLDER [3, 3, 512, 512]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 512]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 21  (workload key: ["86551f1a74663d3ceafd5884659d3478", [1, 56, 56, 64], [3, 3, 64, 64], [1, 1, 1, 64], [1, 56, 56, 64]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 64]\npad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 1) && (i1 < 57)) && (i2 >= 1)) && (i2 < 57)), placeholder[i0, (i1 - 1), (i2 - 1), i3], 0f)\nplaceholder = PLACEHOLDER [3, 3, 64, 64]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 64]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 22  (workload key: ["56af7508fbcdf6d851892b1e8434667b", [1, 56, 56, 256], [1, 1, 256, 128], [1, 1, 1, 128], [1, 28, 28, 128]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 256]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 256, 128]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 128]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 23  (workload key: ["ff5ea7f814e5c497bb685e7385cf7159", [1, 7, 7, 512], [1, 1, 512, 2048], [1, 7, 7, 2048], [1, 1, 1, 2048], [1, 1, 1, 2048], [1, 7, 7, 2048]]) ==========\nplaceholder = PLACEHOLDER [1, 7, 7, 512]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 512, 2048]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 7, 7, 2048]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, ax1, ax2, ax3])\nplaceholder = PLACEHOLDER [1, 1, 1, 2048]\nT_multiply(ax0, ax1, ax2, ax3) = (T_add[ax0, ax1, ax2, ax3]*placeholder[ax0, 0, 0, ax3])\nplaceholder = PLACEHOLDER [1, 1, 1, 2048]\nT_add(ax0, ax1, ax2, ax3) = (T_multiply[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 24  (workload key: ["96daaa9daa1b41bc383b7c05ce8b58de", [1, 224, 224, 3], [7, 7, 3, 64], [1, 1, 1, 64], [1, 112, 112, 64]]) ==========\nplaceholder = PLACEHOLDER [1, 224, 224, 3]\npad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i1 >= 3) && (i1 < 227)) && (i2 >= 3)) && (i2 < 227)), placeholder[i0, (i1 - 3), (i2 - 3), i3], 0f)\nplaceholder = PLACEHOLDER [7, 7, 3, 64]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 64]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 25  (workload key: ["06f578e6519a86e85028eecf4de64b25", [1, 14, 14, 1024], [1, 1, 1024, 2048], [1, 7, 7, 2048]]) ==========\nplaceholder = PLACEHOLDER [1, 14, 14, 1024]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 1024, 2048]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, ((yy*2) + ry), ((xx*2) + rx), rc]*placeholder[ry, rx, rc, ff])\n\n========== Task 26  (workload key: ["7d44c6e3c81cd80f61ff2265b2bae89a", [1, 2048], [1000, 2048], [1, 1000], [1, 1000]]) ==========\nplaceholder = PLACEHOLDER [1, 2048]\nplaceholder = PLACEHOLDER [1000, 2048]\nT_matmul_NT(i, j) += (placeholder[i, k]*placeholder[j, k])\nplaceholder = PLACEHOLDER [1, 1000]\nT_add(ax0, ax1) = (T_matmul_NT[ax0, ax1] + placeholder[ax0, ax1])\n\n========== Task 27  (workload key: ["64b98c71af70a904fdbb81d7d4188d84", [1, 112, 112, 64], [1, 1, 1, 64], [1, 56, 56, 64]]) ==========\nplaceholder = PLACEHOLDER [1, 112, 112, 64]\npad_temp(ax0, ax1, ax2, ax3) = tir.if_then_else(((((ax1 >= 1) && (ax1 < 113)) && (ax2 >= 1)) && (ax2 < 113)), placeholder[ax0, (ax1 - 1), (ax2 - 1), ax3], -3.40282e+38f)\ntensor(ax0, ax1, ax2, ax3) max= pad_temp[ax0, ((ax1*2) + rv0), ((ax2*2) + rv1), ax3]\nplaceholder = PLACEHOLDER [1, 1, 1, 64]\nT_add(ax0, ax1, ax2, ax3) = (tensor[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n\n========== Task 28  (workload key: ["1037be767e8e18197e87653d81c34558", [1, 56, 56, 64], [1, 1, 64, 64], [1, 1, 1, 64], [1, 56, 56, 64]]) ==========\nplaceholder = PLACEHOLDER [1, 56, 56, 64]\npad_temp(i0, i1, i2, i3) = placeholder[i0, i1, i2, i3]\nplaceholder = PLACEHOLDER [1, 1, 64, 64]\nconv2d_nhwc(nn, yy, xx, ff) += (pad_temp[nn, (yy + ry), (xx + rx), rc]*placeholder[ry, rx, rc, ff])\nplaceholder = PLACEHOLDER [1, 1, 1, 64]\nT_add(ax0, ax1, ax2, ax3) = (conv2d_nhwc[ax0, ax1, ax2, ax3] + placeholder[ax0, 0, 0, ax3])\nT_relu(ax0, ax1, ax2, ax3) = max(T_add[ax0, ax1, ax2, ax3], 0f)\n'})}),"\n",(0,d.jsx)(e.h2,{id:"\u5F00\u59CB\u8C03\u4F18",children:"\u5F00\u59CB\u8C03\u4F18"}),"\n",(0,d.jsx)(e.p,{children:"\u63A5\u4E0B\u6765\u4E3A\u8C03\u4F18\u548C\u542F\u52A8\u641C\u7D22\u4EFB\u52A1\u8BBE\u7F6E\u4E00\u4E9B\u9009\u9879"}),"\n",(0,d.jsxs)(e.ul,{children:["\n",(0,d.jsxs)(e.li,{children:[(0,d.jsx)(e.code,{children:"num_measure_trials"})," \u662F\u8C03\u4F18\u671F\u95F4\u53EF\u4EE5\u4F7F\u7528\u7684\u6D4B\u8BD5\u6B21\u6570\uFF08\u6839\u636E\u81EA\u5DF1\u7684\u65F6\u95F4\u9884\u7B97\u8C03\u6574\u8FD9\u4E2A\u53C2\u6570\uFF09\uFF0C\u82E5\u8981\u8FDB\u884C\u5FEB\u901F\u6F14\u793A\uFF0C\u53EF\u5C06\u5176\u8BBE\u7F6E\u4E3A\u8F83\u5C0F\u7684\u6570\u5B57\uFF08\u4F8B\u5982 200\uFF09\u3002\u63A8\u8350\u5C06\u5176\u8BBE\u7F6E\u4E3A ",(0,d.jsx)(e.code,{children:"800 * len(tasks)"})," \u5DE6\u53F3\uFF0C\u4EE5\u4FBF\u4F7F\u641C\u7D22\u6536\u655B\u3002\u6BD4\u5982 ResNet-50 \u6709 29 \u4E2A\u4EFB\u52A1\uFF0C\u6240\u4EE5\u53EF\u4EE5\u8BBE\u7F6E\u4E3A 20000\u3002"]}),"\n",(0,d.jsxs)(e.li,{children:["\u6B64\u5916\uFF0C\u4F7F\u7528 ",(0,d.jsx)(e.code,{children:"RecordToFile"})," \u5C06\u6D4B\u8BD5\u8BB0\u5F55\u8F6C\u50A8\u5230\u65E5\u5FD7\u6587\u4EF6\u4E2D\uFF0C\u6D4B\u8BD5\u8BB0\u5F55\u53EF\u7528\u4E8E\u5386\u53F2\u6700\u4F73\u67E5\u8BE2\u3001\u6062\u590D\u641C\u7D22\u4EE5\u53CA\u8FDB\u884C\u540E\u7EED\u5206\u6790\u3002"]}),"\n",(0,d.jsxs)(e.li,{children:["\u66F4\u591A\u53C2\u6570\u53C2\u89C1 ",(0,d.jsx)(e.code,{children:"auto_scheduler.TuningOptions"}),"\uFF0C",(0,d.jsx)(e.code,{children:"auto_scheduler.LocalRunner"}),"\u3002"]}),"\n"]}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-python",children:'def run_tuning():\n    print("Begin tuning...")\n    tuner = auto_scheduler.TaskScheduler(tasks, task_weights)\n    tune_option = auto_scheduler.TuningOptions(\n        num_measure_trials=200,  # \u5C06\u6B64\u66F4\u6539\u4E3A 20000 \u4EE5\u8FBE\u5230\u6700\u4F73\u6027\u80FD\n        runner=auto_scheduler.LocalRunner(repeat=10, enable_cpu_cache_flush=True),\n        measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n    )\n\n    if use_sparse:\n        from tvm.topi.sparse.utils import sparse_sketch_rules\n\n        search_policy = [\n            auto_scheduler.SketchPolicy(\n                task,\n                program_cost_model=auto_scheduler.XGBModel(),\n                init_search_callbacks=sparse_sketch_rules(),\n            )\n            for task in tasks\n        ]\n\n        tuner.tune(tune_option, search_policy=search_policy)\n    else:\n        tuner.tune(tune_option)\n\n# \u4E0D\u5728\u7F51\u9875\u670D\u52A1\u5668\u4E2D\u8FD0\u884C\u8C03\u4F18\uFF0C\u56E0\u4E3A\u5B83\u9700\u8981\u7684\u65F6\u95F4\u592A\u957F\u3002\n# \u53D6\u6D88\u6CE8\u91CA\u8FD0\u884C\u4EE5\u4E0B\u884C\u3002\n# run_tuning()\n'})}),"\n",(0,d.jsxs)(e.admonition,{type:"note",children:[(0,d.jsx)(e.p,{children:"\u89E3\u91CA\u8C03\u4F18\u8FC7\u7A0B\u4E2D\u6253\u5370\u7684\u4FE1\u606F"}),(0,d.jsx)(e.p,{children:"\u5728\u8C03\u4F18\u8FC7\u7A0B\u4E2D\uFF0C\u63A7\u5236\u53F0\u4E0A\u4F1A\u6253\u5370\u5F88\u591A\u7528\u4E8E\u8C03\u8BD5\u7684\u4FE1\u606F\uFF0C\u6700\u91CD\u8981\u7684\u4FE1\u606F\u662F\u4EFB\u52A1\u8C03\u5EA6\u7A0B\u5E8F\u7684\u8F93\u51FA\uFF0C\u4E0B\u8868\u662F\u8F93\u51FA\u793A\u4F8B\u3002"}),(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-bash",children:"----------------------------------------------------------------------\n------------------------------  [ Task Scheduler ]\n----------------------------------------------------------------------\n|  ID  | Latency (ms) | Speed (GFLOPS) | Trials |\n-------------------------------------------------\n|    0 |        0.010 |           0.40 |     64 |\n|    1 |        0.087 |          47.19 |     64 |\n|    2 |        0.008 |          -0.00 |     64 |\n|    3 |        0.177 |         582.07 |     64 |\n|    4 |        0.268 |         862.37 |    256 |\n|    5 |        0.166 |         621.13 |    128 |\n|    6 |        0.170 |         605.10 |    128 |\n|    7 |        0.128 |         403.20 |     64 |\n|    8 |        0.189 |         545.71 |     64 |\n|    9 |        0.231 |        1001.01 |    448 |\n|   10 |        0.155 |         664.80 |    256 |\n|   11 |        0.155 |         662.86 |    256 |\n|   12 |        0.119 |         434.08 |     64 |\n|   13 |        0.199 |         522.13 |     64 |\n|   14 |        0.235 |         986.56 |    320 |\n|   15 |        0.149 |         689.13 |    128 |\n|   16 |        0.155 |         664.80 |    192 |\n|   17 |        0.151 |         340.64 |     64 |\n|   18 |        0.176 |         597.55 |    128 |\n|   19 |        0.220 |        1054.37 |    192 |\n|   20 |        0.150 |         686.01 |    128 |\n|   21 |        0.159 |         650.88 |    128 |\n|   22 |        0.073 |         358.19 |     64 |\n|   23 |        0.031 |          70.63 |     64 |\n|   24 |        0.251 |         947.73 |    128 |\n|   25 |        0.157 |         652.47 |    128 |\n|   26 |        0.215 |         954.84 |    128 |\n|   27 |        0.237 |         868.92 |    128 |\n|   28 |        0.266 |         774.06 |    128 |\n-------------------------------------------------\nEstimated total latency: 10.016 ms      Trials: 3992    Used time : 1131 s      Next ID: 15\n"})}),(0,d.jsx)(e.p,{children:"\u6B64\u8868\u5217\u51FA\u4E86\u6240\u6709\u4EFB\u52A1\u7684\u5EF6\u8FDF\u548C\uFF08\u9884\u4F30\uFF09\u901F\u5EA6\uFF0C\u8FD8\u5217\u51FA\u4E86\u6240\u6709\u4EFB\u52A1\u7684\u6D4B\u8BD5\u5206\u914D\u3002\u6700\u540E\u4E00\u884C\u6253\u5370\u4E86\u8FD9\u4E9B\u4EFB\u52A1\u7684\u603B\u52A0\u6743\u5EF6\u8FDF\uFF0C\u53EF\u4EE5\u7C97\u7565\u4F30\u8BA1\u7F51\u7EDC\u7684\u7AEF\u5230\u7AEF\u6267\u884C\u65F6\u95F4\u3002\u6700\u540E\u4E00\u884C\u8FD8\u6253\u5370\u4E86\u6D4B\u8BD5\u7684\u603B\u6570\u3001\u81EA\u52A8\u8C03\u4F18\u6240\u82B1\u8D39\u7684\u603B\u65F6\u95F4\u4EE5\u53CA\u4E0B\u4E00\u4E2A\u8981\u8C03\u4F18\u7684\u4EFB\u52A1\u7684 ID\u3002"}),(0,d.jsx)(e.p,{children:"\u8FD8\u6709\u4E00\u4E9B\u300Ctvm::Error\u300D\u9519\u8BEF\uFF0C\u56E0\u4E3A auto-scheduler \u4F1A\u5C1D\u8BD5\u4E00\u4E9B\u65E0\u6548\u7684\u8C03\u5EA6\u3002\u82E5\u8C03\u4F18\u7EE7\u7EED\u8FD0\u884C\uFF0C\u5219\u53EF\u4EE5\u5FFD\u7565\u8FD9\u4E9B\u9519\u8BEF\uFF0C\u56E0\u4E3A\u8FD9\u4E9B\u9519\u8BEF\u4E0E\u4E3B\u8FDB\u7A0B\u9694\u79BB\u3002"})]}),"\n",(0,d.jsxs)(e.admonition,{type:"note",children:[(0,d.jsx)(e.p,{children:"\u63D0\u524D\u7EC8\u6B62\u8C03\u4F18"}),(0,d.jsx)(e.p,{children:"\u53EF\u4EE5\u901A\u8FC7\u5F3A\u5236\u7EC8\u6B62\u6B64\u8FDB\u7A0B\u6765\u63D0\u524D\u7EC8\u6B62\u8C03\u4F18\uFF0C\u53EA\u8981\u5728\u65E5\u5FD7\u6587\u4EF6\u4E2D\u4E3A\u6BCF\u4E2A\u4EFB\u52A1\u83B7\u5F97\u81F3\u5C11\u4E00\u4E2A\u6709\u6548\u7684\u8C03\u5EA6\uFF0C\u5C31\u80FD\u591F\u8FDB\u884C\u7F16\u8BD1\uFF08\u4E0B\u9762\u7684\u90E8\u5206\uFF09\u3002"})]}),"\n",(0,d.jsx)(e.h2,{id:"\u7F16\u8BD1\u53CA\u8BC4\u4F30",children:"\u7F16\u8BD1\u53CA\u8BC4\u4F30"}),"\n",(0,d.jsx)(e.p,{children:"\u81EA\u52A8\u8C03\u4F18\u540E\uFF0C\u53EF\u4EE5\u7528\u627E\u5230\u7684\u6700\u4F73\u8C03\u5EA6\u6765\u7F16\u8BD1\u7F51\u7EDC\u3002\u5728\u81EA\u52A8\u8C03\u4F18\u671F\u95F4\uFF0C\u6240\u6709\u6D4B\u8BD5\u8BB0\u5F55\u90FD\u88AB\u8F6C\u50A8\u5230\u65E5\u5FD7\u6587\u4EF6\u4E2D\uFF0C\u53EF\u4EE5\u8BFB\u53D6\u65E5\u5FD7\u6587\u4EF6\u52A0\u8F7D\u6700\u4F73\u8C03\u5EA6\u3002"}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-python",children:'# \u7528\u5386\u53F2\u6700\u4F73\u7F16\u8BD1\nprint("Compile...")\nwith auto_scheduler.ApplyHistoryBest(log_file):\n    with tvm.transform.PassContext(opt_level=3, config={"relay.backend.use_auto_scheduler": True}):\n        lib = relay.build(mod, target=target, params=params)\n\n# \u521B\u5EFA\u56FE\u6267\u884C\u5668\ndev = tvm.device(str(target), 0)\nmodule = graph_executor.GraphModule(lib["default"](dev))\ndata_tvm = tvm.nd.array((np.random.uniform(size=input_shape)).astype(dtype))\nmodule.set_input("data", data_tvm)\n\n# \u8BC4\u4F30\nprint("Evaluate inference time cost...")\nprint(module.benchmark(dev, repeat=3, min_repeat_ms=500))\n'})}),"\n",(0,d.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,d.jsx)(e.pre,{children:(0,d.jsx)(e.code,{className:"language-bash",children:'Compile...\n/workspace/python/tvm/driver/build_module.py:268: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n  "target_host parameter is going to be deprecated. "\nEvaluate inference time cost...\nExecution time summary:\n mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)\n  762.1013     761.7971     762.8241     761.6828      0.5132\n'})}),"\n",(0,d.jsx)(e.h2,{id:"\u5176\u4ED6\u6280\u5DE7",children:"\u5176\u4ED6\u6280\u5DE7"}),"\n",(0,d.jsxs)(e.ol,{children:["\n",(0,d.jsx)(e.li,{children:"\u5728\u8C03\u4F18\u8FC7\u7A0B\u4E2D\uFF0Cauto-scheduler \u9700\u8981\u7F16\u8BD1\u8BB8\u591A\u7A0B\u5E8F\u5E76\u4ECE\u4E2D\u63D0\u53D6\u7279\u5F81\u3002\u8FD9\u90E8\u5206\u4F1A\u5360\u7528\u5927\u91CF CPU \u8D44\u6E90\uFF0C\u6240\u4EE5\u63A8\u8350\u4F7F\u7528\u591A\u6838\u7684\u9AD8\u6027\u80FD CPU\uFF0C\u52A0\u5FEB\u641C\u7D22\u901F\u5EA6\u3002"}),"\n",(0,d.jsxs)(e.li,{children:["\u53EF\u4EE5\u4F7F\u7528 ",(0,d.jsx)(e.code,{children:"python3 -m tvm.auto_scheduler.measure_record --mode distill -i log.json"})," \u63D0\u53D6\u5927\u65E5\u5FD7\u6587\u4EF6\u5E76\u4EC5\u4FDD\u5B58\u6700\u6709\u7528\u7684\u8BB0\u5F55\u3002"]}),"\n",(0,d.jsxs)(e.li,{children:["\u53EF\u4EE5\u4ECE\u4EE5\u524D\u7684\u65E5\u5FD7\u6587\u4EF6\u6062\u590D\u641C\u7D22\uFF0C\u53EA\u9700\u8981\u5728\u51FD\u6570 ",(0,d.jsx)(e.code,{children:"run_tuning"})," \u4E2D\u521B\u5EFA\u4EFB\u52A1\u8C03\u5EA6\u7A0B\u5E8F\u65F6\u6DFB\u52A0\u4E00\u4E2A\u65B0\u53C2\u6570 ",(0,d.jsx)(e.code,{children:"load_log_file"}),"\u3002\u6BD4\u5982\uFF0C",(0,d.jsx)(e.code,{children:"tuner = auto_scheduler.TaskScheduler(tasks, task_weights, load_log_file=log_file)"})]}),"\n",(0,d.jsxs)(e.li,{children:["\u82E5\u6709\u591A\u4E2A target CPU\uFF0C\u5219\u53EF\u4EE5\u5C06\u6240\u6709\u8FD9\u4E9B CPU \u7528\u4E8E\u5E76\u884C\u5316\u6D4B\u8BD5\u3002\u67E5\u770B\u8FD9 ",(0,d.jsx)(e.a,{href:"https://tvm.apache.org/docs/how_to/tune_with_autotvm/tune_relay_cuda.html#tutorials-autotvm-scale-up-rpc-tracker",children:"\u90E8\u5206"})," \u4E86\u89E3\u5982\u4F55\u4F7F\u7528 RPC \u8DDF\u8E2A\u5668\u548C RPC \u670D\u52A1\u5668\u3002\u8981\u5728 auto-scheduler \u4E2D\u4F7F\u7528 RPC \u8DDF\u8E2A\u5668\uFF0C\u8BF7\u5C06 ",(0,d.jsx)(e.code,{children:"TuningOptions"})," \u4E2D\u7684 runner \u66FF\u6362\u4E3A ",(0,d.jsx)(e.code,{children:"auto_scheduler.RPCRunner"}),"\u3002"]}),"\n"]}),"\n",(0,d.jsxs)(e.p,{children:[(0,d.jsx)(e.strong,{children:"\u811A\u672C\u603B\u8FD0\u884C\u65F6\u957F\uFF1A"}),"\uFF08 1 \u5206 22.035 \u79D2\uFF09"]}),"\n",(0,d.jsx)(e.p,{children:(0,d.jsx)(e.a,{href:"https://tvm.apache.org/docs/_downloads/e416b94ca1090b0897c0f6e0df95b911/tune_network_x86.py",children:"\u4E0B\u8F7D Python \u6E90\u4EE3\u7801\uFF1Atune_network_x86.py"})}),"\n",(0,d.jsx)(e.p,{children:(0,d.jsx)(e.a,{href:"https://tvm.apache.org/docs/_downloads/ad2a7f55d615d188ad664d56696815a6/tune_network_x86.ipynb",children:"\u4E0B\u8F7D Jupyter Notebook\uFF1Atune_network_x86.ipynb"})})]})}function s(a={}){let{wrapper:e}={...(0,o.a)(),...a.components};return e?(0,d.jsx)(e,{...a,children:(0,d.jsx)(i,{...a})}):i(a)}},21494:function(a,e,n){n.d(e,{Z:function(){return x},a:function(){return l}});var r=n(39546);let d={},o=r.createContext(d);function l(a){let e=r.useContext(o);return r.useMemo(function(){return"function"==typeof a?a(e):{...e,...a}},[e,a])}function x(a){let e;return e=a.disableParentContext?"function"==typeof a.components?a.components(d):a.components||d:l(a.components),r.createElement(o.Provider,{value:e},a.children)}}}]);