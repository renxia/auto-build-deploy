"use strict";(self.webpackChunktvm_cn=self.webpackChunktvm_cn||[]).push([["59081"],{98341:function(n,e,t){t.r(e),t.d(e,{default:()=>l,frontMatter:()=>a,metadata:()=>r,assets:()=>o,toc:()=>c,contentTitle:()=>s});var r=JSON.parse('{"id":"topic/vta/tutorials/conv_opt","title":"2D \u5377\u79EF\u4F18\u5316","description":"\u5355\u51FB \u6B64\u5904 \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801","source":"@site/versioned_docs/version-0.10.0/topic/vta/tutorials/05-conv_opt.md","sourceDirName":"topic/vta/tutorials","slug":"/topic/vta/tutorials/conv_opt","permalink":"/docs/tvm-cn/docs/0.10.0/topic/vta/tutorials/conv_opt","draft":false,"unlisted":false,"editUrl":"https://github.com/hyperai/tvm-cn/edit/master/versioned_docs/version-0.10.0/topic/vta/tutorials/05-conv_opt.md","tags":[],"version":"0.10.0","lastUpdatedBy":"sparanoid","lastUpdatedAt":1744717810000,"sidebarPosition":5,"frontMatter":{"title":"2D \u5377\u79EF\u4F18\u5316"},"sidebar":"tutorialSidebar","previous":{"title":"\u5728 VTA \u4E0A\u90E8\u7F72\u6765\u81EA Darknet \u7684\u9884\u8BAD\u7EC3\u89C6\u89C9\u68C0\u6D4B\u6A21\u578B","permalink":"/docs/tvm-cn/docs/0.10.0/topic/vta/tutorials/deploy_darknet"},"next":{"title":"\u77E9\u9635\u4E58\u6CD5\u5206\u5757","permalink":"/docs/tvm-cn/docs/0.10.0/topic/vta/tutorials/mat_mul_blocking"}}'),i=t("74132"),_=t("21494");let a={title:"2D \u5377\u79EF\u4F18\u5316"},s="2D \u5377\u79EF\u4F18\u5316",o={},c=[{value:"RPC \u8BBE\u7F6E",id:"rpc-\u8BBE\u7F6E",level:2},{value:"\u8BA1\u7B97\u58F0\u660E",id:"\u8BA1\u7B97\u58F0\u660E",level:2},{value:"\u8C03\u5EA6\u8BA1\u7B97",id:"\u8C03\u5EA6\u8BA1\u7B97",level:2},{value:"\u5BF9\u8BA1\u7B97\u5206\u5757",id:"\u5BF9\u8BA1\u7B97\u5206\u5757",level:3},{value:"\u865A\u62DF\u7EBF\u7A0B",id:"\u865A\u62DF\u7EBF\u7A0B",level:3},{value:"\u5C06\u62F7\u8D1D\u964D\u7EA7\u5230 DMA \u4F20\u8F93",id:"\u5C06\u62F7\u8D1D\u964D\u7EA7\u5230-dma-\u4F20\u8F93",level:3},{value:"\u5C06\u8BA1\u7B97\u964D\u7EA7\u4E3A VTA \u8BA1\u7B97\u5185\u8054\u51FD\u6570",id:"\u5C06\u8BA1\u7B97\u964D\u7EA7\u4E3A-vta-\u8BA1\u7B97\u5185\u8054\u51FD\u6570",level:3},{value:"TVM \u7F16\u8BD1\u53CA\u9A8C\u8BC1",id:"tvm-\u7F16\u8BD1\u53CA\u9A8C\u8BC1",level:2},{value:"\u603B\u7ED3",id:"\u603B\u7ED3",level:2}];function d(n){let e={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,_.a)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"2d-\u5377\u79EF\u4F18\u5316",children:"2D \u5377\u79EF\u4F18\u5316"})}),"\n",(0,i.jsx)(e.admonition,{type:"note",children:(0,i.jsxs)(e.p,{children:["\u5355\u51FB ",(0,i.jsx)(e.a,{href:"https://tvm.apache.org/docs/topic/vta/tutorials/optimize/convolution_opt.html#sphx-glr-download-topic-vta-tutorials-optimize-convolution-opt-py",children:"\u6B64\u5904"})," \u4E0B\u8F7D\u5B8C\u6574\u7684\u793A\u4F8B\u4EE3\u7801"]})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"\u4F5C\u8005"}),"\uFF1A",(0,i.jsx)(e.a,{href:"https://homes.cs.washington.edu/~moreau/",children:"Thierry Moreau"})]}),"\n",(0,i.jsxs)(e.p,{children:["\u672C\u6559\u7A0B\u6982\u8FF0\u4E86\u5982\u4F55\u7528 TVM \u5728 VTA \u8BBE\u8BA1\u4E0A\u6709\u6548\u5730\u6620\u5C04 2D \u5377\u79EF\u5DE5\u4F5C\u8D1F\u8F7D\u3002\u63A8\u8350\u5148\u5B66\u4E60 ",(0,i.jsx)(e.a,{href:"mat_mul_blocking",children:"\u77E9\u9635\u4E58\u6CD5\u5206\u5757"})," \u6559\u7A0B\u3002"]}),"\n",(0,i.jsx)(e.p,{children:"2D \u5377\u79EF\u5728\u5927\u591A\u6570\u8BA1\u7B97\u673A\u89C6\u89C9\u6DF1\u5EA6\u795E\u7ECF\u7F51\u7EDC\u4E2D\u5360\u4E3B\u5BFC\u5730\u4F4D\u3002\u672C\u6559\u7A0B\u5C06\u6F14\u793A TVM schedule \u4F18\u5316\uFF0C\u5C06 NCHW \u5E03\u5C40\u4E2D\u7684 2D \u5377\u79EF\u7B97\u5B50\u6620\u5C04\u5230 VTA\u3002\u8FD8\u5F15\u5165\u4E86\u5EF6\u8FDF\u9690\u85CF\u7684\u6982\u5FF5\uFF0C\u4F7F\u5F97\u6700\u5927\u9650\u5EA6\u5730\u5229\u7528 VTA \u7684\u8BA1\u7B97\u548C\u5185\u5B58\u8D44\u6E90\u3002"}),"\n",(0,i.jsx)(e.h2,{id:"rpc-\u8BBE\u7F6E",children:"RPC \u8BBE\u7F6E"}),"\n",(0,i.jsx)(e.p,{children:"\u9996\u5148\u5BF9 Pynq \u7684 FPGA \u8FDB\u884C\u7F16\u7A0B\uFF0C\u5E76\u6784\u5EFA\u5176 RPC runtime\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'from __future__ import absolute_import, print_function\n\nimport os\nimport tvm\nimport tvm.testing\nfrom tvm import te\nimport vta\nimport numpy as np\n\nfrom tvm import rpc\nfrom tvm.contrib import utils\nfrom vta.testing import simulator\n\n# \u4ECE 3rdparty/vta-hw/config/vta_config.json \u6587\u4EF6\u52A0\u8F7D VTA \u53C2\u6570\nenv = vta.get_env()\n\n# \u4ECE OS \u73AF\u5883\u4E2D\u8BFB\u53D6 Pynq RPC \u4E3B\u673A IP \u5730\u5740\u548C\u7AEF\u53E3\u53F7\nhost = os.environ.get("VTA_RPC_HOST", "192.168.2.99")\nport = int(os.environ.get("VTA_RPC_PORT", "9091"))\n\n# \u5728 Pynq \u4E0A\u914D\u7F6E\u6BD4\u7279\u6D41\u548C runtime \u7CFB\u7EDF\uFF0C\u5339\u914D vta_config.json \u6587\u4EF6\u6307\u5B9A\u7684 VTA \u914D\u7F6E\u3002\nif env.TARGET == "pynq":\n    # \u786E\u4FDD TVM \u662F\u7528 RPC=1 \u7F16\u8BD1\u7684\n    assert tvm.runtime.enabled("rpc")\n    remote = rpc.connect(host, port)\n\n    # \u91CD\u65B0\u914D\u7F6E JIT runtime\n    vta.reconfig_runtime(remote)\n\n    # \u7528\u9884\u7F16\u8BD1\u7684 VTA \u6BD4\u7279\u6D41\u5BF9 FPGA \u8FDB\u884C\u7F16\u7A0B\u3002\n    # \u53EF\u4EE5\u901A\u8FC7\u4F20\u9012\u6BD4\u7279\u6D41\u6587\u4EF6\u7684\u8DEF\u5F84\u800C\u975E None\uFF0C\u7528\u81EA\u5B9A\u4E49\u6BD4\u7279\u6D41\u5BF9 FPGA \u8FDB\u884C\u7F16\u7A0B\u3002\n    vta.program_fpga(remote, bitstream=None)\n\n# \u5728\u6A21\u62DF\u6A21\u5F0F\u4E0B\uFF0C\u672C\u5730\u6258\u7BA1 RPC \u670D\u52A1\u5668\u3002\nelif env.TARGET in ["sim", "tsim"]:\n    remote = rpc.LocalSession()\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u8BA1\u7B97\u58F0\u660E",children:"\u8BA1\u7B97\u58F0\u660E"}),"\n",(0,i.jsx)(e.p,{children:"\u7B2C\u4E00\u6B65\uFF0C\u7528 NCHW \u683C\u5F0F\u63CF\u8FF0 2D \u5377\u79EF\u8BA1\u7B97\u3002"}),"\n",(0,i.jsx)(e.p,{children:"\u901A\u8FC7 batch size\u3001\u7A7A\u95F4\u7EF4\u5EA6\u3001\u8F93\u5165\u901A\u9053\u3001\u8F93\u51FA\u901A\u9053\u3001\u5185\u6838\u7EF4\u5EA6\u3001\u586B\u5145\u7EF4\u5EA6\u548C\u6B65\u957F\u7EF4\u5EA6\u6765\u5B9A\u4E49 2D \u5377\u79EF shape\u3002"}),"\n",(0,i.jsx)(e.p,{children:"\u5C06 ResNet-18 \u67B6\u6784\u7684\u7B2C 9 \u4E2A\u5377\u79EF\u5C42\u7684 shape \u4F5C\u4E3A\u5377\u79EF\u5DE5\u4F5C\u8D1F\u8F7D\u53C2\u6570\u3002"}),"\n",(0,i.jsx)(e.p,{children:"\u5728 2D \u5377\u79EF\u4E2D\u6DFB\u52A0\u4E86\u989D\u5916\u7684\u7B97\u5B50\uFF0C\u8FD9\u4E9B\u7B97\u5B50\u5BF9\u8F93\u51FA\u8FDB\u884C\u79FB\u4F4D\u548C\u88C1\u526A\uFF0C\u4ECE\u800C\u6A21\u62DF\u5B9A\u70B9\u5377\u79EF\uFF0C\u7136\u540E\u8FDB\u884C\u6821\u6B63\u7EBF\u6027\u6FC0\u6D3B\u3002\u4E0B\u9762\u63CF\u8FF0 2D \u5377\u79EF\u5C42\u7684 TVM \u6570\u636E\u6D41\u56FE\uFF1A"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"/img/docs/uwsampl/web-data/main/vta/tutorial/conv2d_dataflow.png",src:t(69782).Z+"",width:"3916",height:"1212"})}),"\n",(0,i.jsx)(e.p,{children:"\u7531\u4E8E\u8FD9\u79CD\u8BA1\u7B97\u592A\u5927\uFF0C\u65E0\u6CD5\u4E00\u6B21\u5168\u90E8\u653E\u5165 VTA \u7684\u82AF\u7247\u7F13\u51B2\u533A\u3002\u56E0\u6B64\uFF0C\u5728\u8C03\u5EA6\u9636\u6BB5\uFF0C\u6211\u4EEC\u5C06\u4F9D\u9760\u8BA1\u7B97\u5206\u5757\u7B56\u7565\uFF0C\u5C06\u8BA1\u7B97\u5206\u89E3\u4E3A\u6613\u4E8E\u7BA1\u7406\u7684\u5757\u3002"}),"\n",(0,i.jsxs)(e.admonition,{type:"note",children:[(0,i.jsx)(e.p,{children:(0,i.jsx)(e.em,{children:"\u7A7A\u95F4\u586B\u5145"})}),(0,i.jsx)(e.p,{children:"\u6CE8\u610F\uFF0C\u8981\u5BFC\u5165 TOPI \u5E93\uFF0C\u5728\u8F93\u5165\u7279\u5F81\u56FE\u5F20\u91CF\u4E0A\u5E94\u7528\u7A7A\u95F4\u586B\u5145\u3002\u7A7A\u95F4\u586B\u5145\u6709\u52A9\u4E8E\u5728 2D \u5377\u79EF\u7684\u4E0A\u4E0B\u6587\u4E2D\u8FDB\u884C\u5206\u5757\uFF0C\u56E0\u4E3A\u82E5\u5377\u79EF\u6838\u7A97\u53E3\u5927\u5C0F\u5927\u4E8E 1\uFF0C\u5219\u5BF9\u4E8E\u4EFB\u4F55\u7ED9\u5B9A\u5C42\u7684\u8F93\u5165\u7279\u5F81\u56FE\uFF0C\u76F8\u540C\u7684 (x, y) \u7A7A\u95F4\u4F4D\u7F6E\u4F1A\u88AB\u591A\u6B21\u8BFB\u53D6\u3002"}),(0,i.jsx)(e.p,{children:"\u5728 CPU \u548C GPU \u4E0A\uFF0C\u5E76\u884C\u5316\u5DE5\u4F5C\u65F6\u63D0\u9AD8\u5185\u5B58\u8BBF\u95EE\u6548\u7387\u7684\u4E00\u79CD\u65B9\u6CD5\u662F\u7A7A\u95F4\u6253\u5305\uFF0C\u8FD9\u79CD\u65B9\u6CD5\u8981\u5BF9\u6570\u636E\u8FDB\u884C\u91CD\u65B0\u5E03\u5C40\u3002VTA \u52A0\u8F7D DMA \u5F15\u64CE\u53EF\u4EE5\u81EA\u52A8\u63D2\u5165\u586B\u5145\uFF0C\u56E0\u6B64\u4E0D\u5FC5\u5C06\u539F\u59CB\u8F93\u5165\u7279\u5F81\u56FE\u91CD\u65B0\u6253\u5305\u5230\u5185\u5B58\u4E2D\u3002"}),(0,i.jsx)(e.p,{children:"\u6211\u4EEC\u5C55\u793A\u4E86\u6570\u636E\u4ECE DRAM \u52A0\u8F7D\u5230 VTA \u7684 SRAM \u4E2D\u65F6\uFF0CVTA \u7684\u52A8\u6001\u7A7A\u95F4\u586B\u5145\u6548\u679C\u3002\u8FD9\u4E2A\u8FC7\u7A0B\u53D1\u751F\u5728 2D \u8DE8\u6B65\u548C\u586B\u5145\u5185\u5B58\uFF08strided and padded memory\uFF09\u8BFB\u53D6\u540E\u3002"}),(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"/img/docs/uwsampl/web-data/main/vta/tutorial/padding.png",src:t(38313).Z+"",width:"1548",height:"798"})})]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'from tvm import topi\n\n# 2D \u5377\u79EF\u5C42\u5C3A\u5BF8\u53D6\u81EA ResNet-18 \u67B6\u6784\uFF08\u7B2C 9 \u4E2A\u5377\u79EF\u5C42\uFF09\nbatch_size = 1\nheight = 14\nwidth = 14\nin_channels = 256\nout_channels = 256\nkernel_h = 3\nkernel_w = 3\npad_h = 1\npad_w = 1\nstride_h = 1\nstride_w = 1\nassert batch_size % env.BATCH == 0\nassert in_channels % env.BLOCK_IN == 0\nassert out_channels % env.BLOCK_OUT == 0\n\n# \u8F93\u5165\u7279\u5F81\u56FE\uFF1A(N, IC, H, W, n, ic)\ndata_shape = (\n    batch_size // env.BATCH,\n    in_channels // env.BLOCK_IN,\n    height,\n    width,\n    env.BATCH,\n    env.BLOCK_IN,\n)\n# \u5185\u6838\uFF1A\uFF08OC\uFF0CIC\uFF0CH\uFF0CW\uFF0Coc\uFF0Cic\uFF09\nkernel_shape = (\n    out_channels // env.BLOCK_OUT,\n    in_channels // env.BLOCK_IN,\n    kernel_h,\n    kernel_w,\n    env.BLOCK_OUT,\n    env.BLOCK_IN,\n)\n# \u5BFC\u51FA\u8F93\u51FA\u7279\u5F81\u56FE\u7EF4\u5EA6\nfout_height = (height + 2 * pad_h - kernel_h) // stride_h + 1\nfout_width = (width + 2 * pad_w - kernel_w) // stride_w + 1\n# \u8F93\u51FA\u7279\u5F81\u56FE\uFF1A(N, OC, H, W, n, oc)\noutput_shape = (\n    batch_size // env.BATCH,\n    out_channels // env.BLOCK_OUT,\n    fout_height,\n    fout_width,\n    env.BATCH,\n    env.BLOCK_OUT,\n)\n\n# \u5377\u79EF reduction \u8F74\ndy = te.reduce_axis((0, kernel_h), name="dy")\ndx = te.reduce_axis((0, kernel_w), name="dx")\nic = te.reduce_axis((0, in_channels // env.BLOCK_IN), name="ic")\nic_tns = te.reduce_axis((0, env.BLOCK_IN), name="ic_tns")\n\n# \u8F93\u5165\u5360\u4F4D\u7B26\u5F20\u91CF\ndata = te.placeholder(data_shape, name="data", dtype=env.inp_dtype)\nkernel = te.placeholder(kernel_shape, name="kernel", dtype=env.wgt_dtype)\n\n# \u590D\u5236\u7F13\u51B2\u533A\uFF1A\n# \u5BF9\u8F93\u5165\u7279\u5F81\u56FE\u5E94\u7528\u7A7A\u95F4\u586B\u5145\ndata_buf = topi.nn.pad(data, [0, 0, pad_h, pad_w, 0, 0], name="data_buf")\nkernel_buf = te.compute(kernel_shape, lambda *i: kernel(*i), "kernel_buf")\n\n# \u58F0\u660E\u4E8C\u7EF4\u5377\u79EF\nres_conv = te.compute(\n    output_shape,\n    lambda bo, co, i, j, bi, ci: te.sum(\n        data_buf[bo, ic, i * stride_h + dy, j * stride_w + dx, bi, ic_tns].astype(env.acc_dtype)\n        * kernel_buf[co, ic, dy, dx, ci, ic_tns].astype(env.acc_dtype),\n        axis=[ic, dy, dx, ic_tns],\n    ),\n    name="res_conv",\n)\n\n# \u4E3A\u5B9A\u70B9\u5F52\u4E00\u5316\u6DFB\u52A0\u79FB\u4F4D\u9636\u6BB5\nres_shr = te.compute(output_shape, lambda *i: res_conv(*i) >> 8, name="res_shr")\n\n# \u5728\uFF080\uFF0C\u8F93\u5165\u6700\u5927\u503C\uFF09\u4E4B\u95F4\u5E94\u7528 clip \u51FD\u6570\ninp_max = (1 << (env.INP_WIDTH - 1)) - 1\nres_max = te.compute(output_shape, lambda *i: tvm.te.max(res_shr(*i), 0), "res_max")\nres_min = te.compute(output_shape, lambda *i: tvm.te.min(res_max(*i), inp_max), "res_min")\n\n# \u7ED3\u679C\u5F20\u91CF\nres = te.compute(output_shape, lambda *i: res_min(*i).astype(env.inp_dtype), name="res")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u8C03\u5EA6\u8BA1\u7B97",children:"\u8C03\u5EA6\u8BA1\u7B97"}),"\n",(0,i.jsx)(e.p,{children:"\u4E0B\u9762\u5C06\u7814\u7A76\u7528\u6709\u6548\u65B9\u5F0F\u5C06 2D \u5377\u79EF\u6620\u5C04\u5230 VTA \u6240\u9700\u7684\u4E00\u7EC4\u8C03\u5EA6\u8F6C\u6362\u3002\u5305\u62EC\uFF1A"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"\u8BA1\u7B97\u5206\u5757"}),"\n",(0,i.jsx)(e.li,{children:"\u589E\u52A0\u8BA1\u7B97\u5229\u7528\u7387\u7684\u865A\u62DF\u7EBF\u7A0B"}),"\n",(0,i.jsx)(e.li,{children:"\u964D\u7EA7\u5230 VTA \u786C\u4EF6\u5185\u8054\u51FD\u6570"}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# \u521B\u5EFA TVM schedule\ns = te.create_schedule(res.op)\n# \u67E5\u770B\u9ED8\u8BA4\u7684 TVM schedule\nprint(tvm.lower(s, [data, kernel, res], simple_mode=True))\n"})}),"\n",(0,i.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:'@main = primfn(data_1: handle, kernel_1: handle, res_1: handle) -> ()\n  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}\n  buffers = {data: Buffer(data_2: Pointer(int8), int8, [50176], []),\n             kernel: Buffer(kernel_2: Pointer(int8), int8, [589824], []),\n             res: Buffer(res_2: Pointer(int8), int8, [50176], [])}\n  buffer_map = {data_1: data, kernel_1: kernel, res_1: res}\n  preflattened_buffer_map = {data_1: data_3: Buffer(data_2, int8, [1, 16, 14, 14, 1, 16], []), kernel_1: kernel_3: Buffer(kernel_2, int8, [16, 16, 3, 3, 16, 16], []), res_1: res_3: Buffer(res_2, int8, [1, 16, 14, 14, 1, 16], [])} {\n  allocate(data_buf: Pointer(global int8), int8, [65536]), storage_scope = global;\n  allocate(kernel_buf: Pointer(global int8), int8, [589824]), storage_scope = global;\n  allocate(res_conv: Pointer(global int32), int32, [50176]), storage_scope = global {\n    for (i1: int32, 0, 16) {\n      for (i2: int32, 0, 16) {\n        for (i3: int32, 0, 16) {\n          for (i5: int32, 0, 16) {\n            let cse_var_1: int32 = (i3*16)\n            data_buf_1: Buffer(data_buf, int8, [65536], [])[((((i1*4096) + (i2*256)) + cse_var_1) + i5)] = @tir.if_then_else(((((1 <= i2) && (i2 < 15)) && (1 <= i3)) && (i3 < 15)), data[(((((i1*3136) + (i2*224)) + cse_var_1) + i5) - 240)], 0i8, dtype=int8)\n          }\n        }\n      }\n    }\n    for (i0: int32, 0, 16) {\n      for (i1_1: int32, 0, 16) {\n        for (i2_1: int32, 0, 3) {\n          for (i3_1: int32, 0, 3) {\n            for (i4: int32, 0, 16) {\n              for (i5_1: int32, 0, 16) {\n                let cse_var_2: int32 = ((((((i0*36864) + (i1_1*2304)) + (i2_1*768)) + (i3_1*256)) + (i4*16)) + i5_1)\n                kernel_buf_1: Buffer(kernel_buf, int8, [589824], [])[cse_var_2] = kernel[cse_var_2]\n              }\n            }\n          }\n        }\n      }\n    }\n    for (co: int32, 0, 16) {\n      for (i: int32, 0, 14) {\n        for (j: int32, 0, 14) {\n          for (ci: int32, 0, 16) {\n            res_conv_1: Buffer(res_conv, int32, [50176], [])[((((co*3136) + (i*224)) + (j*16)) + ci)] = 0\n            for (ic: int32, 0, 16) {\n              for (dy: int32, 0, 3) {\n                for (dx: int32, 0, 3) {\n                  for (ic_tns: int32, 0, 16) {\n                    let cse_var_4: int32 = (j*16)\n                    let cse_var_3: int32 = ((((co*3136) + (i*224)) + cse_var_4) + ci)\n                    res_conv_1[cse_var_3] = (res_conv_1[cse_var_3] + (cast(int32, data_buf_1[((((((ic*4096) + (i*256)) + (dy*256)) + cse_var_4) + (dx*16)) + ic_tns)])*cast(int32, kernel_buf_1[((((((co*36864) + (ic*2304)) + (dy*768)) + (dx*256)) + (ci*16)) + ic_tns)])))\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    for (i1_2: int32, 0, 16) {\n      for (i2_2: int32, 0, 14) {\n        for (i3_2: int32, 0, 14) {\n          for (i5_2: int32, 0, 16) {\n            let cse_var_5: int32 = ((((i1_2*3136) + (i2_2*224)) + (i3_2*16)) + i5_2)\n            res_conv_2: Buffer(res_conv, int32, [50176], [])[cse_var_5] = @tir.shift_right(res_conv_1[cse_var_5], 8, dtype=int32)\n          }\n        }\n      }\n    }\n    for (i1_3: int32, 0, 16) {\n      for (i2_3: int32, 0, 14) {\n        for (i3_3: int32, 0, 14) {\n          for (i5_3: int32, 0, 16) {\n            let cse_var_6: int32 = ((((i1_3*3136) + (i2_3*224)) + (i3_3*16)) + i5_3)\n            res_conv_3: Buffer(res_conv, int32, [50176], [])[cse_var_6] = max(res_conv_2[cse_var_6], 0)\n          }\n        }\n      }\n    }\n    for (i1_4: int32, 0, 16) {\n      for (i2_4: int32, 0, 14) {\n        for (i3_4: int32, 0, 14) {\n          for (i5_4: int32, 0, 16) {\n            let cse_var_7: int32 = ((((i1_4*3136) + (i2_4*224)) + (i3_4*16)) + i5_4)\n            res_conv_4: Buffer(res_conv, int32, [50176], [])[cse_var_7] = min(res_conv_3[cse_var_7], 127)\n          }\n        }\n      }\n    }\n    for (i1_5: int32, 0, 16) {\n      for (i2_5: int32, 0, 14) {\n        for (i3_5: int32, 0, 14) {\n          for (i5_5: int32, 0, 16) {\n            let cse_var_8: int32 = ((((i1_5*3136) + (i2_5*224)) + (i3_5*16)) + i5_5)\n            res[cse_var_8] = cast(int8, res_conv_4[cse_var_8])\n          }\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u5BF9\u8BA1\u7B97\u5206\u5757",children:"\u5BF9\u8BA1\u7B97\u5206\u5757"}),"\n",(0,i.jsx)(e.p,{children:"\u9ED8\u8BA4\u60C5\u51B5\u4E0B\uFF0C2D \u5377\u79EF\u5BF9\u4E8E\u6FC0\u6D3B\u6216\u5185\u6838\u6743\u91CD\u6765\u8BF4\u592A\u5927\uFF0C\u65E0\u6CD5\u4E00\u6B21\u6027\u540C\u65F6\u88C5\u5165 VTA \u7684\u82AF\u7247\u7F13\u51B2\u533A\u3002\u6CBF\u8F93\u5165\u901A\u9053\u3001\u8F93\u51FA\u901A\u9053\u548C\u9AD8\u5EA6\u7A7A\u95F4\u7EF4\u5EA6\u5206\u5757\u3002\u4E0D\u8981\u6CBF\u5BBD\u5EA6\u7A7A\u95F4\u7EF4\u5EA6\u5206\u5757\uFF0C\u56E0\u4E3A\u5B83\u662F NCHW \u5E03\u5C40\u4E2D\u7684\u6700\u5185\u5C42\u7EF4\u5EA6\uFF08\u56E0\u6B64\uFF0C\u4E3A\u4E86\u589E\u52A0\u5C40\u90E8\u6027\uFF0C\u6700\u597D\u4E0D\u8981\u6CBF\u6700\u5185\u5C42\u7EF4\u5EA6\u8FDB\u884C\u963B\u585E\uFF09\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# \u5B9A\u4E49\u5E73\u94FA\u5927\u5C0F\nb_block = 1 // env.BATCH\noc_block = 128 // env.BLOCK_OUT\nic_block = 16 // env.BLOCK_IN\nh_block = 7\nw_block = 14\n\n# \u6CBF\u7A7A\u95F4\u548C\u8F93\u51FA\u901A\u9053\u7EF4\u5EA6\u5E73\u94FA\u8F93\u51FA\u5F20\u91CF\n# \uFF08\u56E0\u4E3A\u9ED8\u8BA4\u8FDB\u884C\u5355\u4E2A batch \u63A8\u7406\uFF0C\u6CBF batch \u7EF4\u5EA6\u7684\u62C6\u5206\u6CA1\u6709\u6548\u679C\uFF09\nb, oc, y, x, b_tns, oc_tns = s[res].op.axis\nb_out, b_inn = s[res].split(b, factor=b_block)\noc_out, oc_inn = s[res].split(oc, factor=oc_block)\ny_out, y_inn = s[res].split(y, factor=h_block)\nx_out, x_inn = s[res].split(x, factor=w_block)\ns[res].reorder(b_out, oc_out, y_out, x_out, b_inn, oc_inn, y_inn, x_inn, b_tns, oc_tns)\n\n# \u5C06\u4E2D\u95F4\u8BA1\u7B97\u79FB\u52A8\u5230\u6BCF\u4E2A\u8F93\u51FA\u8BA1\u7B97\u5757\u4E2D\ns[res_conv].compute_at(s[res], x_out)\ns[res_shr].compute_at(s[res], x_out)\ns[res_max].compute_at(s[res], x_out)\ns[res_min].compute_at(s[res], x_out)\n\n# \u6CBF reduction \u8F74\uFF08\u8F93\u5165\u901A\u9053\uFF09\u5E94\u7528\u989D\u5916\u7684\u5FAA\u73AF\u5206\u5272\nb_inn, oc_inn, y_inn, x_inn, b_tns, oc_tns = s[res_conv].op.axis\nic_out, ic_inn = s[res_conv].split(ic, factor=ic_block)\n\n# \u5BF9\u8F74\u91CD\u65B0\u6392\u5E8F\u3002\n# 1\uFF09\u5728\u6700\u91CC\u9762\u7684\u4F4D\u7F6E\u5C06 VTA \u5F20\u91CF\u8F74\u5206\u7EC4\uFF1Ab_tns\u3001oc_tns\u3001ic_tns\uFF0C\u4F7F\u5F97 TVM \u5F20\u91CF\u5316\u3002\n# 2\uFF09\u5C06 ic_out \u8F74\u79FB\u51FA\u5377\u79EF\u5FAA\u73AF\uFF0C\u6CBF reduction \u8F74\u963B\u585E\u3002\n# 3\uFF09\u73B0\u5728\u5BF9\u5757\u8F74\u91CD\u65B0\u6392\u5E8F\uFF1Ab_inn\u3001oc_inn\u3001y_inn\u3001x_inn\u3001ic_inn\u3001dy\u3001dx\u3002\n#    VTA runtime/\u786C\u4EF6\u8981\u6C42\u4E3A\u6BCF\u4E2A VTA \u5F20\u91CF\u64CD\u4F5C\u5199\u5165\u4E0D\u540C\u7684\u8F93\u51FA\u7279\u5F81\u56FE\u4F4D\u7F6E\u3002\n#    \u8FD9\u4E2A\u9650\u5236\u8981\u6C42\u5728 b_tns \u4E4B\u524D\u5BF9 oc_inn\u3001y_inn \u6216 x_inn \u5176\u4E2D\u4E4B\u4E00\u8FDB\u884C\u6392\u5E8F\uFF0C\u56E0\u4E3A\u5B83\u4EEC\u90FD\u4F1A\u5F71\u54CD\u8F93\u51FA\u7279\u5F81\u56FE\u7D22\u5F15\u3002\n#    \u4E0B\u9762\u5C06 x_inn \u653E\u8FDB\u53BB\u3002\ns[res_conv].reorder(ic_out, b_inn, oc_inn, y_inn, ic_inn, dy, dx, x_inn, b_tns, oc_tns, ic_tns)\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u865A\u62DF\u7EBF\u7A0B",children:"\u865A\u62DF\u7EBF\u7A0B"}),"\n",(0,i.jsx)(e.p,{children:"\u865A\u62DF\u7EBF\u7A0B\u662F VTA \u786C\u4EF6\u8BBE\u8BA1\u4E2D\uFF0C\u4E00\u79CD\u63D0\u9AD8\u4EFB\u52A1\u7EA7 pipeline \u5E76\u884C\u6027\u7684\u673A\u5236\u3002\u6362\u8A00\u4E4B\uFF0C\u5B83\u901A\u8FC7\u9690\u85CF\u5185\u5B58\u8BBF\u95EE\u5EF6\u8FDF\uFF0C\u6765\u63D0\u9AD8\u8BA1\u7B97\u8D44\u6E90\u5229\u7528\u7387\u3002"}),"\n",(0,i.jsx)(e.p,{children:"\u4EE5\u4E0B\u5B9E\u73B0\uFF0C\u865A\u62DF\u7EBF\u7A0B\u5C06\u5DE5\u4F5C\u5206\u914D\u7ED9\u6CBF\u8F93\u51FA\u901A\u9053\u8F74\u62C6\u5206\u7684\u4E24\u4E2A\u7EBF\u7A0B\u3002\u4E0B\u56FE\u5C55\u793A\u4E86\u8BA1\u7B97 2D \u5377\u79EF\u65F6\uFF0C\u5DE5\u4F5C\u662F\u5982\u4F55\u5212\u5206\u7684\u3002"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.img,{alt:"/img/docs/uwsampl/web-data/main/vta/tutorial/virtual_threading.png",src:t(25783).Z+"",width:"1588",height:"1468"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# VTA \u53EA\u652F\u6301 2 \u4E2A\u865A\u62DF\u7EBF\u7A0B\nv_threads = 2\n\n# \u6CBF\u8F93\u51FA\u901A\u9053\u5916\u8F74\u8FDB\u884C\u865A\u62DF\u7EBF\u7A0B\u62C6\u5206\n_, tx = s[res].split(oc_out, factor=v_threads)\ns[res].reorder(tx, b_out)\ns[res].bind(tx, te.thread_axis("cthread"))\n\n# \u67E5\u770B\u963B\u585E\u548C\u865A\u62DF\u7EBF\u7A0B\u540E\u7684\u5F53\u524D TVM schedule\nprint(tvm.lower(s, [data, kernel, res], simple_mode=True))\n'})}),"\n",(0,i.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:'@main = primfn(data_1: handle, kernel_1: handle, res_1: handle) -> ()\n  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}\n  buffers = {data: Buffer(data_2: Pointer(int8), int8, [50176], []),\n             kernel: Buffer(kernel_2: Pointer(int8), int8, [589824], []),\n             res: Buffer(res_2: Pointer(int8), int8, [50176], [])}\n  buffer_map = {data_1: data, kernel_1: kernel, res_1: res}\n  preflattened_buffer_map = {data_1: data_3: Buffer(data_2, int8, [1, 16, 14, 14, 1, 16], []), kernel_1: kernel_3: Buffer(kernel_2, int8, [16, 16, 3, 3, 16, 16], []), res_1: res_3: Buffer(res_2, int8, [1, 16, 14, 14, 1, 16], [])} {\n  allocate(data_buf: Pointer(global int8), int8, [65536]), storage_scope = global;\n  allocate(kernel_buf: Pointer(global int8), int8, [589824]), storage_scope = global;\n  allocate(res_conv: Pointer(global int32), int32, [25088]), storage_scope = global {\n    for (i1: int32, 0, 16) {\n      for (i2: int32, 0, 16) {\n        for (i3: int32, 0, 16) {\n          for (i5: int32, 0, 16) {\n            let cse_var_1: int32 = (i3*16)\n            data_buf_1: Buffer(data_buf, int8, [65536], [])[((((i1*4096) + (i2*256)) + cse_var_1) + i5)] = @tir.if_then_else(((((1 <= i2) && (i2 < 15)) && (1 <= i3)) && (i3 < 15)), data[(((((i1*3136) + (i2*224)) + cse_var_1) + i5) - 240)], 0i8, dtype=int8)\n          }\n        }\n      }\n    }\n    for (i0: int32, 0, 16) {\n      for (i1_1: int32, 0, 16) {\n        for (i2_1: int32, 0, 3) {\n          for (i3_1: int32, 0, 3) {\n            for (i4: int32, 0, 16) {\n              for (i5_1: int32, 0, 16) {\n                let cse_var_2: int32 = ((((((i0*36864) + (i1_1*2304)) + (i2_1*768)) + (i3_1*256)) + (i4*16)) + i5_1)\n                kernel_buf_1: Buffer(kernel_buf, int8, [589824], [])[cse_var_2] = kernel[cse_var_2]\n              }\n            }\n          }\n        }\n      }\n    }\n    for (i2.outer: int32, 0, 2) {\n      for (co.init: int32, 0, 8) {\n        for (i.init: int32, 0, 7) {\n          for (j.init: int32, 0, 14) {\n            for (ci.init: int32, 0, 16) {\n              let cse_var_3: int32 = ((((co.init*1568) + (i.init*224)) + (j.init*16)) + ci.init)\n               {\n                res_conv_1: Buffer(res_conv, int32, [157351936], [])[cse_var_3] = 0\n                res_conv_1[(cse_var_3 + 12544)] = 0\n              }\n            }\n          }\n        }\n      }\n      for (ic.outer: int32, 0, 16) {\n        for (co: int32, 0, 8) {\n          for (i: int32, 0, 7) {\n            for (dy: int32, 0, 3) {\n              for (dx: int32, 0, 3) {\n                for (j: int32, 0, 14) {\n                  for (ci: int32, 0, 16) {\n                    for (ic_tns: int32, 0, 16) {\n                      let cse_var_8: int32 = (j*16)\n                      let cse_var_7: int32 = ((((co*1568) + (i*224)) + cse_var_8) + ci)\n                      let cse_var_6: int32 = (cse_var_7 + 12544)\n                      let cse_var_5: int32 = ((((((co*36864) + (ic.outer*2304)) + (dy*768)) + (dx*256)) + (ci*16)) + ic_tns)\n                      let cse_var_4: int32 = (((((((ic.outer*4096) + (i2.outer*1792)) + (i*256)) + (dy*256)) + cse_var_8) + (dx*16)) + ic_tns)\n                       {\n                        res_conv_1[cse_var_7] = (res_conv_1[cse_var_7] + (cast(int32, data_buf_1[cse_var_4])*cast(int32, kernel_buf_1[cse_var_5])))\n                        res_conv_1[cse_var_6] = (res_conv_1[cse_var_6] + (cast(int32, data_buf_1[cse_var_4])*cast(int32, kernel_buf_1[(cse_var_5 + 294912)])))\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n      for (i1_2: int32, 0, 8) {\n        for (i2_2: int32, 0, 7) {\n          for (i3_2: int32, 0, 14) {\n            for (i5_2: int32, 0, 16) {\n              let cse_var_10: int32 = ((((i1_2*1568) + (i2_2*224)) + (i3_2*16)) + i5_2)\n              let cse_var_9: int32 = (cse_var_10 + 12544)\n               {\n                res_conv_2: Buffer(res_conv, int32, [157351936], [])[cse_var_10] = @tir.shift_right(res_conv_1[cse_var_10], 8, dtype=int32)\n                res_conv_2[cse_var_9] = @tir.shift_right(res_conv_1[cse_var_9], 8, dtype=int32)\n              }\n            }\n          }\n        }\n      }\n      for (i1_3: int32, 0, 8) {\n        for (i2_3: int32, 0, 7) {\n          for (i3_3: int32, 0, 14) {\n            for (i5_3: int32, 0, 16) {\n              let cse_var_12: int32 = ((((i1_3*1568) + (i2_3*224)) + (i3_3*16)) + i5_3)\n              let cse_var_11: int32 = (cse_var_12 + 12544)\n               {\n                res_conv_3: Buffer(res_conv, int32, [157351936], [])[cse_var_12] = max(res_conv_2[cse_var_12], 0)\n                res_conv_3[cse_var_11] = max(res_conv_2[cse_var_11], 0)\n              }\n            }\n          }\n        }\n      }\n      for (i1_4: int32, 0, 8) {\n        for (i2_4: int32, 0, 7) {\n          for (i3_4: int32, 0, 14) {\n            for (i5_4: int32, 0, 16) {\n              let cse_var_14: int32 = ((((i1_4*1568) + (i2_4*224)) + (i3_4*16)) + i5_4)\n              let cse_var_13: int32 = (cse_var_14 + 12544)\n               {\n                res_conv_4: Buffer(res_conv, int32, [157351936], [])[cse_var_14] = min(res_conv_3[cse_var_14], 127)\n                res_conv_4[cse_var_13] = min(res_conv_3[cse_var_13], 127)\n              }\n            }\n          }\n        }\n      }\n      for (i1.inner: int32, 0, 8) {\n        for (i2.inner: int32, 0, 7) {\n          for (i3.inner: int32, 0, 14) {\n            for (i5_5: int32, 0, 16) {\n              let cse_var_18: int32 = (i2.inner*224)\n              let cse_var_17: int32 = (i3.inner*16)\n              let cse_var_16: int32 = ((((i1.inner*1568) + cse_var_18) + cse_var_17) + i5_5)\n              let cse_var_15: int32 = (((((i1.inner*3136) + (i2.outer*1568)) + cse_var_18) + cse_var_17) + i5_5)\n               {\n                res[cse_var_15] = cast(int8, res_conv_4[cse_var_16])\n                res[(cse_var_15 + 25088)] = cast(int8, res_conv_4[(cse_var_16 + 12544)])\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n'})}),"\n",(0,i.jsx)(e.h3,{id:"\u5C06\u62F7\u8D1D\u964D\u7EA7\u5230-dma-\u4F20\u8F93",children:"\u5C06\u62F7\u8D1D\u964D\u7EA7\u5230 DMA \u4F20\u8F93"}),"\n",(0,i.jsx)(e.p,{children:"\u63A5\u4E0B\u6765\uFF0C\u5C06\u7F13\u51B2\u533A\u8303\u56F4\u8BBE\u7F6E\u4E3A\u76F8\u5E94\u7684\u82AF\u7247 VTA SRAM \u7F13\u51B2\u533A\u3002\u5C06\u52A0\u8F7D\u5FAA\u73AF\u79FB\u52A8\u5230 2D \u5377\u79EF\u8BA1\u7B97\u5FAA\u73AF\u4E2D\uFF0C\u6682\u5B58\u5185\u5B58\u52A0\u8F7D\uFF0C\u4F7F\u5176\u9002\u5408\u82AF\u7247\u4E0A SRAM buffer\u3002\u6700\u540E\uFF0C\u7528 DMA \u62F7\u8D1D\u7F16\u8BD1\u6307\u793A\u6765\u6CE8\u91CA\u52A0\u8F7D/\u5B58\u50A8\u5FAA\u73AF\u5916\u8F74\uFF0C\u4ECE\u800C\u5728 VTA \u4E0A\u6267\u884C\u5927\u5BB9\u91CF\u5185\u5B58\u4F20\u8F93\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# \u8BBE\u7F6E SRAM buffer \u7684\u8303\u56F4\ns[data_buf].set_scope(env.inp_scope)\ns[kernel_buf].set_scope(env.wgt_scope)\ns[res_conv].set_scope(env.acc_scope)\ns[res_shr].set_scope(env.acc_scope)\ns[res_min].set_scope(env.acc_scope)\ns[res_max].set_scope(env.acc_scope)\n\n# \u5757\u6570\u636E\u548C\u5185\u6838\u7F13\u5B58\u8BFB\u53D6\ns[data_buf].compute_at(s[res_conv], ic_out)\ns[kernel_buf].compute_at(s[res_conv], ic_out)\n\n# \u7528 DMA \u62F7\u8D1D\u7F16\u8BD1\u6307\u793A\u64CD\u4F5C DRAM->SRAM\ns[data_buf].pragma(s[data_buf].op.axis[0], env.dma_copy)\ns[kernel_buf].pragma(s[kernel_buf].op.axis[0], env.dma_copy)\n\n# \u5728\u6BCF\u4E2A\u7ED3\u679C\u5757\u4E2D\u7684 SRAM->DRAM \u64CD\u4F5C\u4E0A\uFF0C\u4F7F\u7528 DMA \u62F7\u8D1D\u7F16\u8BD1\u6307\u793A\uFF08\u8FD9\u610F\u5473\u7740\u8FD9\u4E9B\u62F7\u8D1D\u5E94\u6CBF b_inn \u6216\u7ED3\u679C\u8F74 4 \u6267\u884C\uFF09\ns[res].pragma(s[res].op.axis[4], env.dma_copy)\n"})}),"\n",(0,i.jsx)(e.h3,{id:"\u5C06\u8BA1\u7B97\u964D\u7EA7\u4E3A-vta-\u8BA1\u7B97\u5185\u8054\u51FD\u6570",children:"\u5C06\u8BA1\u7B97\u964D\u7EA7\u4E3A VTA \u8BA1\u7B97\u5185\u8054\u51FD\u6570"}),"\n",(0,i.jsx)(e.p,{children:"\u6700\u540E\u4E00\u4E2A\u9636\u6BB5\u662F\u964D\u7EA7\u8BA1\u7B97\u5FAA\u73AF\u5230 VTA \u786C\u4EF6\u5185\u8054\u51FD\u6570\uFF0C\u8FD9\u662F\u901A\u8FC7\u5C06 2D \u5377\u79EF\u6620\u5C04\u5230\u5F20\u91CF\u5185\u8054\u51FD\u6570\uFF0C\u5E76\u5C06\u79FB\u4F4D\u548C\u88C1\u526A\u8BA1\u7B97\u6620\u5C04\u5230\u5411\u91CF ALU \u5B9E\u73B0\u7684\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"# \u5728 batch \u5F20\u91CF\u5E73\u94FA\u8F74\u4E0A\u5E94\u7528\u5F20\u91CF\u5316\ns[res_conv].tensorize(b_tns, env.gemm)\n\n# \u5728\u79FB\u4F4D\u548C\u88C1\u526A\u64CD\u4F5C\u4E0A\u6DFB\u52A0 ALU \u7F16\u8BD1\u6307\u793A\ns[res_shr].pragma(s[res_shr].op.axis[0], env.alu)\ns[res_min].pragma(s[res_min].op.axis[0], env.alu)\ns[res_max].pragma(s[res_max].op.axis[0], env.alu)\n\n# \u5C06\u5185\u5B58\u8D1F\u8F7D/\u5B58\u50A8\u964D\u7EA7\u4E3A DMA \u62F7\u8D1D\u5185\u8054\u51FD\u6570\uFF0C\u5E76\u5C06\u8BA1\u7B97\u964D\u7EA7\u4E3A VTA \u8BA1\u7B97\u5185\u8054\u51FD\u6570\u540E\uFF0C\u67E5\u770B\u6700\u7EC8\u964D\u7EA7\u7684 TVM schedule\u3002\nprint(vta.lower(s, [data, kernel, res], simple_mode=True))\n"})}),"\n",(0,i.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:'@main = primfn(data_1: handle, kernel_1: handle, res_1: handle) -> ()\n  attr = {"from_legacy_te_schedule": True, "global_symbol": "main", "tir.noalias": True}\n  buffers = {data: Buffer(data_2: Pointer(int8), int8, [50176], []),\n             kernel: Buffer(kernel_2: Pointer(int8), int8, [589824], []),\n             res: Buffer(res_2: Pointer(int8), int8, [50176], [])}\n  buffer_map = {data_1: data, kernel_1: kernel, res_1: res}\n  preflattened_buffer_map = {data_1: data_3: Buffer(data_2, int8, [1, 16, 14, 14, 1, 16], []), kernel_1: kernel_3: Buffer(kernel_2, int8, [16, 16, 3, 3, 16, 16], []), res_1: res_3: Buffer(res_2, int8, [1, 16, 14, 14, 1, 16], [])} {\n  @tir.vta.coproc_dep_push(3, 2, dtype=int32)\n  @tir.vta.coproc_dep_push(3, 2, dtype=int32)\n  for (i2.outer: int32, 0, 2) {\n    for (cthread.s: int32, 0, 2) {\n      attr [IterVar(vta: int32, (nullptr), "ThreadIndex", "vta")] "coproc_scope" = 2 {\n        @tir.vta.coproc_dep_pop(3, 2, dtype=int32)\n        attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_uop_scope" = "VTAPushGEMMOp" {\n          @tir.call_extern("VTAUopLoopBegin", 8, 98, 0, 0, dtype=int32)\n          @tir.call_extern("VTAUopLoopBegin", 7, 14, 0, 0, dtype=int32)\n          for (j.init: int32, 0, 14) {\n            @tir.vta.uop_push(0, 1, ((cthread.s*784) + j.init), 0, 0, 0, 0, 0, dtype=int32)\n          }\n          @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n          @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n        }\n        @tir.vta.coproc_dep_push(2, 1, dtype=int32)\n      }\n    }\n    for (ic.outer: int32, 0, 16) {\n      let cse_var_6: int32 = (i2.outer*7)\n      let cse_var_5: int32 = (ic.outer*9)\n      let cse_var_4: int32 = max((1 - cse_var_6), 0)\n      let cse_var_3: int32 = max((cse_var_6 - 6), 0)\n      let cse_var_2: int32 = ((9 - cse_var_4) - cse_var_3)\n      let cse_var_1: int32 = ((((ic.outer*196) + (i2.outer*98)) + (cse_var_4*14)) - 14)\n       {\n        attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_scope" = 1 {\n          @tir.vta.coproc_dep_pop(2, 1, dtype=int32)\n          @tir.call_extern("VTALoadBuffer2D", @tir.tvm_thread_context(@tir.vta.command_handle(, dtype=handle), dtype=handle), data_2, cse_var_1, 14, cse_var_2, 14, 1, cse_var_4, 1, cse_var_3, 0, 2, dtype=int32)\n          @tir.call_extern("VTALoadBuffer2D", @tir.tvm_thread_context(@tir.vta.command_handle(, dtype=handle), dtype=handle), kernel_2, cse_var_5, 9, 8, 144, 0, 0, 0, 0, 0, 1, dtype=int32)\n          @tir.vta.coproc_dep_push(1, 2, dtype=int32)\n        }\n        attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_scope" = 1 {\n          @tir.vta.coproc_dep_pop(2, 1, dtype=int32)\n          @tir.call_extern("VTALoadBuffer2D", @tir.tvm_thread_context(@tir.vta.command_handle(, dtype=handle), dtype=handle), data_2, cse_var_1, 14, cse_var_2, 14, 1, cse_var_4, 1, cse_var_3, 144, 2, dtype=int32)\n          @tir.call_extern("VTALoadBuffer2D", @tir.tvm_thread_context(@tir.vta.command_handle(, dtype=handle), dtype=handle), kernel_2, (cse_var_5 + 1152), 9, 8, 144, 0, 0, 0, 0, 72, 1, dtype=int32)\n          @tir.vta.coproc_dep_push(1, 2, dtype=int32)\n        }\n        for (cthread.s_1: int32, 0, 2) {\n          attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_scope" = 2 {\n            @tir.vta.coproc_dep_pop(1, 2, dtype=int32)\n            attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_uop_scope" = "VTAPushGEMMOp" {\n              @tir.call_extern("VTAUopLoopBegin", 8, 98, 0, 9, dtype=int32)\n              @tir.call_extern("VTAUopLoopBegin", 7, 14, 16, 0, dtype=int32)\n              for (dy: int32, 0, 3) {\n                for (dx: int32, 0, 3) {\n                  for (j: int32, 0, 14) {\n                    @tir.vta.uop_push(0, 0, ((cthread.s_1*784) + j), ((((cthread.s_1*144) + (dy*16)) + j) + dx), (((cthread.s_1*72) + (dy*3)) + dx), 0, 0, 0, dtype=int32)\n                  }\n                }\n              }\n              @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n              @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n            }\n            @tir.vta.coproc_dep_push(2, 1, dtype=int32)\n          }\n        }\n      }\n    }\n    @tir.vta.coproc_dep_pop(2, 1, dtype=int32)\n    @tir.vta.coproc_dep_pop(2, 1, dtype=int32)\n    for (cthread.s_2: int32, 0, 2) {\n      let cse_var_7: int32 = (cthread.s_2*784)\n      attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_scope" = 2 {\n        attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_uop_scope" = "VTAPushALUOp" {\n          @tir.call_extern("VTAUopLoopBegin", 784, 1, 1, 0, dtype=int32)\n          @tir.vta.uop_push(1, 0, cse_var_7, cse_var_7, 0, 3, 1, 8, dtype=int32)\n          @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n        }\n        attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_uop_scope" = "VTAPushALUOp" {\n          @tir.call_extern("VTAUopLoopBegin", 784, 1, 1, 0, dtype=int32)\n          @tir.vta.uop_push(1, 0, cse_var_7, cse_var_7, 0, 1, 1, 0, dtype=int32)\n          @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n        }\n        attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_uop_scope" = "VTAPushALUOp" {\n          @tir.call_extern("VTAUopLoopBegin", 784, 1, 1, 0, dtype=int32)\n          @tir.vta.uop_push(1, 0, cse_var_7, cse_var_7, 0, 0, 1, 127, dtype=int32)\n          @tir.call_extern("VTAUopLoopEnd", dtype=int32)\n        }\n        @tir.vta.coproc_dep_push(2, 3, dtype=int32)\n      }\n    }\n    for (cthread.s_3: int32, 0, 2) {\n      attr [IterVar(vta, (nullptr), "ThreadIndex", "vta")] "coproc_scope" = 3 {\n        @tir.vta.coproc_dep_pop(2, 3, dtype=int32)\n        for (i1.inner: int32, 0, 8) {\n          for (i2.inner: int32, 0, 7) {\n            for (i3.inner: int32, 0, 14) {\n              let cse_var_8: int32 = (i2.inner*14)\n              @tir.call_extern("VTAStoreBuffer2D", @tir.tvm_thread_context(@tir.vta.command_handle(, dtype=handle), dtype=handle), ((((cthread.s_3*784) + (i1.inner*98)) + cse_var_8) + i3.inner), 4, res_2, (((((cthread.s_3*1568) + (i1.inner*196)) + (i2.outer*98)) + cse_var_8) + i3.inner), 1, 1, 1, dtype=int32)\n            }\n          }\n        }\n        @tir.vta.coproc_dep_push(3, 2, dtype=int32)\n      }\n    }\n  }\n  @tir.vta.coproc_dep_pop(3, 2, dtype=int32)\n  @tir.vta.coproc_dep_pop(3, 2, dtype=int32)\n  @tir.vta.coproc_sync(, dtype=int32)\n}\n'})}),"\n",(0,i.jsx)(e.h2,{id:"tvm-\u7F16\u8BD1\u53CA\u9A8C\u8BC1",children:"TVM \u7F16\u8BD1\u53CA\u9A8C\u8BC1"}),"\n",(0,i.jsx)(e.p,{children:"\u6307\u5B9A schedule \u540E\uFF0C\u53EF\u4EE5\u5C06\u5176\u7F16\u8BD1\u4E3A TVM \u51FD\u6570\u3002\u4FDD\u5B58\u6A21\u5757\uFF0C\u4EE5\u4FBF\u901A\u8FC7 RPC \u53D1\u9001\u3002\u8FD0\u884C\u8FD9\u4E2A\u51FD\u6570\uFF0C\u5E76\u6839\u636E numpy \u5B9E\u73B0\u5BF9\u5176\u8FDB\u884C\u9A8C\u8BC1\uFF0C\u4EE5\u786E\u4FDD\u6B63\u786E\u6027\u3002"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# \u7528\u8FD9\u4E2A\u5E93\u8FDB\u884C 2D \u5377\u79EF\u6D4B\u8BD5\nfrom tvm.topi.testing import conv2d_nchw_python\n\n# \u7F16\u8BD1 TVM \u6A21\u5757\nwith vta.build_config(disabled_pass={"tir.CommonSubexprElimTIR"}):\n    my_conv = vta.build(\n        s, [data, kernel, res], tvm.target.Target("ext_dev", host=env.target_host), name="my_conv"\n    )\ntemp = utils.tempdir()\nmy_conv.save(temp.relpath("conv2d.o"))\nremote.upload(temp.relpath("conv2d.o"))\nf = remote.load_module("conv2d.o")\n\n# \u83B7\u53D6\u8FDC\u7A0B\u8BBE\u5907\u4E0A\u4E0B\u6587\nctx = remote.ext_dev(0)\n\n# \u5728 NCHW \u5E03\u5C40\u7684 (-128, 128] int \u8303\u56F4\u5185\u968F\u673A\u521D\u59CB\u5316\u6570\u636E\u548C\u5185\u6838\u6570\u7EC4\ndata_np = np.random.randint(-128, 128, size=(batch_size, in_channels, height, width)).astype(\n    data.dtype\n)\nkernel_np = np.random.randint(\n    -128, 128, size=(out_channels, in_channels, kernel_h, kernel_w)\n).astype(kernel.dtype)\n\n# \u5C06\u6570\u636E\u548C\u5185\u6838\u6570\u7EC4\u4ECE 2D NCHW \u6253\u5305\u4E3A 4D NCHWnc \u6253\u5305\u5E03\u5C40\ndata_packed = data_np.reshape(\n    batch_size // env.BATCH, env.BATCH, in_channels // env.BLOCK_IN, env.BLOCK_IN, height, width\n).transpose((0, 2, 4, 5, 1, 3))\n\nkernel_packed = kernel_np.reshape(\n    out_channels // env.BLOCK_OUT,\n    env.BLOCK_OUT,\n    in_channels // env.BLOCK_IN,\n    env.BLOCK_IN,\n    kernel_h,\n    kernel_w,\n).transpose((0, 2, 4, 5, 1, 3))\n\n# \u7528 tvm.nd.array \u5C06\u8F93\u5165/\u8F93\u51FA\u6570\u7EC4\u683C\u5F0F\u5316\u4E3A DLPack \u6807\u51C6\ndata_nd = tvm.nd.array(data_packed, ctx)\nkernel_nd = tvm.nd.array(kernel_packed, ctx)\nres_nd = tvm.nd.array(np.zeros(output_shape).astype(res.dtype), ctx)\n\n# \u6E05\u9664\u7EDF\u8BA1\nif env.TARGET in ["sim", "tsim"]:\n    simulator.clear_stats()\n\n# \u8C03\u7528\u6A21\u5757\u8FDB\u884C\u8BA1\u7B97\nf(data_nd, kernel_nd, res_nd)\n\n# \u9488\u5BF9 numpy \u5B9E\u73B0\u8FDB\u884C\u9A8C\u8BC1\nres_ref = conv2d_nchw_python(\n    data_np.astype(env.acc_dtype),\n    kernel_np.astype(env.acc_dtype),\n    (stride_h, stride_w),\n    (pad_h, pad_w),\n).astype(env.acc_dtype)\nres_ref = res_ref >> env.INP_WIDTH\nres_ref = np.clip(res_ref, 0, inp_max)\nres_ref = res_ref.astype(res.dtype)\nres_ref = res_ref.reshape(\n    (\n        batch_size // env.BATCH,\n        env.BATCH,\n        out_channels // env.BLOCK_OUT,\n        env.BLOCK_OUT,\n        fout_height,\n        fout_width,\n    )\n).transpose((0, 2, 4, 5, 1, 3))\ntvm.testing.assert_allclose(res_ref, res_nd.numpy())\n\n# \u6253\u5370\u7EDF\u8BA1\nif env.TARGET in ["sim", "tsim"]:\n    sim_stats = simulator.stats()\n    print("Execution statistics:")\n    for k, v in sim_stats.items():\n        print("\\t{:<16}: {:>16}".format(k, v))\n\nprint("Successful 2D convolution test!")\n'})}),"\n",(0,i.jsx)(e.p,{children:"\u8F93\u51FA\u7ED3\u679C\uFF1A"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:'/workspace/python/tvm/driver/build_module.py:267: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n  "target_host parameter is going to be deprecated. "\nExecution statistics:\n        inp_load_nbytes :           114688\n        wgt_load_nbytes :          1179648\n        acc_load_nbytes :                0\n        uop_load_nbytes :             1144\n        out_store_nbytes:            50176\n        gemm_counter    :           451584\n        alu_counter     :             9408\nSuccessful 2D convolution test!\n'})}),"\n",(0,i.jsx)(e.h2,{id:"\u603B\u7ED3",children:"\u603B\u7ED3"}),"\n",(0,i.jsx)(e.p,{children:"\u672C\u6559\u7A0B\u6F14\u793A\u5982\u4F55\u7528 TVM \u8C03\u5EA6\u539F\u8BED\u5C06 2D \u5377\u79EF\u964D\u7EA7\u5230\u786C\u4EF6\u52A0\u901F\u5668\u5185\u8054\u51FD\u6570\u4E0A\uFF0C\u5229\u7528\u786C\u4EF6\u7279\u5B9A\u7684\u4F18\u5316\uFF0C\u4F8B\u5982\u4F7F\u7528\u865A\u62DF\u7EBF\u7A0B\u5EF6\u8FDF\u9690\u85CF\u3002"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.a,{href:"https://tvm.apache.org/docs/_downloads/13ef71e33eaef0855c6e883d9ec5d632/convolution_opt.py",children:"\u4E0B\u8F7D Python \u6E90\u4EE3\u7801\uFF1Aconvolution_opt.py"})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.a,{href:"https://tvm.apache.org/docs/_downloads/b3f997c945cc7de3e03a1e0c4c73fabd/convolution_opt.ipynb",children:"\u4E0B\u8F7D Jupyter Notebook\uFF1Aconvolution_opt.ipynb"})})]})}function l(n={}){let{wrapper:e}={...(0,_.a)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},69782:function(n,e,t){t.d(e,{Z:function(){return r}});let r=t.p+"assets/images/conv2d_dataflow-e42eff0fc2623e1947e2997dd0f72bd1.png"},38313:function(n,e,t){t.d(e,{Z:function(){return r}});let r=t.p+"assets/images/padding-05bcfe13337b5ebb22aa7f387d46fb98.png"},25783:function(n,e,t){t.d(e,{Z:function(){return r}});let r=t.p+"assets/images/virtual_threading-ad310b4bf5c2da35774ec8e9908cf6a7.png"},21494:function(n,e,t){t.d(e,{Z:function(){return s},a:function(){return a}});var r=t(39546);let i={},_=r.createContext(i);function a(n){let e=r.useContext(_);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),r.createElement(_.Provider,{value:e},n.children)}}}]);